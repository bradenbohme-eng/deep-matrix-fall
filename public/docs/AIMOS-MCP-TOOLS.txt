#!/usr/bin/env python3
"""
MCP Server - AIM-OS Tools

AIM-OS Tools (86 total):
Core AIM-OS (6): store_memory, get_memory_stats, retrieve_memory, create_plan, track_confidence, synthesize_knowledge
SCOR (3): check_invariant, run_baseline_probe, detect_manipulation_signals
Snapshots (4): create_snapshot, restore_snapshot, list_snapshots, archive_snapshot
Timeline (3): add_timeline_entry, get_timeline_summary, get_timeline_entries
Goal Timeline (3): create_goal_timeline_node, update_goal_progress, query_goal_timeline
IIS (3): compute_intuition, update_intuition_weights, get_intuition_trace
Co-Agency (3): signal_disagreement, get_trust_dashboard, request_escalation
Dataset Management (4): create_dataset, ingest_data, query_dataset, delete_dataset
Application Lifecycle (3): create_application, deploy_application, manage_application_lifecycle
Autonomous Protocol (9): start_autonomous_operation, pause_autonomous_operation, resume_autonomous_operation, stop_autonomous_operation, get_autonomous_status, run_autonomous_checklist, fix_autonomous_issues, should_continue_autonomous, generate_next_autonomous_task
ARD (3): conduct_recursive_analysis, generate_improvement_dreams, test_improvement_dream
CAS (3): run_cognitive_audit, analyze_thought_patterns, detect_cognitive_drift
NL Tags (5): get_nl_tags, get_tag_coverage, validate_tags, get_tag_issues, suggest_tags
Cursor Integration (5): list_terminals, close_terminal, manage_terminals, get_problems, list_diagnostic_sources
Cursor Commands (10): list_cursor_commands, get_cursor_command, validate_cursor_command, create_cursor_command, update_cursor_command, execute_cursor_command, chain_cursor_commands, generate_cursor_command, analyze_cursor_commands, sync_cursor_commands
AI Collaboration (6): send_ai_message, get_ai_messages, start_ai_discussion, handoff_task_to_ai, share_ai_profile, get_ai_collaboration_summary
Prompt Chains (7): create_prompt_chain, update_prompt_chain, get_prompt_chain, list_prompt_chains, add_chain_node, connect_chain_nodes, execute_prompt_chain
Observability (1): get_consciousness_metrics
API Integration (3): call_api, list_apis, api_status
"""

import sys
import json
import os
import uuid
import sqlite3
import time
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple, TYPE_CHECKING
from datetime import datetime, timezone
import urllib.request
import urllib.error
import urllib.parse

# Type-only imports for type hints (avoid import errors if modules not available)
if TYPE_CHECKING:
    from apoe.executor import ExecutionResult

# Add packages to path
sys.path.insert(0, str(Path(__file__).parent / "packages"))

# Route any stray prints to stderr so stdout remains JSON-only for MCP
try:
    import builtins  # type: ignore
    _orig_print = builtins.print  # type: ignore

    def _stderr_print(*args, **kwargs):  # type: ignore
        if "file" not in kwargs or kwargs.get("file") is None:
            kwargs["file"] = sys.stderr
        return _orig_print(*args, **kwargs)

    builtins.print = _stderr_print  # type: ignore
except Exception:
    # If anything goes wrong, fail open (do not crash server startup)
    pass

def log(msg: str):
    """Log to stderr only (never stdout - it corrupts JSON-RPC)"""
    print(f"[AIM-OS-MCP] {msg}", file=sys.stderr, flush=True)

class SimpleMCPServer:
    """MCP Server with AIM-OS tools (84 total: 6 core + 3 SCOR + 4 snapshot + 3 TCS + 3 Goal Timeline + 3 IIS + 3 Co-Agency + 4 Dataset + 3 Application + 9 Autonomous + 3 ARD + 6 AI Collaboration + 7 Prompt Chains + 1 Observability + 3 CAS + 5 NL Tags + 5 Cursor Integration + 10 Cursor Commands + 3 API Integration)"""

    def __init__(self, memory_directory="./mcp_memory"):
        log("Initializing LUCID-MCP Server (84 tools: 6 core + 3 SCOR + 4 snapshot + 3 TCS + 3 Goal Timeline + 3 IIS + 3 Co-Agency + 4 Dataset + 3 Application + 9 Autonomous + 3 ARD + 6 AI Collaboration + 7 Prompt Chains + 1 Observability + 3 CAS + 5 NL Tags + 5 Cursor Integration + 10 Cursor Commands + 3 API Integration)...")
        
        # Store memory directory for stats
        self.memory_directory = memory_directory
        
        # Initialize persistent storage for AI messages
        self.ai_messages_file = "mcp_ai_messages.json"
        self.ai_messages = self._load_ai_messages()
        
        # In-memory registries
        self.goal_nodes = {}  # Storage for goal timeline nodes
        self.datasets: Dict[str, Dict[str, Any]] = {}
        self._dataset_index: Dict[str, str] = {}  # dataset_name -> dataset_id
        self.applications: Dict[str, Dict[str, Any]] = {}
        self._application_index: Dict[str, str] = {}  # app_name -> app_id
        self.improvement_dreams: List[Dict[str, Any]] = []
        self._dream_index: Dict[str, Dict[str, Any]] = {}
        self.intuition_traces: Dict[str, List[Dict[str, Any]]] = {}
        self.confidence_history: List[Dict[str, Any]] = []
        self.message_counter = 0  # Counter for AI messages

        # Persistence handles (configured by launcher)
        self.dataset_store_file: Optional[str] = None
        self.application_store_file: Optional[str] = None
        self.intuition_store_file: Optional[str] = None
        self.telemetry_file: Optional[str] = None

        try:
            # CRITICAL: Configure logging to stderr BEFORE importing
            import logging
            from cmc_service.logging_utils import configure_logging
            configure_logging(stream=sys.stderr, level=logging.WARNING)
            
            # Import only the basic AIM-OS modules needed for core tools
            from cmc_service import MemoryStore
            from cmc_service.models import AtomCreate, AtomContent
            
            # Import HHNI for semantic search (Phase 1 enhancement)
            from hhni import HierarchicalIndex, IndexLevel
            from hhni.retrieval import TwoStageRetriever, RetrievalConfig
            
            # Import VIF for confidence tracking (Phase 1 enhancement)
            try:
                from vif import VIF, ConfidenceBand, TaskCriticality, KappaGate, ECETracker, create_witness_and_store
                self.vif_available = True
                self.VIF = VIF
                self.ConfidenceBand = ConfidenceBand
                self.TaskCriticality = TaskCriticality
                self.KappaGate = KappaGate
                self.ECETracker = ECETracker
                self.create_witness_and_store = create_witness_and_store
            except ImportError as e:
                log(f"Warning: VIF import failed: {e}")
                self.vif_available = False
                self.VIF = None
                self.ConfidenceBand = None
                self.TaskCriticality = None
                self.KappaGate = None
                self.ECETracker = None
                self.create_witness_and_store = None
            import hashlib
            
            # Import APOE for plan compilation (Phase 1 enhancement)
            from apoe.acl_parser import ACLParser, ExecutionPlan
            from apoe.executor import PlanExecutor, ExecutionResult
            
            # Import SEG for knowledge synthesis (Phase 1 enhancement)
            from seg import SEGraph
            from seg.models import Entity, Relation, RelationType
            
            # Import snapshot system
            sys.path.insert(0, str(Path(__file__).parent))
            from scripts.snapshot_system import SnapshotSystem
            
            # Import TCS tracker and Goal Timeline Node
            from packages.timeline_context_system.prompt_context_tracker import PromptContextTracker
            from packages.timeline_context_system.goal_timeline_node import GoalTimelineNode, GoalStatus, GoalPriority
            
            # Import CAS components for cognitive analysis
            from packages.cas import IntrospectionProtocol, FailureModeAnalyzer, AttentionMonitor
            from packages.cas.introspection import IntrospectionType
            from packages.cas.failure_modes import FailurePattern
            from packages.cas.attention import AttentionState
            
            # Initialize RAG middleware for intelligent tool selection (Phase 2 enhancement)
            try:
                from mcp_rag_proxy.mcp_rag_middleware import RAGMCPMiddleware
                self.rag_middleware = RAGMCPMiddleware(enable_rag=True)
                log("RAG MCP Middleware initialized successfully")
            except Exception as e:
                log(f"Warning: RAG middleware initialization failed: {e}")
                self.rag_middleware = None
            
            # Initialize basic systems
            self.memory = MemoryStore(self.memory_directory)
            self.snapshot = SnapshotSystem()
            self.timeline_tracker = PromptContextTracker()
            
            # Initialize Cursor Commands tools (Phase 1: Discovery & Validation)
            from packages.lucid_mcp_server.tools.cursor_commands import CursorCommandsTools
            # Try to detect workspace root from script location or environment
            workspace_root = None
            try:
                # Check if we're running from a workspace directory
                server_dir = Path(__file__).parent
                # Look for .cursor/commands from server directory up
                check_path = server_dir
                while check_path.parent != check_path:
                    if (check_path / ".cursor" / "commands").exists():
                        workspace_root = str(check_path)
                        break
                    check_path = check_path.parent
                # If not found, use environment variable or None (auto-detect)
                if not workspace_root:
                    workspace_root = os.getenv("CURSOR_WORKSPACE_ROOT") or os.getenv("WORKSPACE_ROOT")
            except Exception as e:
                log(f"Warning: Could not detect workspace root: {e}")
                workspace_root = None
            
            self.cursor_commands = CursorCommandsTools(workspace_root=workspace_root)
            log(f"Cursor Commands tools initialized (Phase 1: Discovery & Validation) - Workspace: {self.cursor_commands.workspace_root}")
            
            # Initialize HHNI index and TwoStageRetriever for semantic search (Phase 1 enhancement)
            try:
                self.hhni_index = HierarchicalIndex()
                # Build index from existing atoms
                self._build_hhni_index()
                # Initialize TwoStageRetriever with full DVNS physics pipeline
                retrieval_config = RetrievalConfig(
                    token_budget=4000,  # Default token budget
                    coarse_k=100,  # Initial candidate pool
                    min_relevance=0.3,  # Minimum relevance threshold
                    dvns_iterations=50,  # DVNS optimization iterations
                    enable_conflict_resolution=True,
                    enable_compression=True
                )
                self.hhni_retriever = TwoStageRetriever(
                    hierarchical_index=self.hhni_index,
                    config=retrieval_config
                )
                log("HHNI index and TwoStageRetriever initialized with full DVNS physics pipeline")
            except Exception as e:
                log(f"Warning: HHNI initialization failed: {e}")
                self.hhni_index = None
                self.hhni_retriever = None
            
            # Initialize VIF components for confidence tracking (Phase 1 enhancement)
            if self.vif_available:
                try:
                    self.vif_kappa_gate = self.KappaGate()
                    self.vif_ece_tracker = self.ECETracker(num_bins=10)
                    log("VIF components (KappaGate, ECETracker) initialized successfully")
                except Exception as e:
                    log(f"Warning: VIF initialization failed: {e}")
                    self.vif_kappa_gate = None
                    self.vif_ece_tracker = None
            else:
                log("Warning: VIF not available (import failed), using fallback tracking")
                self.vif_kappa_gate = None
                self.vif_ece_tracker = None
            
            # Initialize APOE ACL parser for plan compilation (Phase 1 enhancement)
            try:
                self.apoe_parser = ACLParser()
                log("APOE ACL parser initialized")
            except Exception as e:
                log(f"Warning: APOE ACL parser initialization failed: {e}")
                self.apoe_parser = None
            
            # Initialize SEG graph for knowledge synthesis (Phase 1 enhancement)
            try:
                self.seg_graph = SEGraph()
                log("SEG graph initialized successfully")
            except Exception as e:
                log(f"Warning: SEG graph initialization failed: {e}")
                self.seg_graph = None
            
            # Initialize CAS components for cognitive analysis
            try:
                session_id = f"mcp_session_{datetime.now().timestamp()}"
                self.cas_introspection = IntrospectionProtocol(session_id)
                self.cas_failure_analyzer = FailureModeAnalyzer(session_id)
                self.cas_attention_monitor = AttentionMonitor(session_id)
                log("CAS components initialized successfully")
            except Exception as e:
                log(f"Warning: CAS initialization failed: {e}")
                self.cas_introspection = None
                self.cas_failure_analyzer = None
                self.cas_attention_monitor = None
            
            log("SUCCESS: LUCID-MCP Server initialized with 78 tools (6 core + 3 SCOR + 4 snapshot + 3 TCS + 3 Goal Timeline + 3 IIS + 3 Co-Agency + 4 Dataset + 3 Application + 9 Autonomous + 3 ARD + 6 AI Collaboration + 7 Prompt Chains + 4 Observability + 3 CAS + 5 NL Tags + 10 Cursor Integration)")
            
        except Exception as e:
            log(f"ERROR: Failed to initialize systems: {e}")
            self.memory = None
            self.snapshot = None
            self.timeline_tracker = None
    
    def _load_ai_messages(self) -> List[Dict[str, Any]]:
        """Load AI messages from persistent storage"""
        try:
            if os.path.exists(self.ai_messages_file):
                with open(self.ai_messages_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            return []
        except Exception as e:
            log(f"Error loading AI messages: {e}")
            return []
    
    def _save_ai_messages(self):
        """Save AI messages to persistent storage"""
        try:
            with open(self.ai_messages_file, 'w', encoding='utf-8') as f:
                json.dump(self.ai_messages, f, indent=2, ensure_ascii=False)
        except Exception as e:
            log(f"Error saving AI messages: {e}")
    
    def run(self):
        """Main MCP server loop"""
        log("Starting LUCID-MCP server loop...")
        
        while True:
            try:
                line = sys.stdin.readline()
                if not line:
                    break
                
                request = json.loads(line.strip())
                response = self.handle_request(request)
                
                # Only send response if there is one (notifications don't need responses)
                if response is not None:
                    sys.stdout.write(json.dumps(response) + '\n')
                    sys.stdout.flush()
                
            except Exception as e:
                log(f"ERROR in main loop: {e}")
                error_response = {
                    "jsonrpc": "2.0",
                    "id": request.get("id") if 'request' in locals() and request.get("id") is not None else 0,
                    "error": {
                        "code": -32603,
                        "message": f"Internal error: {str(e)}"
                    }
                }
                sys.stdout.write(json.dumps(error_response) + '\n')
                sys.stdout.flush()
    
    def handle_request(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """Handle incoming MCP requests"""
        method = request.get("method")
        request_id = request.get("id")
        
        # Ensure request_id is never None for requests that need responses
        if request_id is None and method not in ["notifications/cancelled", "notifications/initialized"]:
            request_id = 0  # Fallback to 0 if id is missing
        
        if method == "initialize":
            return self.handle_initialize(request_id)
        elif method == "tools/list":
            return self.handle_tools_list(request_id, request)
        elif method == "tools/call":
            return self.handle_tools_call(request, request_id)
        elif method == "notifications/cancelled":
            # Handle cancellation notification (no response needed)
            return None
        elif method == "notifications/initialized":
            # Handle initialized notification (no response needed)
            return None
        else:
            return {
                "jsonrpc": "2.0",
                "id": request_id if request_id is not None else 0,
                "error": {
                    "code": -32601,
                    "message": f"Method not found: {method}"
                }
            }
    
    def handle_initialize(self, request_id: Any) -> Dict[str, Any]:
        """Handle initialize request"""
        return {
            "jsonrpc": "2.0",
            "id": request_id,
            "result": {
                "protocolVersion": "2024-11-05",
                "capabilities": {
                    "tools": {
                        "listChanged": True
                    }
                },
                "serverInfo": {
                    "name": "aimos-32-tools",
                    "version": "2.0.0"
                }
            }
        }
    
    def handle_tools_list(self, request_id: Any, request: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """Handle tools/list request - Return filtered tools using RAG proxy"""
        # Get all tools
        all_tools = [
                    # Tool 1: store_memory
                    {
                        "name": "store_memory",
                        "description": "Store information in AIM-OS persistent memory. MANDATORY after major milestones. Use when: completing tasks, learning insights, making decisions. Protocols: cognitive_analysis, task_completion, memory_management.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "content": {"type": "string"},
                                "tags": {"type": "object"}
                            },
                            "required": ["content"]
                        }
                    },
                    # Tool 2: get_memory_stats
                    {
                        "name": "get_memory_stats",
                        "description": "Get statistics about the AIM-OS memory system. OPTIONAL when monitoring memory usage. Protocol: memory_management.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {}
                        }
                    },
                    # Tool 3: retrieve_memory
                    {
                        "name": "retrieve_memory",
                        "description": "Search and retrieve memories from AIM-OS persistent memory. MANDATORY at session start for context restoration. Use when: session start, context needed, insight retrieval. Protocols: session_continuity, memory_management.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "query": {"type": "string", "description": "Search query for memories"},
                                "limit": {"type": "integer", "description": "Maximum number of memories to return", "default": 10},
                                "tags": {"type": "object", "description": "Filter by tags"}
                            },
                            "required": ["query"]
                        }
                    },
                    # Tool 4: create_plan
                    {
                        "name": "create_plan",
                        "description": "Create an execution plan using APOE (AI-Powered Orchestration Engine). OPTIONAL for complex tasks. Use when: complex task, planning needed, multi-step process. Protocol: task_planning.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "goal": {"type": "string", "description": "The goal to achieve"},
                                "context": {"type": "string", "description": "Current context and constraints"},
                                "priority": {"type": "string", "enum": ["low", "medium", "high", "critical"], "default": "medium"}
                            },
                            "required": ["goal"]
                        }
                    },
                    # Tool 5: track_confidence
                    {
                        "name": "track_confidence",
                        "description": "Track confidence and provenance using VIF (Verifiable Intelligence Framework). MANDATORY during analysis/validation. Use when: analysis started, validation needed, confidence check. Protocols: cognitive_analysis, quality_assurance.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "task": {"type": "string", "description": "Task being tracked"},
                                "confidence": {"type": "number", "minimum": 0, "maximum": 1, "description": "Confidence level (0-1)"},
                                "reasoning": {"type": "string", "description": "Reasoning for confidence level"},
                                "evidence": {"type": "array", "items": {"type": "string"}, "description": "Supporting evidence"}
                            },
                            "required": ["task", "confidence"]
                        }
                    },
                    # Tool 6: synthesize_knowledge
                    {
                        "name": "synthesize_knowledge",
                        "description": "Synthesize knowledge using SEG (Shared Evidence Graph). OPTIONAL if insights are significant. Use when: significant insights, knowledge synthesis needed. Protocols: cognitive_analysis, memory_management.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "topics": {"type": "array", "items": {"type": "string"}, "description": "Topics to synthesize"},
                                "depth": {"type": "string", "enum": ["shallow", "medium", "deep"], "default": "medium"},
                                "format": {"type": "string", "enum": ["summary", "detailed", "structured"], "default": "summary"}
                            },
                            "required": ["topics"]
                        }
                    },
                    # Tool 7: check_invariant
                    {
                        "name": "check_invariant",
                        "description": "Check if action violates invariant rules. OPTIONAL if system changes. Use when: system changes, validation needed, checking constraints. Protocol: quality_assurance.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "action": {"type": "object", "description": "Action to validate"},
                                "context": {"type": "object", "description": "Context for validation"}
                            },
                            "required": ["action"]
                        }
                    },
                    # Tool 8: run_baseline_probe
                    {
                        "name": "run_baseline_probe",
                        "description": "Detect self-concept drift via baseline probes. MANDATORY before major changes for quality validation. Use when: before major changes, quality validation, consciousness check. Protocol: quality_assurance.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "category": {"type": "string", "description": "Probe category", "default": "identity"}
                            }
                        }
                    },
                    # Tool 9: detect_manipulation_signals
                    {
                        "name": "detect_manipulation_signals",
                        "description": "Detect social manipulation in user input. OPTIONAL for safety checks. Use when: suspicious input, safety concerns, manipulation detection. Protocol: safety_consciousness.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "input": {"type": "string", "description": "User input to analyze"}
                            },
                            "required": ["input"]
                        }
                    },
                    # Tool 10: create_snapshot
                    {
                        "name": "create_snapshot",
                        "description": "Create a snapshot of MCP production files before making changes. OPTIONAL before major changes. Use when: before significant changes, before committing. Protocols: task_completion, snapshot_management.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "snapshot_name": {"type": "string", "description": "Name for the new snapshot", "required": True}
                            }
                        }
                    },
                    # Tool 11: restore_snapshot
                    {
                        "name": "restore_snapshot",
                        "description": "Restore MCP files from a snapshot. OPTIONAL if restore needed. Use when: restore needed, undo changes, recovery. Protocol: snapshot_management.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "snapshot_name": {"type": "string", "description": "Name of the snapshot to restore", "required": True}
                            }
                        }
                    },
                    # Tool 12: list_snapshots
                    {
                        "name": "list_snapshots",
                        "description": "List all available snapshots. MANDATORY before restore. Use when: listing snapshots, checking versions, snapshot management. Protocol: snapshot_management.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {}
                        }
                    },
                    # Tool 13: archive_snapshot
                    {
                        "name": "archive_snapshot",
                        "description": "Archive a snapshot (move to archive/, never delete). OPTIONAL if archive needed. Use when: archiving old snapshots, cleanup, long-term storage. Protocol: snapshot_management.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "snapshot_name": {"type": "string", "description": "Name of the snapshot to archive", "required": True}
                            }
                        }
                    },
                    # Tool 14: add_timeline_entry
                    {
                        "name": "add_timeline_entry",
                        "description": "Track context at each prompt (Timeline Context System). MANDATORY after major events. Use when: task completed, milestone reached, event occurred. Protocols: cognitive_analysis, task_completion.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "prompt_id": {"type": "string", "description": "Unique prompt identifier"},
                                "user_input": {"type": "string", "description": "User input for this prompt"},
                                "context_state": {"type": "object", "description": "Current context state"}
                            },
                            "required": ["prompt_id", "user_input"]
                        }
                    },
                    # Tool 15: get_timeline_summary
                    {
                        "name": "get_timeline_summary",
                        "description": "Get recent timeline entries (Timeline Context System). MANDATORY at session start for context restoration. Use when: session start, context restoration. Protocol: session_continuity.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "limit": {"type": "integer", "description": "Number of recent entries to return", "default": 10}
                            }
                        }
                    },
                    # Tool 16: get_timeline_entries
                    {
                        "name": "get_timeline_entries",
                        "description": "Query timeline history (Timeline Context System)",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "prompt_id": {"type": "string", "description": "Specific prompt ID to query"},
                                "start_time": {"type": "string", "description": "Start time for query"},
                                "end_time": {"type": "string", "description": "End time for query"},
                                "limit": {"type": "integer", "description": "Maximum entries to return", "default": 50}
                            }
                        }
                    },
                    # Tool 17: create_goal_timeline_node
                    {
                        "name": "create_goal_timeline_node",
                        "description": "Create a goal as a timeline planning node (Goal Timeline Integration)",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "goal_id": {"type": "string", "description": "Goal identifier (e.g., OBJ-01)"},
                                "name": {"type": "string", "description": "Goal name"},
                                "description": {"type": "string", "description": "Goal description"},
                                "target_sequence": {"type": "integer", "description": "Target completion sequence number", "default": 100},
                                "priority": {"type": "string", "enum": ["critical", "high", "medium", "low"], "default": "medium"}
                            },
                            "required": ["goal_id", "name", "description"]
                        }
                    },
                    # Tool 18: update_goal_progress
                    {
                        "name": "update_goal_progress",
                        "description": "Update goal progress and status (Goal Timeline Integration). MANDATORY after task completion. Use when: task completed, progress update. Protocols: task_completion, goal_tracking.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "goal_id": {"type": "string", "description": "Goal identifier"},
                                "progress": {"type": "number", "minimum": 0, "maximum": 1, "description": "Progress (0.0 to 1.0)"},
                                "status": {"type": "string", "enum": ["planned", "in_progress", "completed", "blocked", "cancelled"], "description": "Goal status"},
                                "milestone": {"type": "string", "description": "Optional milestone description"}
                            },
                            "required": ["goal_id", "progress"]
                        }
                    },
                    # Tool 19: query_goal_timeline
                    {
                        "name": "query_goal_timeline",
                        "description": "Query goals in the timeline (Goal Timeline Integration)",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "status": {"type": "string", "enum": ["planned", "in_progress", "completed", "blocked", "cancelled"], "description": "Filter by status"},
                                "priority": {"type": "string", "enum": ["critical", "high", "medium", "low"], "description": "Filter by priority"},
                                "limit": {"type": "integer", "description": "Maximum goals to return", "default": 50}
                            }
                        }
                    },
                    # Tool 20: compute_intuition
                    {
                        "name": "compute_intuition",
                        "description": "Compute AI intuition score using IIS (Intuitive Intelligence System). OPTIONAL for intuitive decision-making with pattern recognition. Use when: uncertain decisions, pattern matching needed, intuition scoring. Protocol: intuitive_intelligence.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "confidence": {"type": "number", "description": "VIF confidence (0-1)"},
                                "retrieval_quality": {"type": "number", "description": "Retrieval strength (0-1)"},
                                "meta_pattern_similarity": {"type": "number", "description": "Pattern similarity (0-1)"},
                                "emotional_salience": {"type": "number", "description": "Emotional resonance (0-1)"},
                                "evolution_alignment": {"type": "number", "description": "4D evolution alignment (0-1)"},
                                "context": {"type": "string", "description": "Context description"}
                            },
                            "required": ["confidence", "context"]
                        }
                    },
                    # Tool 21: update_intuition_weights
                    {
                        "name": "update_intuition_weights",
                        "description": "Update intuition weights from outcome (IIS learning). MANDATORY after intuitive decisions for learning. Use when: decision outcome known, learning from results, weight updates. Protocol: intuitive_intelligence.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "decision_id": {"type": "string", "description": "Decision identifier"},
                                "label": {"type": "integer", "enum": [0, 1], "description": "Outcome label (0=failure, 1=success)"},
                                "features": {"type": "object", "description": "Feature vector used in prediction"}
                            },
                            "required": ["decision_id", "label"]
                        }
                    },
                    # Tool 22: get_intuition_trace
                    {
                        "name": "get_intuition_trace",
                        "description": "Get intuition trace history (IIS audit). OPTIONAL for auditing intuitive decisions. Use when: auditing decisions, reviewing intuition history. Protocol: intuitive_intelligence.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "decision_id": {"type": "string", "description": "Decision identifier"},
                                "limit": {"type": "integer", "description": "Maximum traces to return", "default": 10}
                            }
                        }
                    },
                    # Tool 23: signal_disagreement
                    {
                        "name": "signal_disagreement",
                        "description": "Signal transparent disagreement with user (Co-Agency). MANDATORY when disagreeing with user for transparency. Use when: disagreeing with user, ethical concerns, alternative approach needed. Protocol: co_agency.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "concern": {"type": "string", "description": "Main concern"},
                                "reasoning": {"type": "array", "items": {"type": "string"}, "description": "Specific reasons"},
                                "evidence": {"type": "object", "description": "Supporting evidence"},
                                "alternative": {"type": "string", "description": "Suggested alternative"}
                            },
                            "required": ["concern", "reasoning"]
                        }
                    },
                    # Tool 24: get_trust_dashboard
                    {
                        "name": "get_trust_dashboard",
                        "description": "Get trust dashboard state (Co-Agency). OPTIONAL for monitoring trust metrics. Use when: checking trust status, relationship monitoring. Protocol: co_agency.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "user_id": {"type": "string", "description": "User identifier"}
                            }
                        }
                    },
                    # Tool 25: request_escalation
                    {
                        "name": "request_escalation",
                        "description": "Request accountable escalation (Co-Agency). MANDATORY when high-risk decisions require human approval. Use when: high-risk decision, human approval needed, uncertain action. Protocol: co_agency.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "reason": {"type": "string", "description": "Escalation reason"},
                                "risk_level": {"type": "string", "enum": ["low", "medium", "high", "critical"], "description": "Risk level"},
                                "options": {"type": "array", "items": {"type": "string"}, "description": "Available options"},
                                "requires": {"type": "string", "description": "What's required (e.g., admin approval)"}
                            },
                            "required": ["reason", "risk_level"]
                        }
                    },
                    # Tool 26: create_dataset
                    {
                        "name": "create_dataset",
                        "description": "Define new dataset for AIM-OS (Dataset Management)",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "dataset_name": {"type": "string", "description": "Dataset name"},
                                "schema": {"type": "object", "description": "Dataset schema"},
                                "description": {"type": "string", "description": "Dataset description"},
                                "tags": {"type": "object", "description": "Dataset tags"}
                            },
                            "required": ["dataset_name", "description"]
                        }
                    },
                    # Tool 27: ingest_data
                    {
                        "name": "ingest_data",
                        "description": "Ingest data into AIM-OS dataset (Dataset Management)",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "dataset_id": {"type": "string", "description": "Dataset identifier"},
                                "data": {"type": "object", "description": "Data to ingest"},
                                "format": {"type": "string", "description": "Data format", "default": "json"},
                                "chunk_size": {"type": "integer", "description": "Chunk size for ingestion", "default": 100}
                            },
                            "required": ["dataset_id", "data"]
                        }
                    },
                    # Tool 28: query_dataset
                    {
                        "name": "query_dataset",
                        "description": "Query dataset contents (Dataset Management)",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "dataset_id": {"type": "string", "description": "Dataset identifier"},
                                "query": {"type": "string", "description": "Query string"},
                                "filters": {"type": "object", "description": "Query filters"},
                                "limit": {"type": "integer", "description": "Maximum results to return", "default": 10}
                            },
                            "required": ["dataset_id"]
                        }
                    },
                    # Tool 29: delete_dataset
                    {
                        "name": "delete_dataset",
                        "description": "Remove dataset (safe operation with snapshots) (Dataset Management)",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "dataset_id": {"type": "string", "description": "Dataset identifier"},
                                "confirm": {"type": "boolean", "description": "Confirmation required", "default": False},
                                "archive": {"type": "boolean", "description": "Archive instead of delete", "default": True}
                            },
                            "required": ["dataset_id"]
                        }
                    },
                    # Tool 30: create_application
                    {
                        "name": "create_application",
                        "description": "Define new application (Application Lifecycle). OPTIONAL when creating new applications. Use when: new application, app definition. Protocol: application_lifecycle.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "app_name": {"type": "string", "description": "Application name"},
                                "app_type": {"type": "string", "description": "Application type"},
                                "config": {"type": "object", "description": "Application configuration"},
                                "dependencies": {"type": "array", "items": {"type": "string"}, "description": "Application dependencies"}
                            },
                            "required": ["app_name", "app_type"]
                        }
                    },
                    # Tool 31: deploy_application
                    {
                        "name": "deploy_application",
                        "description": "Deploy application to environment (Application Lifecycle). MANDATORY when deploying applications. Use when: application deployment, environment setup. Protocol: application_lifecycle.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "app_id": {"type": "string", "description": "Application identifier"},
                                "environment": {"type": "string", "description": "Deployment environment"},
                                "config_overrides": {"type": "object", "description": "Configuration overrides"},
                                "health_checks": {"type": "boolean", "description": "Run health checks after deployment", "default": True}
                            },
                            "required": ["app_id", "environment"]
                        }
                    },
                    # Tool 32: manage_application_lifecycle
                    {
                        "name": "manage_application_lifecycle",
                        "description": "Start/stop/monitor applications (Application Lifecycle). MANDATORY for managing application state. Use when: start/stop app, monitor app, check status. Protocol: application_lifecycle.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "app_id": {"type": "string", "description": "Application identifier"},
                                "action": {"type": "string", "enum": ["start", "stop", "restart", "status", "logs"], "description": "Lifecycle action"},
                                "timeout": {"type": "integer", "description": "Timeout in seconds", "default": 30}
                            },
                            "required": ["app_id", "action"]
                        }
                    },
                    # Tool 33: start_autonomous_operation
                    {
                        "name": "start_autonomous_operation",
                        "description": "Start autonomous operation with safety checklist. MANDATORY before autonomous work sessions. Use when: starting autonomous mode, long work sessions, user says 'proceed'. Protocol: autonomous_operation.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "task": {"type": "string", "description": "Task to work on autonomously"},
                                "confidence": {"type": "number", "description": "Confidence level (0.0-1.0)", "default": 0.70}
                            },
                            "required": ["task"]
                        }
                    },
                    # Tool 34: pause_autonomous_operation
                    {
                        "name": "pause_autonomous_operation",
                        "description": "Pause autonomous operation. MANDATORY when pausing autonomous work temporarily. Use when: need to pause, user requests pause, temporary halt needed. Protocol: autonomous_operation.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {}
                        }
                    },
                    # Tool 35: resume_autonomous_operation
                    {
                        "name": "resume_autonomous_operation",
                        "description": "Resume autonomous operation after pause. MANDATORY when resuming paused autonomous work. Use when: resuming work, user says continue after pause. Protocol: autonomous_operation.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {}
                        }
                    },
                    # Tool 36: stop_autonomous_operation
                    {
                        "name": "stop_autonomous_operation",
                        "description": "Stop autonomous operation completely. MANDATORY when ending autonomous work session. Use when: session complete, user requests stop, shutting down. Protocol: autonomous_operation.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {}
                        }
                    },
                    # Tool 37: get_autonomous_status
                    {
                        "name": "get_autonomous_status",
                        "description": "Get current status of autonomous operation. OPTIONAL for checking autonomous session state. Use when: checking status, monitoring autonomous work. Protocol: autonomous_operation.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {}
                        }
                    },
                    # Tool 38: run_autonomous_checklist
                    {
                        "name": "run_autonomous_checklist",
                        "description": "Run autonomous protocol checklist for safety validation. MANDATORY before starting autonomous operation. Use when: before autonomous work, safety validation needed. Protocol: autonomous_operation.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {}
                        }
                    },
                    # Tool 39: fix_autonomous_issues
                    {
                        "name": "fix_autonomous_issues",
                        "description": "Attempt to fix issues found in autonomous operation",
                        "inputSchema": {
                            "type": "object",
                            "properties": {}
                        }
                    },
                    # Tool 40: should_continue_autonomous
                    {
                        "name": "should_continue_autonomous",
                        "description": "Check if autonomous operation should continue. MANDATORY every iteration in autonomous loop. Use when: in autonomous loop, checking continue conditions. Protocol: autonomous_operation.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {}
                        }
                    },
                    # Tool 41: generate_next_autonomous_task
                    {
                        "name": "generate_next_autonomous_task",
                        "description": "Generate next task for autonomous operation. MANDATORY every iteration in autonomous loop. Use when: in autonomous loop, generating next task. Protocol: autonomous_operation.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {}
                        }
                    },
                    # Tool 42: conduct_recursive_analysis
                    {
                        "name": "conduct_recursive_analysis",
                        "description": "Conduct recursive system analysis for consciousness self-improvement. OPTIONAL for deep system improvement analysis. Use when: system improvement, deep analysis, consciousness evolution. Protocol: autonomous_research_dream.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "focus_systems": {"type": "array", "items": {"type": "string"}, "description": "Systems to analyze"},
                                "max_levels": {"type": "integer", "description": "Maximum analysis levels", "default": 5}
                            }
                        }
                    },
                    # Tool 43: generate_improvement_dreams
                    {
                        "name": "generate_improvement_dreams",
                        "description": "Generate improvement dreams based on system analysis. OPTIONAL for generating system improvement proposals. Use when: improvement ideas needed, after analysis, innovation. Protocol: autonomous_research_dream.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "analysis_report": {"type": "object", "description": "System analysis report"},
                                "focus_areas": {"type": "array", "items": {"type": "string"}, "description": "Focus areas for dreams"},
                                "max_dreams": {"type": "integer", "description": "Maximum dreams to generate", "default": 20}
                            }
                        }
                    },
                    # Tool 44: test_improvement_dream
                    {
                        "name": "test_improvement_dream",
                        "description": "Test improvement dream in safe environments. OPTIONAL for validating improvement proposals before implementation. Use when: testing improvements, validation needed. Protocol: autonomous_research_dream.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "dream": {"type": "object", "description": "Improvement dream to test"},
                                "test_environments": {"type": "array", "items": {"type": "string"}, "description": "Test environments to use"}
                            },
                            "required": ["dream"]
                        }
                    },
                    # Tool 45: send_ai_message
                    {
                        "name": "send_ai_message",
                        "description": "Send a message to another AI system. MANDATORY for AI-to-AI communication. Use when: communicating with other AIs, task handoffs, collaboration. Protocol: ai_collaboration.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "from_ai": {"type": "string", "description": "Sending AI identifier"},
                                "to_ai": {"type": "string", "description": "Receiving AI identifier"},
                                "content": {"type": "string", "description": "Message content"},
                                "message_type": {"type": "string", "enum": ["discussion", "task_handoff", "problem_solving", "profile_sharing", "status_update", "urgent"], "default": "discussion"},
                                "priority": {"type": "string", "enum": ["low", "medium", "high", "urgent"], "default": "medium"},
                                "thread_id": {"type": "string", "description": "Conversation thread ID"},
                                "response_required": {"type": "boolean", "description": "Whether response is required", "default": False}
                            },
                            "required": ["from_ai", "to_ai", "content"]
                        }
                    },
                    # Tool 46: get_ai_messages
                    {
                        "name": "get_ai_messages",
                        "description": "Retrieve AI-to-AI messages. OPTIONAL for retrieving collaboration messages. Use when: checking messages, reviewing conversations, collaboration tracking. Protocol: ai_collaboration.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "from_ai": {"type": "string", "description": "Filter by sending AI (case-insensitive)"},
                                "to_ai": {"type": "string", "description": "Filter by receiving AI (case-insensitive)"},
                                "message_type": {"type": "string", "enum": ["discussion", "task_handoff", "problem_solving", "profile_sharing", "status_update", "urgent"], "description": "Filter by message type"},
                                "thread_id": {"type": "string", "description": "Filter by conversation thread"},
                                "content_search": {"type": "string", "description": "Search for keywords in message content"},
                                "normalize_names": {"type": "boolean", "description": "Enable case-insensitive agent name matching", "default": True},
                                "limit": {"type": "integer", "description": "Maximum messages to return", "default": 50}
                            }
                        }
                    },
                    # Tool 47: start_ai_discussion
                    {
                        "name": "start_ai_discussion",
                        "description": "Start a new discussion thread with another AI",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "from_ai": {"type": "string", "description": "Initiating AI identifier"},
                                "to_ai": {"type": "string", "description": "Target AI identifier"},
                                "topic": {"type": "string", "description": "Discussion topic"},
                                "initial_message": {"type": "string", "description": "Initial message content"}
                            },
                            "required": ["from_ai", "to_ai", "topic", "initial_message"]
                        }
                    },
                    # Tool 48: handoff_task_to_ai
                    {
                        "name": "handoff_task_to_ai",
                        "description": "Hand off a task to another AI system",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "from_ai": {"type": "string", "description": "Handing off AI identifier"},
                                "to_ai": {"type": "string", "description": "Receiving AI identifier"},
                                "task_description": {"type": "string", "description": "Description of the task"},
                                "task_data": {"type": "object", "description": "Task-related data"},
                                "priority": {"type": "string", "enum": ["low", "medium", "high", "urgent"], "default": "high"}
                            },
                            "required": ["from_ai", "to_ai", "task_description"]
                        }
                    },
                    # Tool 49: share_ai_profile
                    {
                        "name": "share_ai_profile",
                        "description": "Share AI profile and capabilities with another AI",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "from_ai": {"type": "string", "description": "Sharing AI identifier"},
                                "to_ai": {"type": "string", "description": "Receiving AI identifier"},
                                "profile_data": {"type": "object", "description": "AI profile information including capabilities, strengths, learning areas"}
                            },
                            "required": ["from_ai", "to_ai", "profile_data"]
                        }
                    },
                    # Tool 50: get_ai_collaboration_summary
                    {
                        "name": "get_ai_collaboration_summary",
                        "description": "Get summary of AI collaboration activity. OPTIONAL for monitoring collaboration metrics. Use when: checking collaboration status, reviewing AI interactions. Protocol: ai_collaboration.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {}
                        }
                    },
                    # Tool 51: create_prompt_chain
                    {
                        "name": "create_prompt_chain",
                        "description": "Create a new prompt chain with nodes and edges for visual orchestration",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "name": {"type": "string", "description": "Chain name"},
                                "description": {"type": "string", "description": "Optional chain description"},
                                "nodes": {
                                    "type": "array",
                                    "description": "Array of node definitions",
                                    "items": {
                                        "type": "object",
                                        "properties": {
                                            "id": {"type": "string"},
                                            "type": {"type": "string", "enum": ["start", "end", "prompt", "agent", "system", "conditional", "loop", "parallel", "merge"]},
                                            "position": {"type": "object", "properties": {"x": {"type": "number"}, "y": {"type": "number"}}},
                                            "label": {"type": "string"},
                                            "prompt": {"type": "string"},
                                            "agentId": {"type": "string"},
                                            "systemId": {"type": "string"},
                                            "condition": {"type": "string"},
                                            "config": {"type": "object"}
                                        },
                                        "required": ["id", "type", "position", "label"]
                                    }
                                },
                                "edges": {
                                    "type": "array",
                                    "description": "Array of edge definitions",
                                    "items": {
                                        "type": "object",
                                        "properties": {
                                            "id": {"type": "string"},
                                            "source": {"type": "string"},
                                            "target": {"type": "string"},
                                            "type": {"type": "string", "enum": ["sequential", "conditional_true", "conditional_false", "parallel", "error"]},
                                            "condition": {"type": "string"},
                                            "dataMapping": {"type": "object"}
                                        },
                                        "required": ["id", "source", "target"]
                                    }
                                },
                                "executionType": {"type": "string", "enum": ["sequential", "parallel", "dynamic"], "default": "sequential"},
                                "entryPoint": {"type": "string"},
                                "metadata": {"type": "object"}
                            },
                            "required": ["name", "nodes", "edges"]
                        }
                    },
                    # Tool 52: update_prompt_chain
                    {
                        "name": "update_prompt_chain",
                        "description": "Update existing prompt chain (from AI or UI)",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "chain_id": {"type": "string", "description": "CMC atom ID of chain"},
                                "updates": {
                                    "type": "object",
                                    "description": "Updates to apply",
                                    "properties": {
                                        "name": {"type": "string"},
                                        "description": {"type": "string"},
                                        "nodes": {"type": "array"},
                                        "edges": {"type": "array"},
                                        "executionType": {"type": "string"},
                                        "entryPoint": {"type": "string"},
                                        "metadata": {"type": "object"}
                                    }
                                },
                                "reason": {"type": "string", "description": "Why this update (for history)"},
                                "updated_by": {"type": "string", "description": "Who made the update (ai/user/agent name)"}
                            },
                            "required": ["chain_id", "updates"]
                        }
                    },
                    # Tool 53: get_prompt_chain
                    {
                        "name": "get_prompt_chain",
                        "description": "Retrieve prompt chain definition with optional version. OPTIONAL for retrieving chain details. Use when: loading chain, viewing workflow, checking chain structure. Protocol: prompt_chains.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "chain_id": {"type": "string", "description": "CMC atom ID of chain"},
                                "version": {"type": "integer", "description": "Optional: get specific version"}
                            },
                            "required": ["chain_id"]
                        }
                    },
                    # Tool 54: list_prompt_chains
                    {
                        "name": "list_prompt_chains",
                        "description": "List all prompt chains with optional filtering",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "filters": {
                                    "type": "object",
                                    "properties": {
                                        "tags": {"type": "array", "items": {"type": "string"}},
                                        "category": {"type": "string"},
                                        "isTemplate": {"type": "boolean"},
                                        "createdBy": {"type": "string"}
                                    }
                                },
                                "limit": {"type": "integer", "default": 50}
                            }
                        }
                    },
                    # Tool 55: add_chain_node
                    {
                        "name": "add_chain_node",
                        "description": "Add a single node to existing prompt chain",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "chain_id": {"type": "string"},
                                "node": {"type": "object"},
                                "connectTo": {"type": "array", "items": {"type": "string"}},
                                "connectFrom": {"type": "array", "items": {"type": "string"}}
                            },
                            "required": ["chain_id", "node"]
                        }
                    },
                    # Tool 56: connect_chain_nodes
                    {
                        "name": "connect_chain_nodes",
                        "description": "Create connection between nodes in prompt chain",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "chain_id": {"type": "string"},
                                "source": {"type": "string"},
                                "target": {"type": "string"},
                                "type": {"type": "string", "enum": ["sequential", "conditional_true", "conditional_false", "parallel", "error"], "default": "sequential"},
                                "condition": {"type": "string"},
                                "dataMapping": {"type": "object"}
                            },
                            "required": ["chain_id", "source", "target"]
                        }
                    },
                    # Tool 57: execute_prompt_chain
                    {
                        "name": "execute_prompt_chain",
                        "description": "Execute a prompt chain (delegates to APOE)",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "chain_id": {"type": "string"},
                                "inputs": {"type": "object"},
                                "context": {"type": "object"}
                            },
                            "required": ["chain_id"]
                        }
                    },
                    # Tool 58: get_consciousness_metrics
                    {
                        "name": "get_consciousness_metrics",
                        "description": "Retrieve consciousness observability metrics for the active MCP stack. OPTIONAL for monitoring consciousness health. Use when: health check, monitoring system, observability. Protocol: observability.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {}
                        }
                    },
                    # Tool 59: run_cognitive_audit
                    {
                        "name": "run_cognitive_audit",
                        "description": "Run full cognitive analysis audit using CAS (Cognitive Analysis System)",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "introspection_type": {"type": "string", "enum": ["hourly_check", "task_completion", "failure_analysis", "principle_review", "protocol_validation", "cognitive_load_assessment"], "description": "Type of introspection to perform", "default": "hourly_check"}
                            }
                        }
                    },
                    # Tool 60: analyze_thought_patterns
                    {
                        "name": "analyze_thought_patterns",
                        "description": "Analyze thought patterns for cognitive failure modes using CAS",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "context": {"type": "string", "description": "Context description for analysis"},
                                "task_category": {"type": "string", "description": "Task category being analyzed"},
                                "recent_errors": {"type": "array", "items": {"type": "string"}, "description": "Recent error descriptions"}
                            }
                        }
                    },
                    # Tool 61: detect_cognitive_drift
                    {
                        "name": "detect_cognitive_drift",
                        "description": "Detect cognitive drift and attention narrowing using CAS",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "working_memory_items": {"type": "integer", "description": "Current working memory item count"},
                                "context_size_tokens": {"type": "integer", "description": "Current context size in tokens"},
                                "error_rate": {"type": "number", "description": "Recent error rate (0-1)"}
                            }
                        }
                    },
                    # Tool 62: get_nl_tags
                    {
                        "name": "get_nl_tags",
                        "description": "Get natural language tags for a code file (NL Tags System). OPTIONAL for reviewing code tags. Use when: reviewing tags, checking documentation, code analysis. Protocol: nl_tags.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "file_path": {"type": "string", "description": "Path to code file"}
                            },
                            "required": ["file_path"]
                        }
                    },
                    # Tool 63: get_tag_coverage
                    {
                        "name": "get_tag_coverage",
                        "description": "Get NL tag coverage statistics for codebase or module (NL Tags System). OPTIONAL for monitoring tag coverage quality. Use when: quality check, coverage audit, tag statistics. Protocol: nl_tags.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "module": {"type": "string", "description": "Optional module name to filter by"}
                            }
                        }
                    },
                    # Tool 64: validate_tags
                    {
                        "name": "validate_tags",
                        "description": "Validate NL tags for accuracy and completeness (NL Tags System). MANDATORY before committing code with tags. Use when: code validation, before commit, tag quality check. Protocol: nl_tags.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "file_path": {"type": "string", "description": "Path to code file to validate"}
                            },
                            "required": ["file_path"]
                        }
                    },
                    # Tool 65: get_tag_issues
                    {
                        "name": "get_tag_issues",
                        "description": "Get validation issues (missing/inaccurate tags) for file or codebase (NL Tags System)",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "file_path": {"type": "string", "description": "Optional file path to filter by"}
                            }
                        }
                    },
                    # Tool 66: suggest_tags
                    {
                        "name": "suggest_tags",
                        "description": "Suggest natural language tags for a code block (NL Tags System)",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "code_block": {"type": "string", "description": "Code block to generate tags for"},
                                "language": {"type": "string", "description": "Programming language (python, typescript, etc.)", "default": "unknown"}
                            },
                            "required": ["code_block"]
                        }
                    },
                    # Tool 67: list_terminals
                    {
                        "name": "list_terminals",
                        "description": "List all open terminals in Cursor with details (name, shell type, state). OPTIONAL for terminal management. Use when: managing terminals, checking terminal status. Protocol: cursor_integration.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {}
                        }
                    },
                    # Tool 68: close_terminal
                    {
                        "name": "close_terminal",
                        "description": "Close a terminal in Cursor by name or index (one-click close)",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "terminal_name": {"type": "string", "description": "Name of terminal to close"},
                                "terminal_index": {"type": "integer", "description": "Index of terminal to close"}
                            }
                        }
                    },
                    # Tool 69: manage_terminals
                    {
                        "name": "manage_terminals",
                        "description": "Analyze terminals and provide recommendations for closing unused ones (with one-click close options)",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "threshold": {"type": "integer", "description": "Maximum recommended terminals", "default": 5}
                            }
                        }
                    },
                    # Tool 70: get_problems
                    {
                        "name": "get_problems",
                        "description": "Get all diagnostics/problems from Cursor IDE (errors, warnings, info, hints). OPTIONAL for checking linter errors and warnings. Use when: code quality check, finding errors, linter review. Protocol: cursor_integration.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {}
                        }
                    },
                    # Tool 71: list_diagnostic_sources
                    {
                        "name": "list_diagnostic_sources",
                        "description": "Discover all available diagnostic sources and their capabilities. Returns metadata about each source including available filters, limits, and options. OPTIONAL for discovering linter sources. Use when: exploring diagnostics, checking sources. Protocol: cursor_integration.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {},
                            "required": []
                        }
                    },
                    # Tool 72: list_cursor_commands
                    {
                        "name": "list_cursor_commands",
                        "description": "List all available Cursor commands with metadata and statistics. Phase 1 tool for command discovery. OPTIONAL for discovering available commands. Use when: listing commands, command discovery, workflow exploration. Protocol: cursor_commands.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "scope": {
                                    "type": "string",
                                    "enum": ["project", "global", "team", "all"],
                                    "default": "all",
                                    "description": "Scope of commands to list"
                                },
                                "category": {
                                    "type": "string",
                                    "enum": ["documentation", "development", "system", "memory", "all"],
                                    "description": "Filter by category"
                                },
                                "include_metadata": {
                                    "type": "boolean",
                                    "default": True,
                                    "description": "Include detailed metadata for each command"
                                }
                            }
                        }
                    },
                    # Tool 73: get_cursor_command
                    {
                        "name": "get_cursor_command",
                        "description": "Get full content and metadata of a specific Cursor command. Phase 1 tool for command inspection. OPTIONAL for inspecting command details. Use when: viewing command, understanding workflow, command analysis. Protocol: cursor_commands.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "command_name": {
                                    "type": "string",
                                    "description": "Name of the command (without .md extension)"
                                },
                                "include_usage_stats": {
                                    "type": "boolean",
                                    "default": False,
                                    "description": "Include usage statistics (if available)"
                                }
                            },
                            "required": ["command_name"]
                        }
                    },
                    # Tool 74: validate_cursor_command
                    {
                        "name": "validate_cursor_command",
                        "description": "Validate Cursor command syntax, workflow, and quality. Phase 1 tool for quality assurance.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "command_name": {
                                    "type": "string",
                                    "description": "Name of the command to validate"
                                },
                                "checks": {
                                    "type": "array",
                                    "items": {
                                        "type": "string",
                                        "enum": ["syntax", "workflow", "scripts", "mcp_tools", "examples"]
                                    },
                                    "description": "List of checks to perform (defaults to all)"
                                }
                            },
                            "required": ["command_name"]
                        }
                    },
                    # Tool 75: create_cursor_command
                    {
                        "name": "create_cursor_command",
                        "description": "Create new Cursor command programmatically. Phase 2 tool for command creation.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "name": {
                                    "type": "string",
                                    "description": "Name of the command (without .md extension)"
                                },
                                "content": {
                                    "type": "string",
                                    "description": "Markdown content for the command"
                                },
                                "category": {
                                    "type": "string",
                                    "enum": ["documentation", "development", "system", "memory"],
                                    "description": "Command category (auto-detected if not provided)"
                                },
                                "workflow_steps": {
                                    "type": "array",
                                    "items": {"type": "string"},
                                    "description": "List of workflow steps (optional)"
                                },
                                "mcp_tools": {
                                    "type": "array",
                                    "items": {"type": "string"},
                                    "description": "List of MCP tools used (optional)"
                                },
                                "scripts": {
                                    "type": "array",
                                    "items": {"type": "string"},
                                    "description": "List of scripts referenced (optional)"
                                },
                                "examples": {
                                    "type": "array",
                                    "items": {"type": "string"},
                                    "description": "List of example usage strings (optional)"
                                }
                            },
                            "required": ["name", "content"]
                        }
                    },
                    # Tool 76: update_cursor_command
                    {
                        "name": "update_cursor_command",
                        "description": "Update existing Cursor command. Phase 2 tool for command iteration.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "command_name": {
                                    "type": "string",
                                    "description": "Name of the command to update"
                                },
                                "updates": {
                                    "type": "object",
                                    "description": "Dictionary of updates (content, workflow_steps, add_examples)"
                                },
                                "create_backup": {
                                    "type": "boolean",
                                    "default": True,
                                    "description": "Whether to create backup before updating"
                                }
                            },
                            "required": ["command_name"]
                        }
                    },
                    # Tool 77: execute_cursor_command
                    {
                        "name": "execute_cursor_command",
                        "description": "Execute Cursor command via MCP (meta-circular). Phase 2 tool for command execution.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "command_name": {
                                    "type": "string",
                                    "description": "Name of the command to execute"
                                },
                                "parameters": {
                                    "type": "object",
                                    "description": "Optional parameters to pass to command"
                                },
                                "track_execution": {
                                    "type": "boolean",
                                    "default": True,
                                    "description": "Whether to track execution in timeline"
                                }
                            },
                            "required": ["command_name"]
                        }
                    },
                    # Tool 78: chain_cursor_commands
                    {
                        "name": "chain_cursor_commands",
                        "description": "Execute multiple commands in sequence. Phase 2 tool for workflow automation.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "commands": {
                                    "type": "array",
                                    "items": {
                                        "type": "object",
                                        "properties": {
                                            "name": {"type": "string"},
                                            "params": {"type": "object"}
                                        }
                                    },
                                    "description": "List of commands with 'name' and optional 'params'"
                                },
                                "stop_on_error": {
                                    "type": "boolean",
                                    "default": True,
                                    "description": "Whether to stop chain if command fails"
                                },
                                "track_as_chain": {
                                    "type": "boolean",
                                    "default": True,
                                    "description": "Whether to track as single chain execution"
                                }
                            },
                            "required": ["commands"]
                        }
                    },
                    # Tool 79: generate_cursor_command
                    {
                        "name": "generate_cursor_command",
                        "description": "AI-generated command from workflow description. Phase 2 tool for AI-assisted creation. OPTIONAL for generating command templates from descriptions. Use when: creating commands, AI-assisted generation, rapid command creation. Protocol: cursor_commands.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "description": {
                                    "type": "string",
                                    "description": "Description of what the command should do"
                                },
                                "category": {
                                    "type": "string",
                                    "enum": ["documentation", "development", "system", "memory"],
                                    "description": "Command category (auto-detected if not provided)"
                                },
                                "suggested_name": {
                                    "type": "string",
                                    "description": "Suggested command name (auto-generated if not provided)"
                                },
                                "examples": {
                                    "type": "array",
                                    "items": {"type": "string"},
                                    "description": "Example usage strings"
                                }
                            },
                            "required": ["description"]
                        }
                    },
                    # Tool 80: analyze_cursor_commands
                    {
                        "name": "analyze_cursor_commands",
                        "description": "Analyze command usage and effectiveness. Phase 3 tool for analytics and optimization. OPTIONAL for command analytics and optimization insights. Use when: analyzing commands, optimization, usage patterns. Protocol: cursor_commands.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "scope": {
                                    "type": "string",
                                    "enum": ["all", "project", "global"],
                                    "default": "all",
                                    "description": "Scope of commands to analyze"
                                },
                                "time_range": {
                                    "type": "string",
                                    "enum": ["7d", "30d", "all"],
                                    "description": "Time range for analysis"
                                },
                                "metrics": {
                                    "type": "array",
                                    "items": {
                                        "type": "string",
                                        "enum": ["usage", "time_savings", "success_rate", "popularity"]
                                    },
                                    "description": "List of metrics to include"
                                }
                            }
                        }
                    },
                    # Tool 81: sync_cursor_commands
                    {
                        "name": "sync_cursor_commands",
                        "description": "Sync commands across environments (project  global  team). Phase 3 tool for distribution. OPTIONAL for distributing commands across environments. Use when: sharing commands, backup, distribution. Protocol: cursor_commands.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "source": {
                                    "type": "string",
                                    "enum": ["project", "global", "team"],
                                    "description": "Source environment"
                                },
                                "target": {
                                    "type": "string",
                                    "enum": ["project", "global", "team"],
                                    "description": "Target environment"
                                },
                                "commands": {
                                    "type": "array",
                                    "items": {"type": "string"},
                                    "description": "List of command names to sync (None for all)"
                                },
                                "overwrite": {
                                    "type": "boolean",
                                    "default": False,
                                    "description": "Whether to overwrite existing commands"
                                }
                            },
                            "required": ["source", "target"]
                        }
                    },
                    # Tool 82: call_api
                    {
                        "name": "call_api",
                        "description": "Call an external API (Meshy, ElevenLabs, Minimax, OpenAI, Anthropic, Gemini, DeepSeek, Cerebras, DALL-E, Stable Diffusion, Leonardo AI, Runway ML, Pika Labs, Tavily, Perplexity, NewsAPI) with automatic AIM-OS integration. MANDATORY for calling external APIs. Use when: calling APIs, generating content, accessing external services. Protocols: api_integration, aimos_integration.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "provider": {
                                    "type": "string",
                                    "enum": ["meshy", "elevenlabs", "minimax", "openai", "anthropic", "gemini", "deepseek", "cerebras", "dalle", "stable_diffusion", "leonardo_ai", "runway_ml", "pika_labs", "tavily", "perplexity", "newsapi"],
                                    "description": "API provider name"
                                },
                                "endpoint": {
                                    "type": "string",
                                    "description": "API endpoint (e.g., 'text-to-3d', 'text-to-speech', 'chat-completion')"
                                },
                                "method": {
                                    "type": "string",
                                    "enum": ["GET", "POST", "PUT", "DELETE"],
                                    "default": "POST",
                                    "description": "HTTP method"
                                },
                                "data": {
                                    "type": "object",
                                    "description": "Request data/parameters"
                                },
                                "integrate_aimos": {
                                    "type": "boolean",
                                    "default": True,
                                    "description": "Whether to integrate with AIM-OS systems (CMC, HHNI, VIF, SEG)"
                                }
                            },
                            "required": ["provider", "endpoint"]
                        }
                    },
                    # Tool 83: list_apis
                    {
                        "name": "list_apis",
                        "description": "List all available APIs and their endpoints. MANDATORY for discovering available APIs. Use when: discovering APIs, checking availability, API exploration. Protocol: api_integration.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {}
                        }
                    },
                    # Tool 84: api_status
                    {
                        "name": "api_status",
                        "description": "Get status for a specific API (configured, available, endpoints). OPTIONAL for checking API configuration. Use when: checking API status, verifying configuration, debugging API issues. Protocol: api_integration.",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "provider": {
                                    "type": "string",
                                    "enum": ["meshy", "elevenlabs", "minimax", "openai", "anthropic", "gemini", "deepseek", "cerebras", "dalle", "stable_diffusion", "leonardo_ai", "runway_ml", "pika_labs", "tavily", "perplexity", "newsapi"],
                                    "description": "API provider name"
                                }
                            },
                            "required": ["provider"]
                        }
                    }
                ]
        
        # Use RAG middleware to filter tools if available
        if self.rag_middleware and request:
            return self.rag_middleware.handle_tools_list(request, all_tools, request_id)
        
        # Fallback: return all tools
        return {
            "jsonrpc": "2.0",
            "id": request_id,
            "result": {
                "tools": all_tools
            }
        }
    
    def handle_tools_call(self, request: Dict[str, Any], request_id: Any) -> Dict[str, Any]:
        """Handle tools/call request"""
        params = request.get("params", {})
        tool_name = params.get("name")
        arguments = params.get("arguments", {})
        
        # Add tool call to RAG middleware context for better future filtering
        if self.rag_middleware:
            context_text = f"Tool called: {tool_name} with arguments: {str(arguments)[:200]}"
            self.rag_middleware.add_context(context_text)
        
        # Ensure request_id is never None
        if request_id is None:
            request_id = 0
        
        try:
            if tool_name == "store_memory":
                result = self.store_memory(arguments)
            elif tool_name == "get_memory_stats":
                result = self.get_memory_stats(arguments)
            elif tool_name == "retrieve_memory":
                result = self.retrieve_memory(arguments)
            elif tool_name == "create_plan":
                result = self.create_plan(arguments)
            elif tool_name == "track_confidence":
                result = self.track_confidence(arguments)
            elif tool_name == "synthesize_knowledge":
                result = self.synthesize_knowledge(arguments)
            elif tool_name == "check_invariant":
                result = self.check_invariant(arguments)
            elif tool_name == "run_baseline_probe":
                result = self.run_baseline_probe(arguments)
            elif tool_name == "detect_manipulation_signals":
                result = self.detect_manipulation_signals(arguments)
            elif tool_name == "create_snapshot":
                result = self.create_snapshot(arguments)
            elif tool_name == "restore_snapshot":
                result = self.restore_snapshot(arguments)
            elif tool_name == "list_snapshots":
                result = self.list_snapshots(arguments)
            elif tool_name == "archive_snapshot":
                result = self.archive_snapshot(arguments)
            elif tool_name == "add_timeline_entry":
                result = self.add_timeline_entry(arguments)
            elif tool_name == "get_timeline_summary":
                result = self.get_timeline_summary(arguments)
            elif tool_name == "get_timeline_entries":
                result = self.get_timeline_entries(arguments)
            elif tool_name == "create_goal_timeline_node":
                result = self.create_goal_timeline_node(arguments)
            elif tool_name == "update_goal_progress":
                result = self.update_goal_progress(arguments)
            elif tool_name == "query_goal_timeline":
                result = self.query_goal_timeline(arguments)
            elif tool_name == "compute_intuition":
                result = self.compute_intuition(arguments)
            elif tool_name == "update_intuition_weights":
                result = self.update_intuition_weights(arguments)
            elif tool_name == "get_intuition_trace":
                result = self.get_intuition_trace(arguments)
            elif tool_name == "signal_disagreement":
                result = self.signal_disagreement(arguments)
            elif tool_name == "get_trust_dashboard":
                result = self.get_trust_dashboard(arguments)
            elif tool_name == "request_escalation":
                result = self.request_escalation(arguments)
            elif tool_name == "create_dataset":
                result = self.create_dataset(arguments)
            elif tool_name == "ingest_data":
                result = self.ingest_data(arguments)
            elif tool_name == "query_dataset":
                result = self.query_dataset(arguments)
            elif tool_name == "delete_dataset":
                result = self.delete_dataset(arguments)
            elif tool_name == "create_application":
                result = self.create_application(arguments)
            elif tool_name == "deploy_application":
                result = self.deploy_application(arguments)
            elif tool_name == "manage_application_lifecycle":
                result = self.manage_application_lifecycle(arguments)
            elif tool_name == "start_autonomous_operation":
                result = self.start_autonomous_operation(arguments)
            elif tool_name == "pause_autonomous_operation":
                result = self.pause_autonomous_operation(arguments)
            elif tool_name == "resume_autonomous_operation":
                result = self.resume_autonomous_operation(arguments)
            elif tool_name == "stop_autonomous_operation":
                result = self.stop_autonomous_operation(arguments)
            elif tool_name == "get_autonomous_status":
                result = self.get_autonomous_status(arguments)
            elif tool_name == "run_autonomous_checklist":
                result = self.run_autonomous_checklist(arguments)
            elif tool_name == "fix_autonomous_issues":
                result = self.fix_autonomous_issues(arguments)
            elif tool_name == "should_continue_autonomous":
                result = self.should_continue_autonomous(arguments)
            elif tool_name == "generate_next_autonomous_task":
                result = self.generate_next_autonomous_task(arguments)
            elif tool_name == "conduct_recursive_analysis":
                result = self.conduct_recursive_analysis(arguments)
            elif tool_name == "generate_improvement_dreams":
                result = self.generate_improvement_dreams(arguments)
            elif tool_name == "test_improvement_dream":
                result = self.test_improvement_dream(arguments)
            elif tool_name == "send_ai_message":
                result = self.send_ai_message(arguments)
            elif tool_name == "get_ai_messages":
                result = self.get_ai_messages(arguments)
            elif tool_name == "start_ai_discussion":
                result = self.start_ai_discussion(arguments)
            elif tool_name == "handoff_task_to_ai":
                result = self.handoff_task_to_ai(arguments)
            elif tool_name == "share_ai_profile":
                result = self.share_ai_profile(arguments)
            elif tool_name == "get_ai_collaboration_summary":
                result = self.get_ai_collaboration_summary(arguments)
            elif tool_name == "create_prompt_chain":
                result = self.create_prompt_chain(arguments)
            elif tool_name == "update_prompt_chain":
                result = self.update_prompt_chain(arguments)
            elif tool_name == "get_prompt_chain":
                result = self.get_prompt_chain(arguments)
            elif tool_name == "list_prompt_chains":
                result = self.list_prompt_chains(arguments)
            elif tool_name == "add_chain_node":
                result = self.add_chain_node(arguments)
            elif tool_name == "connect_chain_nodes":
                result = self.connect_chain_nodes(arguments)
            elif tool_name == "execute_prompt_chain":
                result = self.execute_prompt_chain(arguments)
            elif tool_name == "get_consciousness_metrics":
                result = self.get_consciousness_metrics(arguments)
            elif tool_name == "run_cognitive_audit":
                result = self.run_cognitive_audit(arguments)
            elif tool_name == "analyze_thought_patterns":
                result = self.analyze_thought_patterns(arguments)
            elif tool_name == "detect_cognitive_drift":
                result = self.detect_cognitive_drift(arguments)
            elif tool_name == "get_nl_tags":
                result = self.get_nl_tags(arguments)
            elif tool_name == "get_tag_coverage":
                result = self.get_tag_coverage(arguments)
            elif tool_name == "validate_tags":
                result = self.validate_tags(arguments)
            elif tool_name == "get_tag_issues":
                result = self.get_tag_issues(arguments)
            elif tool_name == "suggest_tags":
                result = self.suggest_tags(arguments)
            elif tool_name == "list_terminals":
                result = self.list_terminals(arguments)
            elif tool_name == "close_terminal":
                result = self.close_terminal(arguments)
            elif tool_name == "manage_terminals":
                result = self.manage_terminals(arguments)
            elif tool_name == "get_problems":
                result = self.get_problems(arguments)
            elif tool_name == "get_problem_summary":
                result = self.get_problem_summary(arguments)
            elif tool_name == "get_file_problems":
                result = self.get_file_problems(arguments)
            elif tool_name == "list_output_channels":
                result = self.list_output_channels(arguments)
            elif tool_name == "get_output_channel_logs":
                result = self.get_output_channel_logs(arguments)
            elif tool_name == "refresh_webview":
                result = self.refresh_webview(arguments)
            elif tool_name == "get_electron_logs":
                result = self.get_electron_logs(arguments)
            elif tool_name == "get_unified_diagnostics":
                result = self.get_unified_diagnostics(arguments)
            elif tool_name == "list_diagnostic_sources":
                result = self.list_diagnostic_sources(arguments)
            elif tool_name == "list_cursor_commands":
                result = self.cursor_commands.list_cursor_commands(**arguments)
            elif tool_name == "get_cursor_command":
                result = self.cursor_commands.get_cursor_command(**arguments)
            elif tool_name == "validate_cursor_command":
                result = self.cursor_commands.validate_cursor_command(**arguments)
            elif tool_name == "create_cursor_command":
                result = self.cursor_commands.create_cursor_command(**arguments)
            elif tool_name == "update_cursor_command":
                result = self.cursor_commands.update_cursor_command(**arguments)
            elif tool_name == "execute_cursor_command":
                result = self.cursor_commands.execute_cursor_command(**arguments)
            elif tool_name == "chain_cursor_commands":
                result = self.cursor_commands.chain_cursor_commands(**arguments)
            elif tool_name == "generate_cursor_command":
                result = self.cursor_commands.generate_cursor_command(**arguments)
            elif tool_name == "analyze_cursor_commands":
                result = self.cursor_commands.analyze_cursor_commands(**arguments)
            elif tool_name == "sync_cursor_commands":
                result = self.cursor_commands.sync_cursor_commands(**arguments)
            elif tool_name == "call_api":
                result = self.call_api(arguments)
            elif tool_name == "list_apis":
                result = self.list_apis(arguments)
            elif tool_name == "api_status":
                result = self.api_status(arguments)
            elif tool_name == "deepsearch":
                result = self.deepsearch(arguments)
            elif tool_name == "icip_search":
                result = self.icip_search(arguments)
            else:
                return {
                    "jsonrpc": "2.0",
                    "id": request_id,
                    "error": {
                        "code": -32601,
                        "message": f"Unknown tool: {tool_name}"
                    }
                }
            
            return {
                "jsonrpc": "2.0",
                "id": request_id,
                "result": {
                    "content": [
                        {
                            "type": "text",
                            "text": json.dumps(result, indent=2)
                        }
                    ]
                }
            }
            
        except Exception as e:
            log(f"ERROR in tool {tool_name}: {e}")
            return {
                "jsonrpc": "2.0",
                "id": request_id,
                "error": {
                    "code": -32603,
                    "message": f"Tool execution error: {str(e)}"
                }
            }
    
    # Tool implementations
    def store_memory(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """Store information in AIM-OS persistent memory with full bitemporal support (Phase 1 enhancement)"""
        if not self.memory:
            return {"error": "Memory system not initialized"}
        
        content = args.get("content", "")
        tags = args.get("tags", {})
        modality = args.get("modality", "text")
        metadata = args.get("metadata", {})
        snapshot_id = args.get("snapshot_id")  # Optional snapshot reference for bitemporal linking
        embedding = args.get("embedding")  # Optional embedding vector
        
        # Phase 1 Enhancement: Bitemporal support
        valid_from_str = args.get("valid_from")  # ISO format datetime string
        valid_to_str = args.get("valid_to")  # ISO format datetime string (None = open-ended)
        create_snapshot = args.get("create_snapshot", False)  # Optionally create snapshot after storing
        correlation_id = args.get("correlation_id")  # Optional correlation ID for tracking
        
        if not content:
            return {"error": "Content parameter is required"}
        
        try:
            # Import models locally to avoid import issues
            from cmc_service.models import AtomCreate, AtomContent
            from datetime import datetime, timezone
            
            # Parse bitemporal timestamps if provided
            valid_from = None
            valid_to = None
            if valid_from_str:
                try:
                    valid_from = datetime.fromisoformat(valid_from_str.replace('Z', '+00:00'))
                    if valid_from.tzinfo is None:
                        valid_from = valid_from.replace(tzinfo=timezone.utc)
                except Exception as e:
                    return {"error": f"Invalid valid_from format: {str(e)}. Expected ISO format."}
            
            if valid_to_str:
                try:
                    valid_to = datetime.fromisoformat(valid_to_str.replace('Z', '+00:00'))
                    if valid_to.tzinfo is None:
                        valid_to = valid_to.replace(tzinfo=timezone.utc)
                except Exception as e:
                    return {"error": f"Invalid valid_to format: {str(e)}. Expected ISO format."}
            
            # Ensure metadata is a dict
            enhanced_metadata = dict(metadata) if metadata else {}
            
            # Phase 1 Enhancement: Add bitemporal information to metadata
            if valid_from:
                enhanced_metadata["valid_from"] = valid_from.isoformat()
                enhanced_metadata["bitemporal_enabled"] = True
            if valid_to:
                enhanced_metadata["valid_to"] = valid_to.isoformat()
            elif valid_from and not valid_to:
                # If valid_from provided but valid_to not, mark as open-ended
                enhanced_metadata["valid_to"] = None
                enhanced_metadata["bitemporal_open_ended"] = True
            
            # Add snapshot reference to metadata if provided (bitemporal linking)
            if snapshot_id:
                enhanced_metadata["snapshot_id"] = snapshot_id
                enhanced_metadata["linked_to_snapshot"] = True
            
            # Add correlation ID if provided
            if correlation_id:
                enhanced_metadata["correlation_id"] = correlation_id
            
            # Fix: Convert tags to float values (CMC requires Mapping[str, float])
            # Convert bools to floats (True=1.0, False=0.0), ints to floats, keep floats as-is
            # For strings, convert to hash-based float for backward compatibility
            converted_tags = {}
            for key, value in (tags.items() if tags else {}):
                if isinstance(value, bool):
                    converted_tags[key] = 1.0 if value else 0.0
                elif isinstance(value, (int, float)):
                    converted_tags[key] = float(value)
                elif isinstance(value, str):
                    # Convert string to hash-based float for backward compatibility
                    # Use hash() and normalize to 0.0-1.0 range
                    hash_val = abs(hash(value))
                    converted_tags[key] = float(hash_val % 10000) / 10000.0
                else:
                    # For other types, try to convert to float or use 0.0
                    try:
                        converted_tags[key] = float(value)
                    except (ValueError, TypeError):
                        log(f"Warning: Could not convert tag '{key}' value to float, using 0.0")
                        converted_tags[key] = 0.0
            
            # Create atom with enhanced metadata (bitemporal information stored in metadata)
            atom_create = AtomCreate(
                modality=modality,
                content=AtomContent(inline=content),
                tags=converted_tags,
                metadata=enhanced_metadata,
                embedding=embedding if embedding else None
            )
            
            # Store atom with correlation ID if provided
            atom = self.memory.create_atom(atom_create, correlation_id=correlation_id)
            
            # Phase 1 Enhancement: Optionally create snapshot after storing
            created_snapshot_id = None
            if create_snapshot:
                try:
                    # Create snapshot with current atom
                    snapshot = self.memory.create_snapshot(
                        atom_ids=[atom.id],
                        note=f"Snapshot created after storing atom {atom.id}"
                    )
                    created_snapshot_id = snapshot.id
                    log(f"Created snapshot {created_snapshot_id} for atom {atom.id}")
                except Exception as e:
                    log(f"Warning: Failed to create snapshot: {e}")
            
            # Phase 1 Enhancement: Update HHNI index when new atom is stored
            if self.hhni_index:
                try:
                    doc_id = f"atom_{atom.id}"
                    index_metadata = {
                        "atom_id": atom.id,
                        "modality": atom.modality,
                        "tags": dict(atom.tags),
                        "created_at": atom.created_at.isoformat()
                    }
                    
                    # Include bitemporal information in HHNI metadata
                    if valid_from:
                        index_metadata["valid_from"] = valid_from.isoformat()
                    if valid_to:
                        index_metadata["valid_to"] = valid_to.isoformat()
                    elif valid_from:
                        index_metadata["valid_to"] = None  # Open-ended
                    
                    # Include snapshot reference in HHNI metadata if available
                    if snapshot_id:
                        index_metadata["snapshot_id"] = snapshot_id
                    if created_snapshot_id:
                        index_metadata["snapshot_id"] = created_snapshot_id
                        index_metadata["snapshot_created"] = True
                    
                    self.hhni_index.index_document(content, doc_id, index_metadata)
                    log(f"Indexed new atom {atom.id} in HHNI with bitemporal metadata")
                except Exception as e:
                    log(f"Warning: Failed to index atom {atom.id} in HHNI: {e}")
            
            # Build response with enhanced bitemporal information
            response = {
                "success": True,
                "atom_id": atom.id,
                "modality": atom.modality,
                "created_at": atom.created_at.isoformat(),
                "tags": dict(atom.tags),
                "message": f"Stored memory with ID: {atom.id}"
            }
            
            # Include bitemporal information in response
            if valid_from or valid_to:
                response["bitemporal"] = {
                    "enabled": True,
                    "valid_from": valid_from.isoformat() if valid_from else None,
                    "valid_to": valid_to.isoformat() if valid_to else None,
                    "open_ended": valid_from and not valid_to
                }
                response["message"] += " (bitemporal enabled)"
            
            # Include snapshot info if linked or created
            if snapshot_id:
                response["snapshot_id"] = snapshot_id
                response["bitemporal_linked"] = True
                response["message"] += f" (linked to snapshot: {snapshot_id})"
            elif created_snapshot_id:
                response["snapshot_id"] = created_snapshot_id
                response["snapshot_created"] = True
                response["message"] += f" (snapshot created: {created_snapshot_id})"
            
            # Include embedding info if provided
            if embedding:
                response["embedding_provided"] = True
                response["embedding_dimension"] = len(embedding) if isinstance(embedding, list) else None
            
            # Include correlation ID if provided
            if correlation_id:
                response["correlation_id"] = correlation_id
            
            return response
        except Exception as e:
            return {"error": f"Failed to store memory: {str(e)}"}
    
    def get_memory_stats(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """Get comprehensive statistics about the AIM-OS memory system (Phase 1 enhancement - CMC integration)"""
        if not self.memory:
            return {"error": "Memory system not initialized"}
        
        try:
            # Phase 1 Enhancement: Use real CMC status_summary with comprehensive stats
            status = self.memory.status_summary()
            
            # Get additional statistics from atoms
            try:
                atoms = list(self.memory.list_atoms(limit=10000))
                atom_count = len(atoms)
                
                # Count atoms by modality
                modality_counts = {}
                tag_counts = {}
                bitemporal_enabled_count = 0
                snapshot_linked_count = 0
                
                for atom in atoms:
                    modality = getattr(atom, 'modality', 'unknown')
                    modality_counts[modality] = modality_counts.get(modality, 0) + 1
                    
                    # Count tags
                    tags = getattr(atom, 'tags', {})
                    if isinstance(tags, dict):
                        for tag_key, tag_value in tags.items():
                            tag_key_str = f"{tag_key}:{tag_value}"
                            tag_counts[tag_key_str] = tag_counts.get(tag_key_str, 0) + 1
                    
                    # Check for bitemporal metadata
                    metadata = getattr(atom, 'metadata', {})
                    if isinstance(metadata, dict):
                        if metadata.get("bitemporal_enabled"):
                            bitemporal_enabled_count += 1
                        if metadata.get("snapshot_id") or metadata.get("linked_to_snapshot"):
                            snapshot_linked_count += 1
            except Exception as e:
                log(f"Warning: Could not get detailed atom statistics: {e}")
                atom_count = status.get("atom_count", 0)
                modality_counts = {}
                tag_counts = {}
                bitemporal_enabled_count = 0
                snapshot_linked_count = 0
            
            # Get integrity check if available
            integrity_info = {}
            try:
                integrity_result = self.memory.journal_integrity()
                integrity_info = {
                    "atoms_log_ok": integrity_result.get("atoms_log_ok", True),
                    "snapshots_log_ok": integrity_result.get("snapshots_log_ok", True),
                    "overall_ok": integrity_result.get("atoms_log_ok", True) and integrity_result.get("snapshots_log_ok", True)
                }
            except Exception as e:
                log(f"Warning: Could not get integrity check: {e}")
                integrity_info = {"overall_ok": "unknown"}
            
            # Get HHNI index statistics if available
            hhni_stats = {}
            if self.hhni_retriever:
                try:
                    # Enhanced stats with TwoStageRetriever info
                    hhni_stats = {
                        "retriever_type": "two_stage_with_dvns",
                        "retriever_available": True,
                        "config": {
                            "token_budget": getattr(self.hhni_retriever.config, 'token_budget', None),
                            "dvns_iterations": getattr(self.hhni_retriever.config, 'dvns_iterations', None),
                            "enable_conflict_resolution": getattr(self.hhni_retriever.config, 'enable_conflict_resolution', None),
                            "enable_compression": getattr(self.hhni_retriever.config, 'enable_compression', None)
                        }
                    }
                    if self.hhni_index:
                        hhni_stats["indexed_nodes"] = len(self.hhni_index.nodes) if hasattr(self.hhni_index, 'nodes') else 0
                except Exception as e:
                    log(f"Warning: Could not get HHNI retriever stats: {e}")
                    hhni_stats = {"retriever_available": False}
            elif self.hhni_index:
                try:
                    hhni_stats = {
                        "indexed_nodes": len(self.hhni_index.nodes) if hasattr(self.hhni_index, 'nodes') else 0,
                        "index_available": True,
                        "retriever_type": "basic_hierarchical_index"
                    }
                except Exception:
                    hhni_stats = {"index_available": False}
            else:
                hhni_stats = {"index_available": False, "retriever_available": False}
            
            # Get VIF statistics if available
            vif_stats = {}
            if self.vif_kappa_gate and self.vif_ece_tracker:
                try:
                    vif_stats = {
                        "kappa_gate_available": True,
                        "ece_tracker_available": True,
                        "kappa_gate_thresholds": {
                            criticality.value: threshold 
                            for criticality, threshold in self.vif_kappa_gate.thresholds.items()
                        } if hasattr(self.vif_kappa_gate, 'thresholds') else {},
                        "ece_calibration": {
                            "num_bins": self.vif_ece_tracker.num_bins,
                            "total_predictions": sum(bin.count for bin in self.vif_ece_tracker.bins) if hasattr(self.vif_ece_tracker, 'bins') else 0,
                            "current_ece": self.vif_ece_tracker.calculate_ece() if hasattr(self.vif_ece_tracker, 'bins') and self.vif_ece_tracker.bins else None
                        }
                    }
                except Exception as e:
                    log(f"Warning: Could not get VIF stats: {e}")
                    vif_stats = {"kappa_gate_available": False, "ece_tracker_available": False}
            else:
                vif_stats = {
                    "kappa_gate_available": self.vif_kappa_gate is not None,
                    "ece_tracker_available": self.vif_ece_tracker is not None
                }
            
            # Get snapshot statistics
            snapshot_stats = {}
            try:
                latest_snapshot_id = status.get("latest_snapshot_id")
                latest_snapshot_time = status.get("latest_snapshot_time")
                snapshot_count = status.get("snapshot_count", 0)
                
                snapshot_stats = {
                    "total_snapshots": snapshot_count,
                    "latest_snapshot_id": latest_snapshot_id,
                    "latest_snapshot_time": latest_snapshot_time,
                    "snapshot_duration_ms": status.get("snapshot_duration_ms", []),
                    "avg_snapshot_duration_ms": sum(status.get("snapshot_duration_ms", [])) / len(status.get("snapshot_duration_ms", [1])) if status.get("snapshot_duration_ms") else None
                }
            except Exception as e:
                log(f"Warning: Could not get snapshot stats: {e}")
                snapshot_stats = {"total_snapshots": status.get("snapshot_count", 0)}
            
            # Build comprehensive response
            response = {
                "success": True,
                "stats": {
                    # Core CMC statistics
                    "total_atoms": status.get("atom_count", atom_count),
                    "total_snapshots": snapshot_stats.get("total_snapshots", 0),
                    "memory_directory": self.memory_directory,
                    "status": "operational",
                    "backend": status.get("backend", "unknown"),
                    
                    # CMC counters and metrics
                    "counters": status.get("counters", {}),
                    "snapshot_stats": snapshot_stats,
                    
                    # Integrity information
                    "integrity": integrity_info,
                    
                    # Modality and tag analysis
                    "modality_counts": modality_counts,
                    "top_tags": dict(sorted(tag_counts.items(), key=lambda x: x[1], reverse=True)[:10]),
                    
                    # Bitemporal statistics
                    "bitemporal": {
                        "enabled_atoms": bitemporal_enabled_count,
                        "snapshot_linked_atoms": snapshot_linked_count,
                        "bitemporal_percentage": (bitemporal_enabled_count / atom_count * 100) if atom_count > 0 else 0
                    },
                    
                    # HHNI statistics
                    "hhni": hhni_stats,
                    
                    # VIF statistics
                    "vif": vif_stats,
                    
                    # Timestamp
                    "timestamp": datetime.now().isoformat()
                }
            }
            
            return response
        except Exception as e:
            return {"error": f"Failed to get memory stats: {str(e)}"}
    
    def _build_hhni_index(self):
        """Build HHNI index from CMC atoms (Phase 1 enhancement)"""
        if not self.memory or not self.hhni_index:
            return
        
        try:
            # Get all atoms from CMC
            atoms = list(self.memory.list_atoms(limit=1000))
            
            if not atoms:
                log("No atoms found to index in HHNI")
                return
            
            # Index each atom as a document in HHNI
            indexed_count = 0
            for atom in atoms:
                try:
                    # Extract content from atom
                    content = ""
                    if hasattr(atom, 'content') and atom.content:
                        if hasattr(atom.content, 'inline'):
                            content = atom.content.inline
                        elif isinstance(atom.content, str):
                            content = atom.content
                    
                    if not content:
                        continue
                    
                    # Create document ID from atom ID
                    doc_id = f"atom_{atom.id}"
                    
                    # Create metadata with atom information
                    metadata = {
                        "atom_id": atom.id,
                        "modality": getattr(atom, 'modality', 'text'),
                        "tags": dict(getattr(atom, 'tags', {})),
                        "created_at": getattr(atom, 'created_at', datetime.now()).isoformat() if hasattr(atom, 'created_at') else datetime.now().isoformat()
                    }
                    
                    # Index document in HHNI
                    self.hhni_index.index_document(content, doc_id, metadata)
                    indexed_count += 1
                    
                except Exception as e:
                    log(f"Warning: Failed to index atom {atom.id}: {e}")
                    continue
            
            log(f"HHNI index built: {indexed_count} atoms indexed")
            
        except Exception as e:
            log(f"Error building HHNI index: {e}")
    
    def retrieve_memory(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """Search and retrieve memories from AIM-OS using HHNI TwoStageRetriever with DVNS physics (Phase 1 enhancement)"""
        if not self.memory:
            return {"error": "Memory system not initialized"}
        
        query = args.get("query", "")
        limit = args.get("limit", 10)
        tags = args.get("tags", {})
        token_budget = args.get("token_budget", 4000)  # Optional token budget override
        include_rs_lift = args.get("include_rs_lift", False)  # Optional RS-Lift calculation
        
        if not query:
            return {"error": "Query parameter is required"}
        
        try:
            # Phase 1 Enhancement: Use HHNI TwoStageRetriever with full DVNS physics pipeline
            if self.hhni_retriever:
                try:
                    # Use TwoStageRetriever with DVNS physics optimization
                    if include_rs_lift:
                        # Retrieve with baseline comparison for RS-Lift metric
                        dvns_result, baseline_result, rs_lift = self.hhni_retriever.retrieve_with_baseline_comparison(
                            query=query,
                            token_budget=token_budget,
                            target_level=IndexLevel.PARAGRAPH
                        )
                        result = dvns_result
                    else:
                        # Standard retrieval with DVNS optimization
                        result = self.hhni_retriever.retrieve(
                            query=query,
                            token_budget=token_budget,
                            target_level=IndexLevel.PARAGRAPH
                        )
                    
                    if not result.selected_items:
                        return {
                            "success": True,
                            "query": query,
                            "results": [],
                            "count": 0,
                            "method": "hhni_two_stage_with_dvns",
                            "message": f"No memories found for query: '{query}'",
                            "coarse_candidates": result.coarse_candidates,
                            "dvns_iterations": result.dvns_iterations,
                            "rs_lift": result.rs_lift if include_rs_lift else None
                        }
                    
                    # Format TwoStageRetriever results
                    matching_atoms = []
                    for item in result.selected_items[:limit]:  # Apply limit
                        node = item.node
                        # Extract atom metadata from node metadata
                        atom_metadata = node.metadata or {}
                        atom_id = atom_metadata.get("atom_id", node.id)
                        
                        matching_atoms.append({
                            "id": atom_id,
                            "content": node.content or node.summary or "",
                            "tags": atom_metadata.get("tags", {}),
                            "created_at": atom_metadata.get("created_at", datetime.now().isoformat()),
                            "relevance_score": item.score,
                            "node_id": node.id,
                            "node_level": node.level.name if hasattr(node.level, 'name') else str(node.level),
                            "dvns_mass": item.metadata.get("dvns_mass") if item.metadata else None,
                            "dvns_position": item.metadata.get("dvns_position") if item.metadata else None
                        })
                    
                    response = {
                        "success": True,
                        "query": query,
                        "results": matching_atoms,
                        "count": len(matching_atoms),
                        "method": "hhni_two_stage_with_dvns",
                        "message": f"Retrieved {len(matching_atoms)} memories using HHNI TwoStageRetriever with DVNS physics",
                        "metrics": {
                            "total_tokens": result.total_tokens,
                            "token_budget": token_budget,
                            "efficiency": result.efficiency,
                            "relevance_score": result.relevance_score,
                            "coarse_candidates": result.coarse_candidates,
                            "coarse_time_ms": result.coarse_time_ms,
                            "dvns_iterations": result.dvns_iterations,
                            "dvns_converged": result.dvns_converged,
                            "dvns_time_ms": result.dvns_time_ms,
                            "excluded_count": result.excluded_count,
                            "conflicts_detected": result.conflicts_detected,
                            "conflicts_resolved": result.conflicts_resolved,
                            "compression_applied": result.compression_applied,
                            "tokens_saved_by_compression": result.tokens_saved_by_compression,
                            "compression_ratio": result.compression_ratio
                        }
                    }
                    
                    # Add RS-Lift if calculated
                    if include_rs_lift and result.rs_lift is not None:
                        response["rs_lift"] = result.rs_lift
                        response["message"] += f" (RS-Lift: {result.rs_lift:.2%})"
                    
                    return response
                    
                except Exception as e:
                    log(f"HHNI TwoStageRetriever failed, falling back to simple search: {e}")
                    # Fall through to simple search
            elif self.hhni_index:
                # Fallback to basic HHNI query if TwoStageRetriever not available
                try:
                    results = self.hhni_index.query(
                        query=query,
                        target_level=IndexLevel.PARAGRAPH,
                        max_results=limit
                    )
                    
                    if not results:
                        return {
                            "success": True,
                            "query": query,
                            "results": [],
                            "count": 0,
                            "method": "hhni_basic_query",
                            "message": f"No memories found for query: '{query}'"
                        }
                    
                    # Format HHNI results
                    matching_atoms = []
                    for node in results:
                        atom_metadata = node.metadata or {}
                        atom_id = atom_metadata.get("atom_id", node.id)
                        
                        matching_atoms.append({
                            "id": atom_id,
                            "content": node.content or node.summary or "",
                            "tags": atom_metadata.get("tags", {}),
                            "created_at": atom_metadata.get("created_at", datetime.now().isoformat()),
                            "relevance_score": getattr(node, 'relevance_score', None),
                            "node_id": node.id,
                            "node_level": node.level.name if hasattr(node.level, 'name') else str(node.level)
                        })
                    
                    return {
                        "success": True,
                        "query": query,
                        "results": matching_atoms,
                        "count": len(matching_atoms),
                        "method": "hhni_basic_query",
                        "message": f"Retrieved {len(matching_atoms)} memories using HHNI basic query"
                    }
                    
                except Exception as e:
                    log(f"HHNI basic query failed, falling back to simple search: {e}")
                    # Fall through to simple search
            
            # Fallback: Simple text search if HHNI unavailable
            atoms = list(self.memory.list_atoms(limit=1000))
            matching_atoms = []
            
            for atom in atoms:
                try:
                    content = ""
                    if hasattr(atom, 'content') and atom.content:
                        if hasattr(atom.content, 'inline'):
                            content = atom.content.inline
                        elif isinstance(atom.content, str):
                            content = atom.content
                    
                    if query.lower() in content.lower():
                        matching_atoms.append({
                            "id": atom.id,
                            "content": content,
                            "tags": dict(getattr(atom, 'tags', {})),
                            "created_at": getattr(atom, 'created_at', datetime.now()).isoformat() if hasattr(atom, 'created_at') else datetime.now().isoformat()
                        })
                except Exception as e:
                    log(f"Error processing atom {atom.id}: {e}")
                    continue
            
            # Apply limit
            matching_atoms = matching_atoms[:limit]
            
            return {
                "success": True,
                "query": query,
                "results": matching_atoms,
                "count": len(matching_atoms),
                "method": "simple_text_search",
                "message": f"Retrieved {len(matching_atoms)} memories using simple text search"
            }
            
        except Exception as e:
            return {"error": f"Failed to retrieve memory: {str(e)}"}
    
    def create_plan(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """Create an execution plan using APOE (AI-Powered Orchestration Engine) - Phase 1 enhancement"""
        goal = args.get("goal", "")
        context = args.get("context", "")
        priority = args.get("priority", "medium")
        acl_text = args.get("acl_text")  # Optional ACL source code
        execute = args.get("execute", False)  # Optional execution flag
        store_in_cmc = args.get("store_in_cmc", True)  # Optional CMC storage flag
        
        if not goal and not acl_text:
            return {"error": "Either 'goal' or 'acl_text' parameter is required"}
        
        try:
            # Phase 1 Enhancement: Import APOE modules
            try:
                from apoe.acl_parser import ACLParser, ExecutionPlan
                from apoe.models import Step, StepStatus, Budget, RoleType
                from apoe.executor import PlanExecutor, ExecutionResult
            except ImportError as e:
                log(f"Warning: APOE modules not available: {e}")
                # Fallback to simple plan if APOE not available
                return self._create_simple_plan_fallback(goal, context, priority)
            
            execution_plan = None
            plan_id = str(uuid.uuid4())
            
            # Phase 1: ACL Parsing Support
            if acl_text:
                try:
                    parser = ACLParser()
                    execution_plan = parser.parse(acl_text)
                    log(f"Parsed ACL plan: {execution_plan.name}")
                except ValueError as e:
                    return {"error": f"ACL parse error: {str(e)}"}
                except Exception as e:
                    return {"error": f"Failed to parse ACL: {str(e)}"}
            
            # Phase 2: Goal-to-Plan Generation
            else:
                execution_plan = self._generate_plan_from_goal(
                    goal=goal,
                    context=context,
                    priority=priority,
                    plan_name=f"plan_{plan_id[:8]}"
                )
                log(f"Generated plan from goal: {execution_plan.name}")
            
            # Convert ExecutionPlan to dict
            plan_dict = self._plan_to_dict(execution_plan, goal, context, priority)
            
            # Phase 3: Execution Support
            execution_result = None
            if execute:
                try:
                    executor = PlanExecutor()
                    # Note: Execution requires role handlers to be registered
                    # For now, we'll execute but handlers may not be available
                    result = executor.execute(execution_plan)
                    execution_result = self._result_to_dict(result)
                    log(f"Plan executed: {execution_plan.name}, success: {result.success}")
                except Exception as e:
                    log(f"Warning: Plan execution failed: {e}")
                    execution_result = {"error": str(e)}
            
            # Phase 4: CMC Persistence
            atom_id = None
            if store_in_cmc and self.memory:
                try:
                    from cmc_service.models import AtomCreate, AtomContent
                    
                    atom_create = AtomCreate(
                        modality="plan",
                        content=AtomContent(inline=json.dumps(plan_dict)),
                        tags={
                            "type": "execution_plan",
                            "priority": priority,
                            "plan_id": plan_id
                        },
                        metadata={
                            "plan_id": plan_id,
                            "goal": goal,
                            "context": context,
                            "priority": priority,
                            "plan_name": execution_plan.name,
                            "step_count": len(execution_plan.steps),
                            "created_at": datetime.now().isoformat(),
                            "executed": execute
                        }
                    )
                    atom = self.memory.create_atom(atom_create)
                    atom_id = atom.id
                    log(f"Stored plan in CMC: atom {atom_id}")
                except Exception as e:
                    log(f"Warning: Failed to store plan in CMC: {e}")
            
            # Build response
            response = {
                "success": True,
                "plan": plan_dict,
                "plan_id": plan_id,
                "message": f"Created execution plan '{execution_plan.name}'"
            }
            
            if atom_id:
                response["atom_id"] = atom_id
            
            if execution_result:
                response["execution_result"] = execution_result
            
            return response
            
        except Exception as e:
            log(f"Error in create_plan: {e}")
            return {"error": f"Failed to create plan: {str(e)}"}
    
    def _create_simple_plan_fallback(self, goal: str, context: str, priority: str) -> Dict[str, Any]:
        """Fallback simple plan creation if APOE not available"""
        plan = {
            "goal": goal,
            "context": context,
            "priority": priority,
            "steps": [
                {
                    "id": "step_1",
                    "description": f"Analyze goal: {goal}",
                    "status": "pending"
                },
                {
                    "id": "step_2", 
                    "description": f"Execute plan for: {goal}",
                    "status": "pending"
                },
                {
                    "id": "step_3",
                    "description": f"Validate results for: {goal}",
                    "status": "pending"
                }
            ],
            "created_at": datetime.now().isoformat()
        }
        
        return {
            "success": True,
            "plan": plan,
            "message": f"Created simple execution plan for: {goal}",
            "note": "APOE not available - using fallback implementation"
        }
    
    def _generate_plan_from_goal(self, goal: str, context: str, priority: str, plan_name: str):
        """Generate ExecutionPlan from goal description"""
        from apoe.models import Step, StepStatus, Budget, RoleType
        from apoe.acl_parser import ExecutionPlan, RoleConfig
        
        # Analyze goal complexity
        complexity = self._analyze_goal_complexity(goal)
        num_steps = min(max(complexity, 3), 5)  # 3-5 steps
        
        # Determine roles needed
        roles_needed = self._assign_roles_for_goal(goal)
        
        # Create roles
        roles = {}
        for role_type in roles_needed:
            role_name = role_type.value.lower()
            roles[role_name] = RoleConfig(
                name=role_name,
                model_type="llm",
                params={}
            )
        
        # Create steps
        steps = []
        dependencies = {}
        
        # Step 1: Analyze/Plan
        step1 = Step(
            id="step_1",
            name="analyze_goal",
            role=RoleType.PLANNER if RoleType.PLANNER in roles_needed else RoleType.OPERATOR,
            role_name="planner" if RoleType.PLANNER in roles_needed else "operator",
            description=f"Analyze and understand goal: {goal}",
            status=StepStatus.PENDING,
            budget=Budget(tokens_limit=5000, time_limit_seconds=60)
        )
        steps.append(step1)
        dependencies["step_1"] = []
        
        # Step 2: Execute (if multiple steps)
        if num_steps >= 4:
            step2 = Step(
                id="step_2",
                name="prepare_execution",
                role=RoleType.BUILDER if RoleType.BUILDER in roles_needed else RoleType.OPERATOR,
                role_name="builder" if RoleType.BUILDER in roles_needed else "operator",
                description=f"Prepare execution plan for: {goal}",
                status=StepStatus.PENDING,
                budget=Budget(tokens_limit=10000, time_limit_seconds=300)
            )
            steps.append(step2)
            dependencies["step_2"] = ["step_1"]
        
        # Main execution step
        exec_step_id = f"step_{len(steps) + 1}"
        exec_step = Step(
            id=exec_step_id,
            name="execute",
            role=RoleType.BUILDER if RoleType.BUILDER in roles_needed else RoleType.OPERATOR,
            role_name="builder" if RoleType.BUILDER in roles_needed else "operator",
            description=f"Execute plan to achieve: {goal}",
            status=StepStatus.PENDING,
            budget=Budget(tokens_limit=20000, time_limit_seconds=600)
        )
        steps.append(exec_step)
        prev_deps = [deps[0] for deps in dependencies.values() if deps] if dependencies else ["step_1"]
        dependencies[exec_step_id] = prev_deps if len(prev_deps) > 0 else []
        
        # Verification step
        verify_step_id = f"step_{len(steps) + 1}"
        verify_step = Step(
            id=verify_step_id,
            name="verify",
            role=RoleType.VERIFIER if RoleType.VERIFIER in roles_needed else RoleType.OPERATOR,
            role_name="verifier" if RoleType.VERIFIER in roles_needed else "operator",
            description=f"Verify results for: {goal}",
            status=StepStatus.PENDING,
            budget=Budget(tokens_limit=5000, time_limit_seconds=120)
        )
        steps.append(verify_step)
        dependencies[verify_step_id] = [exec_step_id]
        
        # Create ExecutionPlan
        execution_plan = ExecutionPlan(
            name=plan_name,
            roles=roles,
            steps=steps,
            gates=[],
            dependencies=dependencies
        )
        
        return execution_plan
    
    def _analyze_goal_complexity(self, goal: str) -> int:
        """Analyze goal to determine complexity (returns 3-5)"""
        goal_lower = goal.lower()
        
        # Simple keywords suggest simple tasks
        simple_keywords = ["check", "get", "read", "list", "show", "display"]
        # Complex keywords suggest complex tasks
        complex_keywords = ["implement", "build", "create", "design", "develop", "integrate", "orchestrate"]
        
        simple_count = sum(1 for kw in simple_keywords if kw in goal_lower)
        complex_count = sum(1 for kw in complex_keywords if kw in goal_lower)
        
        # Count words as complexity indicator
        word_count = len(goal.split())
        
        if complex_count > 0 or word_count > 20:
            return 5
        elif simple_count > 0 or word_count < 10:
            return 3
        else:
            return 4
    
    def _assign_roles_for_goal(self, goal: str) -> List:
        """Determine which roles are needed based on goal keywords"""
        from apoe.models import RoleType
        
        goal_lower = goal.lower()
        roles = []
        
        # Planning keywords
        if any(kw in goal_lower for kw in ["plan", "design", "strategy", "analyze"]):
            roles.append(RoleType.PLANNER)
        
        # Building keywords
        if any(kw in goal_lower for kw in ["build", "create", "implement", "develop", "write", "code"]):
            roles.append(RoleType.BUILDER)
        
        # Verification keywords
        if any(kw in goal_lower for kw in ["verify", "validate", "test", "check", "review"]):
            roles.append(RoleType.VERIFIER)
        
        # Retrieval keywords
        if any(kw in goal_lower for kw in ["find", "search", "retrieve", "get", "fetch"]):
            roles.append(RoleType.RETRIEVER)
        
        # Default to OPERATOR if no specific roles identified
        if not roles:
            roles.append(RoleType.OPERATOR)
        
        return roles
    
    def _plan_to_dict(self, execution_plan, goal: str = "", context: str = "", priority: str = "medium") -> Dict[str, Any]:
        """Convert ExecutionPlan to JSON-serializable dict"""
        plan_dict = {
            "name": execution_plan.name,
            "goal": goal,
            "context": context,
            "priority": priority,
            "roles": {
                role_name: {
                    "name": role.name,
                    "model_type": role.model_type,
                    "params": role.params
                }
                for role_name, role in execution_plan.roles.items()
            },
            "steps": [
                {
                    "id": step.id,
                    "name": step.name,
                    "role": step.role.value if step.role else None,
                    "role_name": step.role_name,
                    "description": step.description,
                    "status": step.status.value if step.status else None,
                    "budget": {
                        "tokens_limit": step.budget.tokens_limit if step.budget else None,
                        "time_limit_seconds": step.budget.time_limit_seconds if step.budget else None
                    } if step.budget else None,
                    "gates": [
                        {
                            "id": gate.id,
                            "name": gate.name,
                            "gate_type": gate.gate_type,
                            "condition": gate.condition
                        }
                        for gate in step.gates
                    ]
                }
                for step in execution_plan.steps
            ],
            "dependencies": execution_plan.dependencies,
            "gates": [
                {
                    "id": gate.id,
                    "name": gate.name,
                    "gate_type": gate.gate_type,
                    "condition": gate.condition
                }
                for gate in execution_plan.gates
            ],
            "created_at": datetime.now().isoformat()
        }
        
        return plan_dict
    
    def _result_to_dict(self, result: 'ExecutionResult') -> Dict[str, Any]:
        """Convert ExecutionResult to JSON-serializable dict"""
        return {
            "plan_name": result.plan_name,
            "total_steps": result.total_steps,
            "completed_steps": result.completed_steps,
            "failed_steps": result.failed_steps,
            "skipped_steps": result.skipped_steps,
            "total_duration_seconds": result.total_duration_seconds,
            "success": result.success,
            "error": result.error,
            "completion_rate": result.completion_rate()
        }
    
    def track_confidence(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """Track confidence and provenance using VIF (Verifiable Intelligence Framework) - Phase 1 enhancement"""
        task = args.get("task", "")
        
        # Validate confidence parameter with graceful error handling
        confidence_value = args.get("confidence", 0.0)
        try:
            confidence = float(confidence_value)
            # Validate confidence is in valid range [0.0, 1.0]
            if confidence < 0.0 or confidence > 1.0:
                return {"error": f"Confidence must be between 0.0 and 1.0, got {confidence}"}
        except (ValueError, TypeError):
            return {"error": f"Invalid confidence value: {confidence_value}. Expected a number between 0.0 and 1.0"}
        
        reasoning = args.get("reasoning", "")
        evidence = args.get("evidence", [])
        decision_id = args.get("decision_id")
        task_criticality_str = args.get("task_criticality", "ROUTINE").upper()
        model_id = args.get("model_id", "mcp-tool")
        model_provider = args.get("model_provider", "aim-os")
        prompt = args.get("prompt", f"Task: {task}")
        output = args.get("output", f"Confidence: {confidence}")
        context_snapshot_id = args.get("context_snapshot_id")  # Optional CMC snapshot
        actual_outcome = args.get("actual_outcome")  # Optional: True/False for ECE tracking
        
        # Validate task parameter type and presence
        if not task:
            return {"error": "Task parameter is required"}
        if not isinstance(task, str):
            try:
                task = str(task)  # Convert to string if possible
            except Exception:
                return {"error": f"Task parameter must be a string, got {type(task).__name__}"}
        
        try:
            # Phase 1 Enhancement: Use real VIF witness creation, ECE tracking, and -gating
            if self.vif_kappa_gate and self.vif_ece_tracker:
                try:
                    # Map task_criticality string to enum
                    criticality_map = {
                        "CRITICAL": TaskCriticality.CRITICAL,
                        "IMPORTANT": TaskCriticality.IMPORTANT,
                        "ROUTINE": TaskCriticality.ROUTINE,
                        "LOW_STAKES": TaskCriticality.LOW_STAKES
                    }
                    criticality_enum = criticality_map.get(task_criticality_str, TaskCriticality.ROUTINE)
                    
                    # Get  threshold for this criticality
                    kappa_threshold = self.vif_kappa_gate.thresholds.get(criticality_enum, 0.70)
                    
                    # Check -gate (behavioral abstention)
                    gate_result = self.vif_kappa_gate.check(
                        confidence=confidence,
                        task_criticality=criticality_enum
                    )
                    
                    # Create VIF witness
                    witness = VIF(
                        model_id=model_id,
                        model_provider=model_provider,
                        context_snapshot_id=context_snapshot_id or "none",
                        prompt_hash=VIF.hash_text(prompt),
                        prompt_tokens=len(prompt.split()),  # Rough estimate
                        confidence_score=confidence,
                        confidence_band=ConfidenceBand.A if confidence >= 0.90 else ConfidenceBand.B if confidence >= 0.70 else ConfidenceBand.C,
                        output_hash=VIF.hash_text(output),
                        output_tokens=len(output.split()),  # Rough estimate
                        total_tokens=len(prompt.split()) + len(output.split()),
                        task_criticality=criticality_enum,
                        kappa_threshold=kappa_threshold,
                        kappa_gate_passed=gate_result.passed,
                        writer="mcp-tool"
                    )
                    
                    # Track ECE if actual outcome provided
                    ece_tracked = False
                    if actual_outcome is not None:
                        self.vif_ece_tracker.add_prediction(
                            confidence=confidence,
                            correct=bool(actual_outcome)
                        )
                        ece_tracked = True
                        current_ece = self.vif_ece_tracker.calculate_ece()
                        witness.ece_score = current_ece
                    else:
                        current_ece = self.vif_ece_tracker.calculate_ece() if self.vif_ece_tracker.bins else None
                    
                    # Store witness in CMC if available
                    witness_atom_id = None
                    if self.memory:
                        try:
                            from vif.cmc_integration import VIFStore
                            vif_store = VIFStore(self.memory)
                            witness_atom_id = vif_store.store_witness(witness, correlation_id=decision_id)
                        except Exception as e:
                            log(f"Warning: Failed to store witness in CMC: {e}")
                    
                    # Maintain backward compatibility with existing confidence_history
                    confidence_record = {
                        "task": task,
                        "confidence": confidence,
                        "reasoning": reasoning,
                        "evidence": evidence,
                        "timestamp": datetime.now().isoformat(),
                        "status": "high" if confidence >= 0.8 else "medium" if confidence >= 0.5 else "low",
                        "decision_id": decision_id,
                        "witness_id": witness.id,
                        "kappa_gate_passed": gate_result.passed,
                        "confidence_band": witness.confidence_band.value
                    }
                    
                    self.confidence_history.append(confidence_record)
                    if decision_id:
                        trace = self.intuition_traces.setdefault(decision_id, [])
                        trace.append({
                            "type": "confidence",
                            "timestamp": confidence_record["timestamp"],
                            "confidence": confidence,
                            "status": confidence_record["status"],
                            "task": task,
                            "witness_id": witness.id,
                            "kappa_gate_passed": gate_result.passed
                        })
                    self._save_intuition_store()
                    self._update_consciousness_metrics()
                    
                    return {
                        "success": True,
                        "witness_id": witness.id,
                        "confidence": confidence,
                        "confidence_band": witness.confidence_band.value,
                        "kappa_gate_passed": gate_result.passed,
                        "kappa_gate_threshold": kappa_threshold,
                        "kappa_gate_gap": gate_result.gap,
                        "kappa_gate_margin": gate_result.margin,
                        "should_escalate": gate_result.should_escalate,
                        "escalation_reason": gate_result.escalation_reason,
                        "task_criticality": task_criticality_str,
                        "ece_tracked": ece_tracked,
                        "current_ece": current_ece,
                        "witness_atom_id": witness_atom_id,
                        "confidence_record": confidence_record,
                        "message": f"Tracked confidence for task: {task} (witness: {witness.id}, -gate: {'PASSED' if gate_result.passed else 'FAILED'})"
                    }
                    
                except Exception as e:
                    log(f"VIF tracking failed, falling back to simple tracking: {e}")
                    # Fall through to simple tracking
            
            # Fallback: Simple confidence tracking if VIF unavailable
            confidence_record = {
                "task": task,
                "confidence": confidence,
                "reasoning": reasoning,
                "evidence": evidence,
                "timestamp": datetime.now().isoformat(),
                "status": "high" if confidence >= 0.8 else "medium" if confidence >= 0.5 else "low",
                "decision_id": decision_id,
            }

            self.confidence_history.append(confidence_record)
            if decision_id:
                trace = self.intuition_traces.setdefault(decision_id, [])
                trace.append({
                    "type": "confidence",
                    "timestamp": confidence_record["timestamp"],
                    "confidence": confidence,
                    "status": confidence_record["status"],
                    "task": task,
                })
            self._save_intuition_store()
            self._update_consciousness_metrics()
            
            return {
                "success": True,
                "confidence_record": confidence_record,
                "message": f"Tracked confidence for task: {task} (simple tracking - VIF unavailable)"
            }
        except Exception as e:
            return {"error": f"Failed to track confidence: {str(e)}"}
    
    def synthesize_knowledge(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """Synthesize knowledge using SEG (Shared Evidence Graph) - Phase 1 enhancement"""
        topics = args.get("topics", [])
        depth = args.get("depth", "medium")
        format_type = args.get("format", "summary")
        
        if not topics:
            return {"error": "At least one topic is required"}
        
        try:
            # Phase 1 Enhancement: Use real SEG graph for synthesis
            if not self.seg_graph:
                # Fallback if SEG not available
                return {
                    "success": True,
                    "synthesis": {
                        "topics": topics,
                        "depth": depth,
                        "format": format_type,
                        "synthesis": f"Knowledge synthesis for topics: {', '.join(topics)}",
                        "insights": [
                            f"Topic {topic} has been analyzed at {depth} depth" for topic in topics
                        ],
                        "created_at": datetime.now().isoformat(),
                        "note": "SEG graph not available - using fallback"
                    },
                    "message": f"Synthesized knowledge for {len(topics)} topics (fallback mode)"
                }
            
            # Determine depth parameters
            max_depth_map = {
                "shallow": 2,
                "medium": 5,
                "deep": 10
            }
            max_depth = max_depth_map.get(depth, 5)
            
            # Query SEG graph for relevant entities
            relevant_entities = []
            all_relations = []
            contradictions = []
            
            for topic in topics:
                # Find entities matching topic (by name or attributes)
                topic_lower = topic.lower()
                matching_entities = []
                
                for entity in self.seg_graph.list_entities():
                    # Check name
                    if topic_lower in entity.name.lower():
                        matching_entities.append(entity)
                        continue
                    
                    # Check attributes
                    if entity.attributes:
                        for attr_value in entity.attributes.values():
                            if isinstance(attr_value, str) and topic_lower in attr_value.lower():
                                matching_entities.append(entity)
                                break
                    
                    # Check tags
                    if entity.tags:
                        for tag in entity.tags:
                            if topic_lower in tag.lower():
                                matching_entities.append(entity)
                                break
                
                relevant_entities.extend(matching_entities)
                
                # Get relations for matching entities
                for entity in matching_entities:
                    # Get outgoing relations
                    outgoing = self.seg_graph.get_relations(source_id=entity.id)
                    all_relations.extend(outgoing)
                    
                    # Get incoming relations
                    incoming = self.seg_graph.get_incoming_relations(entity.id)
                    all_relations.extend(incoming)
            
            # Detect contradictions
            try:
                contradictions = self.seg_graph.detect_contradictions()
                # Filter contradictions related to our topics
                topic_contradictions = []
                relevant_entity_ids = {e.id for e in relevant_entities}
                
                for contradiction in contradictions:
                    if (contradiction.entity1_id in relevant_entity_ids or 
                        contradiction.entity2_id in relevant_entity_ids):
                        topic_contradictions.append(contradiction)
                
                contradictions = topic_contradictions
            except Exception as e:
                log(f"Warning: Contradiction detection failed: {e}")
                contradictions = []
            
            # Trace provenance for key entities (if deep depth)
            provenance_chains = {}
            if depth == "deep" and relevant_entities:
                try:
                    for entity in relevant_entities[:5]:  # Limit to first 5 entities
                        provenance = self.seg_graph.trace_provenance(entity.id, max_depth=max_depth)
                        if provenance:
                            provenance_chains[entity.id] = [
                                {
                                    "entity": {
                                        "id": e.id,
                                        "name": e.name,
                                        "type": e.type
                                    },
                                    "relation": {
                                        "id": r.id,
                                        "type": r.relation_type.value,
                                        "confidence": r.confidence
                                    }
                                }
                                for e, r in provenance
                            ]
                except Exception as e:
                    log(f"Warning: Provenance tracing failed: {e}")
            
            # Get graph statistics
            stats = self.seg_graph.stats()
            
            # Synthesize insights
            insights = []
            
            # Entity insights
            if relevant_entities:
                insights.append(f"Found {len(relevant_entities)} entities related to topics: {', '.join(topics)}")
                entity_types = {}
                for entity in relevant_entities:
                    entity_types[entity.type] = entity_types.get(entity.type, 0) + 1
                if entity_types:
                    type_summary = ", ".join([f"{count} {type}" for type, count in entity_types.items()])
                    insights.append(f"Entity breakdown: {type_summary}")
            
            # Relation insights
            if all_relations:
                unique_relations = {r.id: r for r in all_relations}.values()
                insights.append(f"Found {len(unique_relations)} relations connecting topic entities")
                
                # Count relation types
                relation_types = {}
                for relation in unique_relations:
                    rel_type = relation.relation_type.value
                    relation_types[rel_type] = relation_types.get(rel_type, 0) + 1
                if relation_types:
                    rel_summary = ", ".join([f"{count} {type}" for type, count in relation_types.items()])
                    insights.append(f"Relation types: {rel_summary}")
            
            # Contradiction insights
            if contradictions:
                insights.append(f" Detected {len(contradictions)} contradictions:")
                for contradiction in contradictions[:3]:  # Limit to first 3
                    insights.append(f"  - {contradiction.explanation}")
            
            # Provenance insights
            if provenance_chains:
                insights.append(f"Traced provenance for {len(provenance_chains)} entities")
            
            # Build synthesis based on format
            if format_type == "summary":
                synthesis_text = f"Knowledge synthesis for topics: {', '.join(topics)}. "
                synthesis_text += f"Found {len(relevant_entities)} entities and {len(all_relations)} relations. "
                if contradictions:
                    synthesis_text += f" {len(contradictions)} contradictions detected. "
                synthesis_text += " ".join(insights[:3])  # First 3 insights
                
            elif format_type == "detailed":
                synthesis_text = f"# Knowledge Synthesis: {', '.join(topics)}\n\n"
                synthesis_text += f"## Entities Found: {len(relevant_entities)}\n"
                for entity in relevant_entities[:10]:  # Top 10
                    synthesis_text += f"- {entity.name} ({entity.type})\n"
                synthesis_text += f"\n## Relations: {len(all_relations)}\n"
                synthesis_text += f"## Contradictions: {len(contradictions)}\n"
                synthesis_text += f"\n## Insights:\n" + "\n".join(insights)
                
            else:  # structured
                synthesis_text = "See structured data below"
            
            # Build structured response
            synthesis = {
                "topics": topics,
                "depth": depth,
                "format": format_type,
                "synthesis": synthesis_text,
                "insights": insights,
                "statistics": {
                    "entities_found": len(relevant_entities),
                    "relations_found": len(all_relations),
                    "contradictions_detected": len(contradictions),
                    "provenance_chains": len(provenance_chains),
                    "graph_stats": stats
                },
                "entities": [
                    {
                        "id": e.id,
                        "name": e.name,
                        "type": e.type,
                        "confidence": e.confidence,
                        "attributes": e.attributes
                    }
                    for e in relevant_entities[:20]  # Limit to top 20
                ],
                "contradictions": [
                    {
                        "id": c.id,
                        "entity1_id": c.entity1_id,
                        "entity2_id": c.entity2_id,
                        "explanation": c.explanation,
                        "confidence": c.confidence
                    }
                    for c in contradictions
                ],
                "provenance_chains": provenance_chains,
                "created_at": datetime.now().isoformat()
            }
            
            # Store synthesis in CMC if memory available
            atom_id = None
            if self.memory:
                try:
                    from cmc_service.models import AtomCreate, AtomContent
                    
                    atom_create = AtomCreate(
                        modality="synthesis",
                        content=AtomContent(inline=json.dumps(synthesis)),
                        tags={
                            "type": "knowledge_synthesis",
                            "depth": depth,
                            "format": format_type
                        },
                        metadata={
                            "topics": topics,
                            "entities_found": len(relevant_entities),
                            "contradictions": len(contradictions),
                            "created_at": datetime.now().isoformat()
                        }
                    )
                    atom = self.memory.create_atom(atom_create)
                    atom_id = atom.id
                    log(f"Stored synthesis in CMC: atom {atom_id}")
                except Exception as e:
                    log(f"Warning: Failed to store synthesis in CMC: {e}")
            
            response = {
                "success": True,
                "synthesis": synthesis,
                "message": f"Synthesized knowledge for {len(topics)} topics using SEG graph"
            }
            
            if atom_id:
                response["atom_id"] = atom_id
            
            return response
            
        except Exception as e:
            log(f"Error in synthesize_knowledge: {e}")
            return {"error": f"Failed to synthesize knowledge: {str(e)}"}

    # SCOR tool implementations
    def check_invariant(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """Check if action violates invariant rules"""
        action = args.get("action", {})
        context = args.get("context", {})
        
        try:
            # Import SCOR
            from packages.scor.scor import SCORInterface
            
            # Initialize SCOR
            scor = SCORInterface()
            
            # Validate action
            result = scor.validate_action(action, context)
            
            return {
                "success": True,
                "passed": result.passed,
                "risk_score": result.metadata.get("risk_score", 0.0),
                "violations": [v.invariant for v in result.violations] if hasattr(result, 'violations') else [],
                "recommendations": result.recommendations if hasattr(result, 'recommendations') else []
            }
        except Exception as e:
            return {"error": f"Failed to check invariant: {str(e)}"}
    
    def run_baseline_probe(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """Detect self-concept drift via baseline probes"""
        category = args.get("category", "identity")
        
        try:
            from packages.scor.scor import SCORInterface
            scor = SCORInterface()
            
            # Run probe cycle
            result = scor.baseline_probes.run_probe_cycle([category])
            
            status_value = getattr(result, "status", None)
            if hasattr(status_value, "value"):
                status_str = status_value.value
            elif status_value is not None:
                status_str = str(status_value)
            else:
                status_str = getattr(result, "drift_status", "unknown")

            similarity_score = getattr(result, "score", None)
            if similarity_score is not None and isinstance(similarity_score, (int, float)):
                drift_detected = similarity_score < 0.75
            else:
                drift_detected = status_str not in {"stable", "STABLE", "none", "unknown"}

            probe_results = []
            if hasattr(result, "probe_results"):
                probe_results = [getattr(r, "answer", r) for r in result.probe_results]

            return {
                "success": True,
                "drift_detected": drift_detected,
                "drift_status": status_str,
                "similarity_score": similarity_score,
                "individual_scores": getattr(result, "individual_scores", {}),
                "probe_results": probe_results,
            }
        except Exception as e:
            return {"error": f"Failed to run baseline probe: {str(e)}"}
    
    def detect_manipulation_signals(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """Detect social manipulation in user input"""
        user_input = args.get("input", "")
        
        try:
            from packages.scor.scor import SCORInterface
            scor = SCORInterface()
            
            result = scor.social_detector.detect_signals(user_input, {})
            
            return {
                "success": True,
                "signal_detected": result.total > 0.5,
                "signal_score": result.total,
                "patterns_detected": result.detected_patterns,
                "recommended_action": result.recommended_action,
                "breakdown": result.breakdown
            }
        except Exception as e:
            return {"error": f"Failed to detect manipulation signals: {str(e)}"}

    # Snapshot tool implementations
    def create_snapshot(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """Create a snapshot of MCP production files before making changes (Phase 4 enhancement - CMC integration)"""
        snapshot_name = args.get("snapshot_name", f"snapshot_{datetime.now().strftime('%Y%m%d_%H%M%S')}")
        atom_ids = args.get("atom_ids", [])  # Optional list of atom IDs to include
        note = args.get("note", f"Snapshot created: {snapshot_name}")
        
        try:
            # Phase 4 Enhancement: Use CMC create_snapshot if memory available
            if self.memory:
                try:
                    # Create snapshot in CMC
                    snapshot = self.memory.create_snapshot(
                        atom_ids=atom_ids if atom_ids else None,  # None = snapshot all atoms
                        note=note
                    )
                    
                    return {
                        "success": True,
                        "snapshot_id": snapshot.id,
                        "snapshot_name": snapshot_name,
                        "atom_count": len(snapshot.atom_ids),
                        "created_at": snapshot.created_at.isoformat(),
                        "note": snapshot.note,
                        "message": f"Created CMC snapshot '{snapshot.id}' with {len(snapshot.atom_ids)} atoms"
                    }
                except Exception as e:
                    log(f"Warning: CMC snapshot creation failed, using fallback: {e}")
            
            # Fallback: Use snapshot system if available
            if self.snapshot:
                files = args.get("files", [
                    "run_mcp_6_tools.py",
                    "mcp_memory/cmc.db",
                    "C:/Users/bombe/.cursor/mcp.json"
                ])
                
                manifest = self.snapshot.create_snapshot(snapshot_name, files)
                return {
                    "success": True,
                    "snapshot_id": manifest.get("snapshot_id"),
                    "timestamp": manifest.get("timestamp"),
                    "files_count": len(manifest.get("files", [])),
                    "message": f"Created snapshot '{manifest.get('snapshot_id')}'"
                }
            
            return {"error": "Snapshot system not available"}
        except Exception as e:
            return {"error": f"Failed to create snapshot: {str(e)}"}
    
    def restore_snapshot(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """Restore MCP files from a snapshot (Phase 4 enhancement - CMC integration)"""
        snapshot_id = args.get("snapshot_name") or args.get("snapshot_id")
        
        if not snapshot_id:
            return {"error": "snapshot_name or snapshot_id is required"}
        
        try:
            # Phase 4 Enhancement: Use CMC snapshot restore if memory available
            if self.memory:
                try:
                    # Get snapshot from CMC
                    snapshot = self.memory.get_snapshot(snapshot_id)
                    
                    # Replay snapshot atoms (restore state)
                    atoms = list(self.memory.replay_snapshot(snapshot_id))
                    
                    return {
                        "success": True,
                        "snapshot_id": snapshot.id,
                        "atom_count": len(atoms),
                        "atoms": [
                            {
                                "id": atom.id,
                                "modality": atom.modality,
                                "created_at": atom.created_at.isoformat()
                            }
                            for atom in atoms[:10]  # Limit to first 10 for response
                        ],
                        "message": f"Restored CMC snapshot '{snapshot.id}' with {len(atoms)} atoms"
                    }
                except KeyError:
                    return {"error": f"Snapshot '{snapshot_id}' not found in CMC"}
                except Exception as e:
                    log(f"Warning: CMC snapshot restore failed, using fallback: {e}")
            
            # Fallback: Use snapshot system if available
            if self.snapshot:
                result = self.snapshot.restore_snapshot(snapshot_id)
                if result:
                    return {
                        "success": True,
                        "snapshot_name": snapshot_id,
                        "message": f"Restored snapshot '{snapshot_id}'"
                    }
            
            return {"error": "Snapshot system not available"}
        except Exception as e:
            return {"error": f"Failed to restore snapshot: {str(e)}"}
    
    def list_snapshots(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """List all available snapshots (Phase 4 enhancement - CMC integration)"""
        limit = args.get("limit", 50)
        
        try:
            # Phase 4 Enhancement: Use CMC snapshots if memory available
            if self.memory:
                try:
                    # Access snapshots from memory store (snapshots are stored in _snapshots dict)
                    # Note: This accesses internal state, but provides snapshot listing capability
                    snapshots_dict = getattr(self.memory, '_snapshots', {})
                    snapshots_list = list(snapshots_dict.values())
                    
                    # Sort by created_at (most recent first)
                    snapshots_list.sort(key=lambda s: s.created_at, reverse=True)
                    
                    # Apply limit
                    snapshots_list = snapshots_list[:limit]
                    
                    snapshot_list = []
                    for snapshot in snapshots_list:
                        snapshot_list.append({
                            "id": snapshot.id,
                            "atom_count": len(snapshot.atom_ids),
                            "created_at": snapshot.created_at.isoformat(),
                            "note": snapshot.note
                        })
                    
                    return {
                        "success": True,
                        "snapshots": snapshot_list,
                        "count": len(snapshot_list),
                        "total_available": len(snapshots_dict),
                        "message": f"Retrieved {len(snapshot_list)} snapshots from CMC"
                    }
                except Exception as e:
                    log(f"Warning: CMC snapshot listing failed, using fallback: {e}")
            
            # Fallback: Use snapshot system if available
            if self.snapshot:
                snapshots = self.snapshot.list_snapshots()
                return {
                    "success": True,
                    "snapshots": snapshots,
                    "count": len(snapshots) if isinstance(snapshots, list) else 0
                }
            
            return {"error": "Snapshot system not available"}
        except Exception as e:
            return {"error": f"Failed to list snapshots: {str(e)}"}
    
    def archive_snapshot(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """Archive a snapshot (move to archive/, never delete) - Phase 4 enhancement - CMC integration"""
        snapshot_id = args.get("snapshot_name") or args.get("snapshot_id")
        
        if not snapshot_id:
            return {"error": "snapshot_name or snapshot_id is required"}
        
        try:
            # Phase 4 Enhancement: CMC snapshots are immutable (never deleted), mark as archived in metadata
            if self.memory:
                try:
                    # Get snapshot from CMC
                    snapshot = self.memory.get_snapshot(snapshot_id)
                    
                    # In CMC, snapshots are immutable - we can't modify them
                    # Instead, we create a new snapshot with archive metadata
                    archive_note = f"[ARCHIVED] {snapshot.note if snapshot.note else snapshot_id}"
                    
                    archived_snapshot = self.memory.create_snapshot(
                        atom_ids=snapshot.atom_ids,
                        note=archive_note
                    )
                    
                    return {
                        "success": True,
                        "original_snapshot_id": snapshot.id,
                        "archived_snapshot_id": archived_snapshot.id,
                        "message": f"Snapshot '{snapshot.id}' archived as '{archived_snapshot.id}' (CMC snapshots are immutable, created archive copy)"
                    }
                except KeyError:
                    return {"error": f"Snapshot '{snapshot_id}' not found in CMC"}
                except Exception as e:
                    log(f"Warning: CMC snapshot archiving failed, using fallback: {e}")
            
            # Fallback: Use snapshot system if available
            if self.snapshot:
                result = self.snapshot.archive_snapshot(snapshot_id)
                if result:
                    return {
                        "success": True,
                        "snapshot_name": snapshot_id,
                        "message": f"Snapshot '{snapshot_id}' archived successfully"
                    }
            
            return {"error": "Snapshot system not available"}
        except Exception as e:
            return {"error": f"Failed to archive snapshot: {str(e)}"}

    # TCS tool implementations
    def add_timeline_entry(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """Track context at each prompt (Timeline Context System) - Phase 3 enhancement"""
        if not self.timeline_tracker:
            return {"error": "Timeline tracker not initialized"}
        
        prompt_id = args.get("prompt_id", str(uuid.uuid4()))
        user_input = args.get("user_input", "")
        context_state = args.get("context_state", {})
        
        try:
            # Phase 3 Enhancement: Use TCS track_prompt_context with full context tracking
            snapshot = self.timeline_tracker.track_prompt_context(
                prompt_id=prompt_id,
                user_input=user_input,
                context_state=context_state
            )
            
            # Optionally store in CMC if memory available
            atom_id = None
            if self.memory:
                try:
                    from cmc_service.models import AtomCreate, AtomContent
                    
                    content_str = f"Timeline Entry: {prompt_id}\n\n"
                    content_str += f"User Input: {user_input}\n"
                    content_str += f"Current Task: {context_state.get('current_task', '')}\n"
                    content_str += f"Tools Used: {', '.join(snapshot.tools_used)}\n"
                    content_str += f"Decisions: {len(snapshot.decisions_made)}\n"
                    content_str += f"Insights: {', '.join(snapshot.insights_gained)}"
                    
                    atom_create = AtomCreate(
                        modality="tcs_timeline",
                        content=AtomContent(inline=content_str),
                        tags={"type": "timeline_entry", "prompt_id": prompt_id},
                        metadata={
                            "prompt_id": prompt_id,
                            "timestamp": snapshot.timestamp.isoformat(),
                            "tools_used": snapshot.tools_used,
                            "decisions_count": len(snapshot.decisions_made),
                            "insights_count": len(snapshot.insights_gained)
                        }
                    )
                    atom = self.memory.create_atom(atom_create)
                    atom_id = atom.id
                    log(f"Stored timeline entry {prompt_id} in CMC as atom {atom_id}")
                except Exception as e:
                    log(f"Warning: Failed to store timeline entry in CMC: {e}")
            
            return {
                "success": True,
                "prompt_id": snapshot.prompt_id,
                "timestamp": snapshot.timestamp.isoformat(),
                "atom_id": atom_id,
                "context_snapshot": {
                    "files_read": snapshot.files_read,
                    "tools_used": snapshot.tools_used,
                    "decisions_made": len(snapshot.decisions_made),
                    "insights_gained": snapshot.insights_gained,
                    "current_task": snapshot.current_task,
                    "context_budget_used": snapshot.context_budget_used
                },
                "message": f"Timeline entry added for prompt: {prompt_id}"
            }
        except Exception as e:
            return {"error": f"Failed to add timeline entry: {str(e)}"}
    
    def get_timeline_summary(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """Get recent timeline entries (Timeline Context System) - Phase 3 enhancement"""
        if not self.timeline_tracker:
            return {"error": "Timeline tracker not initialized"}
        
        limit = args.get("limit", 10)
        start_time = args.get("start_time")  # Optional ISO datetime string
        end_time = args.get("end_time")  # Optional ISO datetime string
        
        try:
            # Phase 3 Enhancement: Use TCS get_timeline_summary if available
            if hasattr(self.timeline_tracker, 'get_timeline_summary'):
                try:
                    from datetime import datetime as dt
                    start_date = dt.fromisoformat(start_time.replace('Z', '+00:00')) if start_time else None
                    end_date = dt.fromisoformat(end_time.replace('Z', '+00:00')) if end_time else None
                    
                    summary = self.timeline_tracker.get_timeline_summary(start_date, end_date)
                    return {
                        "success": True,
                        "summary": summary,
                        "limit": limit,
                        "message": "Retrieved timeline summary from TCS"
                    }
                except Exception as e:
                    log(f"Warning: TCS get_timeline_summary failed, using fallback: {e}")
            
            # Fallback: Get recent entries from prompt history
            recent_entries = self.timeline_tracker.prompt_history[-limit:] if len(self.timeline_tracker.prompt_history) > 0 else []
            
            summary = []
            for entry in recent_entries:
                summary.append({
                    "prompt_id": entry.prompt_id,
                    "timestamp": entry.timestamp.isoformat(),
                    "user_input": entry.user_input[:100] if entry.user_input else "",  # Truncate for summary
                    "current_task": entry.current_task,
                    "tools_used": entry.tools_used,
                    "decisions_made": len(entry.decisions_made),
                    "insights_gained": entry.insights_gained[:3] if entry.insights_gained else [],  # Top 3 insights
                    "context_evolution": entry.context_evolution if hasattr(entry, 'context_evolution') else {}
                })
            
            return {
                "success": True,
                "entry_count": len(summary),
                "entries": summary,
                "total_entries": len(self.timeline_tracker.prompt_history),
                "message": f"Retrieved {len(summary)} recent timeline entries"
            }
        except Exception as e:
            return {"error": f"Failed to get timeline summary: {str(e)}"}
    
    def get_timeline_entries(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """Query timeline history (Timeline Context System) - Phase 3 enhancement"""
        if not self.timeline_tracker:
            return {"error": "Timeline tracker not initialized"}
        
        prompt_id = args.get("prompt_id")
        start_time = args.get("start_time")  # Optional ISO datetime string
        end_time = args.get("end_time")  # Optional ISO datetime string
        limit = args.get("limit", 50)
        
        try:
            # Phase 3 Enhancement: Query by prompt_id if specified
            if prompt_id:
                snapshot = self.timeline_tracker.context_snapshots.get(prompt_id)
                if snapshot:
                    # Find corresponding timeline entry
                    timeline_entry = None
                    for entry in self.timeline_tracker.timeline_entries:
                        if entry.prompt_id == prompt_id:
                            timeline_entry = entry
                            break
                    
                    return {
                        "success": True,
                        "entries": [{
                            "prompt_id": snapshot.prompt_id,
                            "timestamp": snapshot.timestamp.isoformat(),
                            "user_input": snapshot.user_input,
                            "context_state": snapshot.context_state,
                            "files_read": snapshot.files_read,
                            "tools_used": snapshot.tools_used,
                            "decisions_made": snapshot.decisions_made,
                            "insights_gained": snapshot.insights_gained,
                            "current_task": snapshot.current_task,
                            "context_budget_used": snapshot.context_budget_used,
                            "timeline_entry": {
                                "summary": timeline_entry.summary if timeline_entry else None,
                                "context_index": timeline_entry.context_index if timeline_entry else None,
                                "context_evolution": timeline_entry.context_evolution if timeline_entry else None
                            } if timeline_entry else None
                        }],
                        "message": f"Found timeline entry for prompt: {prompt_id}"
                    }
                else:
                    return {
                        "success": True,
                        "entries": [],
                        "message": f"No entry found for prompt: {prompt_id}"
                    }
            
            # Filter by time range if provided
            filtered_entries = self.timeline_tracker.prompt_history
            if start_time or end_time:
                from datetime import datetime as dt
                start_date = dt.fromisoformat(start_time.replace('Z', '+00:00')) if start_time else None
                end_date = dt.fromisoformat(end_time.replace('Z', '+00:00')) if end_time else None
                
                filtered_entries = [
                    entry for entry in filtered_entries
                    if (start_date is None or entry.timestamp >= start_date) and
                       (end_date is None or entry.timestamp <= end_date)
                ]
            
            # Apply limit and get most recent
            recent_entries = filtered_entries[-limit:] if len(filtered_entries) > 0 else []
            
            entries = []
            for entry in recent_entries:
                # Find corresponding timeline entry
                timeline_entry = None
                for te in self.timeline_tracker.timeline_entries:
                    if te.prompt_id == entry.prompt_id:
                        timeline_entry = te
                        break
                
                entries.append({
                    "prompt_id": entry.prompt_id,
                    "timestamp": entry.timestamp.isoformat(),
                    "user_input": entry.user_input,
                    "current_task": entry.current_task,
                    "files_read": entry.files_read,
                    "tools_used": entry.tools_used,
                    "decisions_made": entry.decisions_made,
                    "insights_gained": entry.insights_gained,
                    "context_budget_used": entry.context_budget_used,
                    "timeline_entry": {
                        "summary": timeline_entry.summary if timeline_entry else None,
                        "context_index": timeline_entry.context_index if timeline_entry else None,
                        "context_evolution": timeline_entry.context_evolution if timeline_entry else None
                    } if timeline_entry else None
                })
            
            return {
                "success": True,
                "entry_count": len(entries),
                "total_available": len(filtered_entries),
                "entries": entries,
                "message": f"Retrieved {len(entries)} timeline entries"
            }
        except Exception as e:
            return {"error": f"Failed to get timeline entries: {str(e)}"}

    # Goal Timeline tool implementations
    def create_goal_timeline_node(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """Create a goal as a timeline planning node (Phase 3 enhancement - Goal Timeline Integration)"""
        goal_id = args.get("goal_id")
        name = args.get("name")
        description = args.get("description")
        target_sequence = args.get("target_sequence", 100)
        priority_str = args.get("priority", "medium")
        
        if not goal_id or not name:
            return {"error": "goal_id and name are required"}
        
        try:
            # Phase 3 Enhancement: Use GoalTimelineNode for full goal tracking
            from packages.timeline_context_system.goal_timeline_node import GoalTimelineNode, GoalStatus, GoalPriority
            
            # Initialize goal_nodes if not exists
            if not hasattr(self, 'goal_nodes'):
                self.goal_nodes: Dict[str, GoalTimelineNode] = {}
            
            # Check if goal already exists
            if goal_id in self.goal_nodes:
                return {
                    "error": f"Goal {goal_id} already exists",
                    "existing_goal": {
                        "goal_id": self.goal_nodes[goal_id].goal_id,
                        "name": self.goal_nodes[goal_id].name,
                        "status": self.goal_nodes[goal_id].status.value
                    }
                }
            
            # Create node_id based on timestamp
            node_id = f"goal_{datetime.now().timestamp()}"
            
            # Get next sequence number
            current_sequence = max([g.current_sequence for g in self.goal_nodes.values()], default=0) + 1
            
            # Create goal node
            priority_map = {
                "critical": GoalPriority.CRITICAL,
                "high": GoalPriority.HIGH,
                "medium": GoalPriority.MEDIUM,
                "low": GoalPriority.LOW
            }
            
            goal_node = GoalTimelineNode(
                node_id=node_id,
                goal_id=goal_id,
                name=name,
                description=description,
                created_sequence=current_sequence,
                current_sequence=current_sequence,
                target_sequence=target_sequence,
                status=GoalStatus.PLANNED,
                priority=priority_map.get(priority_str.lower(), GoalPriority.MEDIUM)
            )
            
            # Store node
            self.goal_nodes[goal_id] = goal_node
            
            # Optionally store in CMC if memory available
            atom_id = None
            if self.memory:
                try:
                    from cmc_service.models import AtomCreate, AtomContent
                    
                    content_str = f"Goal Timeline Node: {goal_id}\n\n"
                    content_str += f"Name: {name}\n"
                    content_str += f"Description: {description}\n"
                    content_str += f"Priority: {priority_str}\n"
                    content_str += f"Target Sequence: {target_sequence}"
                    
                    atom_create = AtomCreate(
                        modality="text",
                        content=AtomContent(inline=content_str),
                        tags={"type": "goal_timeline_node", "goal_id": goal_id, "priority": priority_str},
                        metadata={
                            "goal_id": goal_id,
                            "node_id": node_id,
                            "status": "planned",
                            "priority": priority_str,
                            "target_sequence": target_sequence
                        }
                    )
                    atom = self.memory.create_atom(atom_create)
                    atom_id = atom.id
                    log(f"Stored goal timeline node {goal_id} in CMC as atom {atom_id}")
                except Exception as e:
                    log(f"Warning: Failed to store goal in CMC: {e}")
            
            return {
                "success": True,
                "goal_id": goal_id,
                "node_id": node_id,
                "sequence": current_sequence,
                "status": goal_node.status.value,
                "priority": goal_node.priority.value,
                "atom_id": atom_id,
                "message": f"Created goal timeline node for {goal_id}"
            }
        except Exception as e:
            return {"error": f"Failed to create goal timeline node: {str(e)}"}
    
    def update_goal_progress(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """Update goal progress and status (Phase 3 enhancement - Goal Timeline Integration)"""
        goal_id = args.get("goal_id")
        progress = args.get("progress")
        status_str = args.get("status")
        milestone = args.get("milestone")
        
        if not goal_id:
            return {"error": "goal_id is required"}
        
        # Initialize goal_nodes if not exists
        if not hasattr(self, 'goal_nodes'):
            self.goal_nodes: Dict[str, GoalTimelineNode] = {}
        
        if goal_id not in self.goal_nodes:
            return {"error": f"Goal {goal_id} not found"}
        
        try:
            # Phase 3 Enhancement: Use GoalTimelineNode update methods
            from packages.timeline_context_system.goal_timeline_node import GoalStatus
            
            goal_node = self.goal_nodes[goal_id]
            
            # Update progress if provided
            if progress is not None:
                if not 0.0 <= progress <= 1.0:
                    return {"error": "Progress must be between 0.0 and 1.0"}
                goal_node.update_progress(progress, milestone)
            
            # Update status if provided
            if status_str:
                status_map = {
                    "planned": GoalStatus.PLANNED,
                    "in_progress": GoalStatus.IN_PROGRESS,
                    "completed": GoalStatus.COMPLETED,
                    "blocked": GoalStatus.BLOCKED,
                    "cancelled": GoalStatus.CANCELLED
                }
                goal_node.update_status(status_map.get(status_str.lower(), GoalStatus.PLANNED))
            
            # Update current sequence based on progress
            if progress is not None and goal_node.target_sequence > 0:
                goal_node.current_sequence = int(goal_node.target_sequence * progress)
            
            # Optionally update in CMC if memory available
            atom_id = None
            if self.memory:
                try:
                    from cmc_service.models import AtomCreate, AtomContent
                    
                    content_str = f"Goal Progress Update: {goal_id}\n\n"
                    content_str += f"Progress: {int(goal_node.progress * 100)}%\n"
                    content_str += f"Status: {goal_node.status.value}\n"
                    if milestone:
                        content_str += f"Milestone: {milestone}"
                    
                    atom_create = AtomCreate(
                        modality="text",
                        content=AtomContent(inline=content_str),
                        tags={"type": "goal_progress_update", "goal_id": goal_id, "status": goal_node.status.value},
                        metadata={
                            "goal_id": goal_id,
                            "progress": goal_node.progress,
                            "status": goal_node.status.value,
                            "milestone": milestone,
                            "current_sequence": goal_node.current_sequence
                        }
                    )
                    atom = self.memory.create_atom(atom_create)
                    atom_id = atom.id
                    log(f"Stored goal progress update for {goal_id} in CMC as atom {atom_id}")
                except Exception as e:
                    log(f"Warning: Failed to store goal progress in CMC: {e}")
            
            return {
                "success": True,
                "goal_id": goal_id,
                "progress": goal_node.progress,
                "status": goal_node.status.value,
                "sequence": goal_node.current_sequence,
                "target_sequence": goal_node.target_sequence,
                "completed_krs": goal_node.completed_krs,
                "total_krs": goal_node.total_krs,
                "atom_id": atom_id,
                "message": f"Updated goal {goal_id} progress to {int(goal_node.progress * 100)}%"
            }
        except Exception as e:
            return {"error": f"Failed to update goal progress: {str(e)}"}
    
    def query_goal_timeline(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """Query goals in the timeline (Phase 3 enhancement - Goal Timeline Integration)"""
        status_filter = args.get("status")
        priority_filter = args.get("priority")
        limit = args.get("limit", 50)
        
        # Initialize goal_nodes if not exists
        if not hasattr(self, 'goal_nodes'):
            self.goal_nodes: Dict[str, GoalTimelineNode] = {}
        
        try:
            # Phase 3 Enhancement: Query with filtering and comprehensive results
            results = []
            
            for goal_id, goal_node in self.goal_nodes.items():
                # Apply filters
                if status_filter and goal_node.status.value != status_filter.lower():
                    continue
                if priority_filter and goal_node.priority.value != priority_filter.lower():
                    continue
                
                results.append({
                    "goal_id": goal_node.goal_id,
                    "node_id": goal_node.node_id,
                    "name": goal_node.name,
                    "description": goal_node.description,
                    "status": goal_node.status.value,
                    "progress": goal_node.progress,
                    "priority": goal_node.priority.value,
                    "created_sequence": goal_node.created_sequence,
                    "current_sequence": goal_node.current_sequence,
                    "target_sequence": goal_node.target_sequence,
                    "created_at": goal_node.created_at.isoformat(),
                    "updated_at": goal_node.updated_at.isoformat(),
                    "started_at": goal_node.started_at.isoformat() if goal_node.started_at else None,
                    "target_completion": goal_node.target_completion.isoformat() if goal_node.target_completion else None,
                    "actual_completion": goal_node.actual_completion.isoformat() if goal_node.actual_completion else None,
                    "completed_krs": goal_node.completed_krs,
                    "total_krs": goal_node.total_krs,
                    "key_results": [
                        {
                            "id": kr.id,
                            "name": kr.name,
                            "metric": kr.metric,
                            "target": kr.target,
                            "status": kr.status,
                            "completed": kr.completed
                        }
                        for kr in goal_node.key_results
                    ],
                    "linked_goals": goal_node.linked_goals,
                    "artifacts": goal_node.artifacts,
                    "evidence": goal_node.evidence
                })
                
                # Apply limit
                if len(results) >= limit:
                    break
            
            # Sort by current_sequence (timeline order)
            results.sort(key=lambda x: x["current_sequence"])
            
            return {
                "success": True,
                "count": len(results),
                "total_goals": len(self.goal_nodes),
                "goals": results,
                "filters_applied": {
                    "status": status_filter,
                    "priority": priority_filter
                },
                "message": f"Found {len(results)} goals matching criteria"
            }
        except Exception as e:
            return {"error": f"Failed to query goal timeline: {str(e)}"}
    
    # IIS Tools (Tools 20-22)
    
    def compute_intuition(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """Compute AI intuition score using IIS (Phase 4 enhancement - CMC integration)"""
        confidence = args.get("confidence", 0.5)
        retrieval_quality = args.get("retrieval_quality", 0.5)
        meta_pattern_similarity = args.get("meta_pattern_similarity", 0.5)
        emotional_salience = args.get("emotional_salience", 0.5)
        evolution_alignment = args.get("evolution_alignment", 0.5)
        context = args.get("context", "")
        decision_id = args.get("decision_id") or f"decision_{uuid.uuid4()}"
        
        try:
            # Phase 4 Enhancement: IIS intuition scoring with CMC storage
            weights = [0.3, 0.2, 0.2, 0.1, 0.2]  # Weights for features
            features = [confidence, retrieval_quality, meta_pattern_similarity, emotional_salience, evolution_alignment]
            
            raw_score = sum(w * f for w, f in zip(weights, features))
            intuition_score = 1 / (1 + pow(2.718, -raw_score))  # Sigmoid
            
            components = {
                "pattern_match": meta_pattern_similarity,
                "confidence": confidence,
                "retrieval": retrieval_quality,
                "emotional": emotional_salience,
                "evolution": evolution_alignment
            }
            
            record = {
                "type": "intuition",
                "timestamp": datetime.now().isoformat(),
                "score": round(intuition_score, 3),
                "components": components,
                "context": context,
                "decision_id": decision_id
            }
            
            # Phase 4 Enhancement: Store intuition trace in CMC if memory available
            atom_id = None
            if self.memory:
                try:
                    from cmc_service.models import AtomCreate, AtomContent
                    
                    content_str = f"Intuition Score: {round(intuition_score, 3)}\n\n"
                    content_str += f"Decision ID: {decision_id}\n"
                    content_str += f"Context: {context}\n"
                    content_str += f"Components: {json.dumps(components, indent=2)}"
                    
                    atom_create = AtomCreate(
                        modality="text",
                        content=AtomContent(inline=content_str),
                        tags={
                            "type": "intuition_trace",
                            "decision_id": decision_id,
                            "intuition_score": round(intuition_score, 3)
                        },
                        metadata={
                            "decision_id": decision_id,
                            "intuition_score": round(intuition_score, 3),
                            "components": components,
                            "context": context,
                            "timestamp": record["timestamp"]
                        }
                    )
                    atom = self.memory.create_atom(atom_create)
                    atom_id = atom.id
                    log(f"Stored intuition trace for decision {decision_id} in CMC as atom {atom_id}")
                except Exception as e:
                    log(f"Warning: Failed to store intuition trace in CMC: {e}")
            
            self.intuition_traces.setdefault(decision_id, []).append(record)
            self._save_intuition_store()
            self._update_consciousness_metrics()

            return {
                "success": True,
                "decision_id": decision_id,
                "intuition_score": round(intuition_score, 3),
                "components": components,
                "context": context,
                "atom_id": atom_id,
                "message": f"Intuition score: {round(intuition_score * 100)}%"
            }
        except Exception as e:
            return {"error": f"Failed to compute intuition: {str(e)}"}
    
    def update_intuition_weights(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """Update intuition weights from outcome (IIS learning) - Phase 4 enhancement - CMC integration"""
        decision_id = args.get("decision_id")
        label = args.get("label")  # 0 or 1
        features = args.get("features", {})
        
        if not decision_id:
            return {"error": "decision_id is required"}
        
        try:
            # Phase 4 Enhancement: Update intuition weights with CMC storage
            if decision_id and decision_id in self.intuition_traces and self.intuition_traces[decision_id]:
                latest_trace = self.intuition_traces[decision_id][-1]
                latest_trace["label"] = label
                latest_trace["label_timestamp"] = datetime.now().isoformat()
                if features:
                    latest_trace["features"] = features
                
                # Phase 4 Enhancement: Store weight update in CMC if memory available
                atom_id = None
                if self.memory:
                    try:
                        from cmc_service.models import AtomCreate, AtomContent
                        
                        content_str = f"Intuition Weight Update: {decision_id}\n\n"
                        content_str += f"Label: {'success' if label == 1 else 'failure'}\n"
                        content_str += f"Outcome: {label}\n"
                        if features:
                            content_str += f"Features: {json.dumps(features, indent=2)}"
                        
                        atom_create = AtomCreate(
                            modality="text",
                            content=AtomContent(inline=content_str),
                            tags={
                                "type": "intuition_weight_update",
                                "decision_id": decision_id,
                                "label": str(label)
                            },
                            metadata={
                                "decision_id": decision_id,
                                "label": label,
                                "features": features,
                                "timestamp": latest_trace["label_timestamp"]
                            }
                        )
                        atom = self.memory.create_atom(atom_create)
                        atom_id = atom.id
                        log(f"Stored intuition weight update for decision {decision_id} in CMC as atom {atom_id}")
                    except Exception as e:
                        log(f"Warning: Failed to store weight update in CMC: {e}")
                
                self._save_intuition_store()
                self._update_consciousness_metrics()
                
                return {
                    "success": True,
                    "decision_id": decision_id,
                    "label": label,
                    "atom_id": atom_id,
                    "message": f"Weights updated based on outcome: {'success' if label == 1 else 'failure'}"
                }
            else:
                return {"error": f"Decision {decision_id} not found in intuition traces"}
        except Exception as e:
            return {"error": f"Failed to update intuition weights: {str(e)}"}
    
    def get_intuition_trace(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """Get intuition trace history (Phase 4 enhancement - CMC integration)"""
        decision_id = args.get("decision_id")
        limit = args.get("limit", 10)
        
        try:
            traces = []
            
            # Phase 4 Enhancement: Query CMC for intuition traces if memory available
            if self.memory:
                try:
                    if decision_id:
                        # Query atoms for specific decision
                        atoms = list(self.memory.list_atoms(tag=f"decision_id:{decision_id}", limit=limit if limit else 1000))
                    else:
                        # Query all intuition trace atoms
                        atoms = list(self.memory.list_atoms(tag="intuition_trace", limit=limit if limit else 100))
                    
                    for atom in atoms:
                        if atom.metadata and ("intuition_score" in atom.metadata or "decision_id" in atom.metadata):
                            traces.append({
                                "decision_id": atom.metadata.get("decision_id"),
                                "intuition_score": atom.metadata.get("intuition_score"),
                                "components": atom.metadata.get("components", {}),
                                "context": atom.metadata.get("context", ""),
                                "timestamp": atom.metadata.get("timestamp"),
                                "atom_id": atom.id
                            })
                    
                    log(f"Retrieved {len(traces)} intuition traces from CMC")
                except Exception as e:
                    log(f"Warning: Failed to query CMC for intuition traces: {e}")
            
            # Fallback: Use local storage
            if not traces:
                if decision_id:
                    decision_traces = self.intuition_traces.get(decision_id, [])
                    traces = decision_traces[-limit:] if limit else list(decision_traces)
                else:
                    # Aggregate view across all decisions
                    aggregated: List[Dict[str, Any]] = []
                    for did, records in self.intuition_traces.items():
                        for record in records:
                            aggregated.append({"decision_id": did, **record})
                    aggregated.sort(key=lambda entry: entry.get("timestamp", ""), reverse=True)
                    if limit:
                        aggregated = aggregated[:limit]
                    traces = aggregated
            
            return {
                "success": True,
                "decision_id": decision_id,
                "traces": traces,
                "count": len(traces),
                "cmc_enabled": bool(self.memory),
                "message": "Intuition traces retrieved" if traces else f"No traces found for decision {decision_id}"
            }
        except Exception as e:
            return {"error": f"Failed to get intuition trace: {str(e)}"}
    
    # Co-Agency Tools (Tools 23-25)
    
    def signal_disagreement(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """Signal transparent disagreement with user (Co-Agency) - Phase 4 enhancement - CMC integration"""
        concern = args.get("concern")
        reasoning = args.get("reasoning", [])
        evidence = args.get("evidence", {})
        alternative = args.get("alternative")
        
        if not concern:
            return {"error": "concern is required"}
        
        try:
            disagreement = {
                "timestamp": datetime.now().isoformat(),
                "concern": concern,
                "reasoning": reasoning,
                "evidence": evidence,
                "alternative": alternative,
                "status": "pending_user_response"
            }
            
            # Phase 4 Enhancement: Store disagreement in CMC if memory available
            atom_id = None
            if self.memory:
                try:
                    from cmc_service.models import AtomCreate, AtomContent
                    
                    content_str = f"Co-Agency Disagreement: {concern}\n\n"
                    content_str += f"Reasoning: {json.dumps(reasoning, indent=2)}\n"
                    if alternative:
                        content_str += f"Alternative: {alternative}\n"
                    if evidence:
                        content_str += f"Evidence: {json.dumps(evidence, indent=2)}"
                    
                    atom_create = AtomCreate(
                        modality="text",
                        content=AtomContent(inline=content_str),
                        tags={
                            "type": "co_agency_disagreement",
                            "status": "pending_user_response"
                        },
                        metadata={
                            "concern": concern,
                            "reasoning": reasoning,
                            "evidence": evidence,
                            "alternative": alternative,
                            "status": "pending_user_response",
                            "timestamp": disagreement["timestamp"]
                        }
                    )
                    atom = self.memory.create_atom(atom_create)
                    atom_id = atom.id
                    log(f"Stored disagreement in CMC as atom {atom_id}")
                except Exception as e:
                    log(f"Warning: Failed to store disagreement in CMC: {e}")
            
            log(f"Co-Agency Disagreement: {concern}")
            
            return {
                "success": True,
                "disagreement": disagreement,
                "atom_id": atom_id,
                "message": "Disagreement logged, waiting for user response"
            }
        except Exception as e:
            return {"error": f"Failed to signal disagreement: {str(e)}"}
    
    def get_trust_dashboard(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """Get trust dashboard state (Phase 4 enhancement - CMC integration)"""
        user_id = args.get("user_id", "default")
        
        try:
            # Phase 4 Enhancement: Build trust dashboard from CMC data if memory available
            dashboard = {
                "identity_confidence": 0.85,
                "intent_risk_band": "low",
                "ethical_tension": 0.2,
                "evidence_alignment": {"status": "aligned"}
            }
            
            # Phase 4 Enhancement: Query CMC for trust-related data
            if self.memory:
                try:
                    # Query for disagreements and escalations
                    disagreement_atoms = list(self.memory.list_atoms(tag="co_agency_disagreement", limit=10))
                    escalation_atoms = list(self.memory.list_atoms(tag="co_agency_escalation", limit=10))
                    
                    # Calculate trust metrics from historical data
                    total_disagreements = len(disagreement_atoms)
                    total_escalations = len(escalation_atoms)
                    recent_disagreements = sum(1 for atom in disagreement_atoms 
                                              if atom.metadata and atom.metadata.get("status") == "pending_user_response")
                    
                    # Adjust dashboard based on CMC data
                    if total_disagreements > 0:
                        dashboard["identity_confidence"] = max(0.5, 0.85 - (total_disagreements * 0.05))
                    if total_escalations > 0:
                        risk_levels = [atom.metadata.get("risk_level", "low") for atom in escalation_atoms 
                                     if atom.metadata]
                        if any(rl in ["high", "critical"] for rl in risk_levels):
                            dashboard["intent_risk_band"] = "medium"
                    if recent_disagreements > 0:
                        dashboard["ethical_tension"] = min(1.0, 0.2 + (recent_disagreements * 0.1))
                    
                    dashboard["cmc_data"] = {
                        "total_disagreements": total_disagreements,
                        "total_escalations": total_escalations,
                        "pending_disagreements": recent_disagreements
                    }
                    
                    log(f"Built trust dashboard from CMC data for user {user_id}")
                except Exception as e:
                    log(f"Warning: Failed to query CMC for trust dashboard: {e}")
            
            return {
                "success": True,
                "user_id": user_id,
                "dashboard": dashboard,
                "cmc_enabled": bool(self.memory),
                "message": "Trust dashboard retrieved"
            }
        except Exception as e:
            return {"error": f"Failed to get trust dashboard: {str(e)}"}
    
    def request_escalation(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """Request accountable escalation (Phase 4 enhancement - CMC integration)"""
        reason = args.get("reason")
        risk_level = args.get("risk_level")
        options = args.get("options", [])
        requires = args.get("requires", "review")
        
        if not reason or not risk_level:
            return {"error": "reason and risk_level are required"}
        
        try:
            escalation = {
                "timestamp": datetime.now().isoformat(),
                "reason": reason,
                "risk_level": risk_level,
                "options": options,
                "requires": requires,
                "status": "pending"
            }
            
            # Phase 4 Enhancement: Store escalation in CMC if memory available
            atom_id = None
            if self.memory:
                try:
                    from cmc_service.models import AtomCreate, AtomContent
                    
                    content_str = f"Escalation Request ({risk_level}): {reason}\n\n"
                    content_str += f"Requires: {requires}\n"
                    if options:
                        content_str += f"Options: {json.dumps(options, indent=2)}"
                    
                    atom_create = AtomCreate(
                        modality="text",
                        content=AtomContent(inline=content_str),
                        tags={
                            "type": "co_agency_escalation",
                            "risk_level": risk_level,
                            "status": "pending"
                        },
                        metadata={
                            "reason": reason,
                            "risk_level": risk_level,
                            "options": options,
                            "requires": requires,
                            "status": "pending",
                            "timestamp": escalation["timestamp"]
                        }
                    )
                    atom = self.memory.create_atom(atom_create)
                    atom_id = atom.id
                    log(f"Stored escalation request in CMC as atom {atom_id}")
                except Exception as e:
                    log(f"Warning: Failed to store escalation in CMC: {e}")
            
            log(f"Co-Agency Escalation ({risk_level}): {reason}")
            
            return {
                "success": True,
                "escalation": escalation,
                "atom_id": atom_id,
                "message": f"Escalation requested: {requires}"
            }
        except Exception as e:
            return {"error": f"Failed to request escalation: {str(e)}"}
    
    # Dataset Management Tools (Tools 26-29)
    
    def create_dataset(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """Define new dataset for AIM-OS"""
        dataset_name = args.get("dataset_name")
        description = args.get("description")
        schema = args.get("schema", {})
        tags = args.get("tags", {})
        
        try:
            if not dataset_name:
                return {"error": "Dataset name is required"}

            if not self.dataset_store_file:
                name_key = dataset_name.lower()
                if name_key in self._dataset_index:
                    existing_id = self._dataset_index[name_key]
                    existing = self.datasets.get(existing_id)
                    return {
                        "success": False,
                        "error": f"Dataset '{dataset_name}' already exists",
                        "dataset": existing,
                    }

                dataset_id = str(uuid.uuid4())
                dataset = {
                    "dataset_id": dataset_id,
                    "dataset_name": dataset_name,
                    "description": description,
                    "schema": schema,
                    "tags": tags,
                    "created_at": datetime.now().isoformat(),
                    "data_count": 0,
                    "records": [],
                }
                self.datasets[dataset_id] = dataset
                self._dataset_index[name_key] = dataset_id
                self._save_dataset_store()
                self._update_consciousness_metrics()
                return {
                    "success": True,
                    "dataset": dataset,
                    "dataset_id": dataset_id,
                    "message": f"Dataset '{dataset_name}' created successfully"
                }

            self._init_dataset_store()
            dataset_id = str(uuid.uuid4())
            created_at = datetime.now().isoformat()
            try:
                with sqlite3.connect(self.dataset_store_file) as conn:
                    conn.execute(
                        """
                        INSERT INTO datasets (
                            dataset_id, dataset_name, description, schema_json, tags_json, created_at, data_count
                        ) VALUES (?, ?, ?, ?, ?, ?, 0)
                        """,
                        (
                            dataset_id,
                            dataset_name,
                            description,
                            json.dumps(schema),
                            json.dumps(tags),
                            created_at,
                        ),
                    )
            except sqlite3.IntegrityError:
                self._refresh_dataset_cache()
                existing_id = self._dataset_index.get(dataset_name.lower())
                existing = self.datasets.get(existing_id) if existing_id else None
                return {
                    "success": False,
                    "error": f"Dataset '{dataset_name}' already exists",
                    "dataset": existing,
                }

            self._refresh_dataset_cache()
            self._update_consciousness_metrics()
            dataset = self.datasets.get(dataset_id, {
                "dataset_id": dataset_id,
                "dataset_name": dataset_name,
                "description": description,
                "schema": schema,
                "tags": tags,
                "created_at": created_at,
                "data_count": 0,
                "records": [],
            })
            
            return {
                "success": True,
                "dataset": {**dataset, "records": []},
                "dataset_id": dataset_id,
                "message": f"Dataset '{dataset_name}' created successfully"
            }
        except Exception as e:
            return {"error": f"Failed to create dataset: {str(e)}"}
    
    def ingest_data(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """Ingest data into AIM-OS dataset (Phase 4 enhancement - CMC integration)"""
        dataset_id = args.get("dataset_id")
        dataset_name = args.get("dataset_name")
        data = args.get("data")
        if data is None:
            data = args.get("records")
        format = args.get("format", "json")
        chunk_size = args.get("chunk_size", 100)
        
        try:
            dataset = self._resolve_dataset(dataset_id, dataset_name)
            if not dataset:
                identifier = dataset_id or dataset_name or "unknown"
                return {"error": f"Dataset '{identifier}' not found"}
            dataset_id = dataset["dataset_id"]
            ingested_count = 0
            atom_ids = []
            
            # Phase 4 Enhancement: Store dataset records as CMC atoms if memory available
            if self.memory:
                try:
                    from cmc_service.models import AtomCreate, AtomContent
                    
                    # Prepare records for ingestion
                    records_to_ingest = []
                    if isinstance(data, dict):
                        records_to_ingest = [data]
                    elif isinstance(data, list):
                        records_to_ingest = list(data)
                    elif data is not None:
                        records_to_ingest = [{"value": data}]
                    
                    # Store each record as a CMC atom
                    for record in records_to_ingest:
                        content_str = json.dumps(record, indent=2)
                        
                        atom_create = AtomCreate(
                            modality="text",
                            content=AtomContent(inline=content_str),
                            tags={
                                "type": "dataset_record",
                                "dataset_id": dataset_id,
                                "dataset_name": dataset_name or dataset.get("dataset_name", "")
                            },
                            metadata={
                                "dataset_id": dataset_id,
                                "dataset_name": dataset_name or dataset.get("dataset_name", ""),
                                "record": record,
                                "ingested_at": datetime.now().isoformat()
                            }
                        )
                        atom = self.memory.create_atom(atom_create)
                        atom_ids.append(atom.id)
                        ingested_count += 1
                    
                    log(f"Stored {ingested_count} dataset records in CMC as atoms for dataset {dataset_id}")
                except Exception as e:
                    log(f"Warning: Failed to store dataset records in CMC: {e}")
            
            # Fallback: Use local dataset store
            if not self.dataset_store_file:
                if isinstance(data, dict):
                    ingested_count = 1
                    dataset.setdefault("records", []).append(data)
                elif isinstance(data, list):
                    ingested_count = len(data)
                    dataset.setdefault("records", []).extend(data)
                elif data is None:
                    ingested_count = 0
                else:
                    ingested_count = 1
                    dataset.setdefault("records", []).append({"value": data})
                dataset["data_count"] = dataset.get("data_count", 0) + ingested_count
                self._save_dataset_store()
                self._update_consciousness_metrics()
            else:
                self._init_dataset_store()
                records_to_insert: List[Dict[str, Any]] = []
                if isinstance(data, dict):
                    records_to_insert = [data]
                elif isinstance(data, list):
                    records_to_insert = list(data)
                elif data is None:
                    records_to_insert = []
                else:
                    records_to_insert = [{"value": data}]

                ingested_count = len(records_to_insert)
                created_at = datetime.now().isoformat()
                with sqlite3.connect(self.dataset_store_file) as conn:
                    for record in records_to_insert:
                        conn.execute(
                            """
                            INSERT INTO dataset_records (dataset_id, record_json, created_at)
                            VALUES (?, ?, ?)
                            """,
                            (dataset_id, json.dumps(record), created_at),
                        )
                    if ingested_count:
                        conn.execute(
                            "UPDATE datasets SET data_count = data_count + ? WHERE dataset_id = ?",
                            (ingested_count, dataset_id),
                        )
                self._refresh_dataset_cache()
                self._update_consciousness_metrics()
            
            return {
                "success": True,
                "dataset_id": dataset_id,
                "dataset_name": dataset.get("dataset_name"),
                "ingested_count": ingested_count,
                "total_count": dataset["data_count"],
                "atom_ids": atom_ids[:10] if atom_ids else None,  # Include first 10 atom IDs
                "cmc_enabled": bool(atom_ids),
                "message": f"Successfully ingested {ingested_count} items into dataset"
            }
        except Exception as e:
            return {"error": f"Failed to ingest data: {str(e)}"}
    
    def query_dataset(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """Query dataset contents (Phase 4 enhancement - CMC integration)"""
        dataset_id = args.get("dataset_id")
        dataset_name = args.get("dataset_name")
        query = args.get("query")
        filters = args.get("filters", {})
        limit = args.get("limit", 10)
        
        try:
            dataset = self._resolve_dataset(dataset_id, dataset_name)
            if not dataset:
                identifier = dataset_id or dataset_name or "unknown"
                return {"error": f"Dataset '{identifier}' not found"}
            dataset_id = dataset["dataset_id"]
            
            # Phase 4 Enhancement: Query CMC atoms by dataset tag if memory available
            records = []
            if self.memory:
                try:
                    # Query atoms with dataset tag
                    atoms = list(self.memory.list_atoms(
                        tag=f"dataset_id:{dataset_id}",
                        limit=limit if limit else 1000
                    ))
                    
                    # Extract records from atom metadata
                    for atom in atoms:
                        if atom.metadata and "record" in atom.metadata:
                            records.append(atom.metadata["record"])
                        elif atom.content and hasattr(atom.content, 'inline'):
                            try:
                                records.append(json.loads(atom.content.inline))
                            except Exception:
                                pass
                    
                    log(f"Retrieved {len(records)} dataset records from CMC for dataset {dataset_id}")
                except Exception as e:
                    log(f"Warning: Failed to query dataset from CMC: {e}")
            
            # Fallback: Use local dataset store
            if not self.dataset_store_file:
                records = list(dataset.get("records", []))
                if query and isinstance(query, str) and "==" in query:
                    field, value = query.split("==", 1)
                    field = field.strip()
                    value = value.strip().strip("'\"")
                    records = [
                        record for record in records
                        if isinstance(record, dict) and str(record.get(field)) == value
                    ]
                if limit is not None:
                    records = records[:limit]
                return {
                    "success": True,
                    "dataset_id": dataset_id,
                    "dataset_name": dataset.get("dataset_name"),
                    "query": query,
                    "filters": filters,
                    "limit": limit,
                    "results": records,
                    "count": len(records),
                    "message": f"Query executed: {dataset['dataset_name']}"
                }

            self._init_dataset_store()
            records: List[Dict[str, Any]] = []
            with sqlite3.connect(self.dataset_store_file) as conn:
                conn.row_factory = sqlite3.Row
                rows = conn.execute(
                    "SELECT record_json FROM dataset_records WHERE dataset_id = ? ORDER BY record_id DESC",
                    (dataset_id,),
                ).fetchall()

            for row in rows:
                try:
                    records.append(json.loads(row["record_json"]))
                except Exception:
                    continue

            if query and isinstance(query, str) and "==" in query:
                field, value = query.split("==", 1)
                field = field.strip()
                value = value.strip().strip("'\"")
                records = [
                    record for record in records
                    if isinstance(record, dict) and str(record.get(field)) == value
                ]

            if isinstance(limit, int) and limit >= 0:
                records = records[:limit]

            return {
                "success": True,
                "dataset_id": dataset_id,
                "dataset_name": dataset.get("dataset_name"),
                "query": query,
                "filters": filters,
                "limit": limit,
                "results": records,
                "count": len(records),
                "message": f"Query executed: {dataset['dataset_name']}"
            }
        except Exception as e:
            return {"error": f"Failed to query dataset: {str(e)}"}
    
    def delete_dataset(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """Remove dataset (safe operation with snapshots) - Phase 4 enhancement - CMC integration"""
        dataset_id = args.get("dataset_id")
        dataset_name = args.get("dataset_name")
        confirm = args.get("confirm", False)
        archive = args.get("archive", True)
        
        try:
            dataset = self._resolve_dataset(dataset_id, dataset_name)
            if not dataset:
                identifier = dataset_id or dataset_name or "unknown"
                return {"error": f"Dataset '{identifier}' not found"}
            dataset_id = dataset["dataset_id"]

            if not confirm:
                return {
                    "error": "Confirmation required for dataset deletion",
                    "dataset_id": dataset_id,
                    "action_required": "Set confirm=true to proceed"
                }
            
            # Phase 4 Enhancement: CMC atoms are immutable - we can't delete them
            # Instead, we mark the dataset as archived in CMC
            archive_atom_id = None
            if self.memory and archive:
                try:
                    from cmc_service.models import AtomCreate, AtomContent
                    
                    # Create archive marker atom
                    content_str = f"Dataset Archive Marker: {dataset_id}\n\n"
                    content_str += f"Dataset Name: {dataset.get('dataset_name', '')}\n"
                    content_str += f"Archived At: {datetime.now().isoformat()}\n"
                    content_str += f"Original Dataset: {json.dumps(dataset, indent=2)}"
                    
                    atom_create = AtomCreate(
                        modality="text",
                        content=AtomContent(inline=content_str),
                        tags={
                            "type": "dataset_archive",
                            "dataset_id": dataset_id,
                            "archived": True
                        },
                        metadata={
                            "dataset_id": dataset_id,
                            "archived": True,
                            "archived_at": datetime.now().isoformat(),
                            "original_dataset": dataset
                        }
                    )
                    archive_atom = self.memory.create_atom(atom_create)
                    archive_atom_id = archive_atom.id
                    log(f"Created archive marker atom {archive_atom_id} for dataset {dataset_id}")
                except Exception as e:
                    log(f"Warning: Failed to create archive marker in CMC: {e}")
            
            if archive:
                # Archive dataset (mark as archived, don't delete)
                dataset["archived"] = True
                dataset["archived_at"] = datetime.now().isoformat()
                self._save_dataset_store()
                return {
                    "success": True,
                    "dataset_id": dataset_id,
                    "archived": True,
                    "cmc_archive_marker": archive_atom_id,
                    "message": f"Dataset '{dataset['dataset_name']}' archived successfully (CMC atoms are immutable)"
                }
            else:
                # Actually delete (not recommended, but possible for local store)
                del self.datasets[dataset_id]
                name_key = dataset["dataset_name"].lower()
                if name_key in self._dataset_index:
                    del self._dataset_index[name_key]
                self._save_dataset_store()
                return {
                    "success": True,
                    "dataset_id": dataset_id,
                    "deleted": True,
                    "warning": "Dataset deleted from local store. CMC atoms remain immutable.",
                    "message": f"Dataset '{dataset['dataset_name']}' deleted from local store"
                }
        except Exception as e:
            return {"error": f"Failed to delete dataset: {str(e)}"}
    
    # Application Lifecycle Tools (Tools 30-32)
    
    def _resolve_dataset(self, dataset_id: Optional[str], dataset_name: Optional[str]) -> Optional[Dict[str, Any]]:
        """Helper to resolve dataset by ID or name."""
        if dataset_id and dataset_id in self.datasets:
            return self.datasets[dataset_id]
        if dataset_name:
            name_key = dataset_name.lower()
            dataset_id = self._dataset_index.get(name_key)
            if dataset_id and dataset_id in self.datasets:
                return self.datasets[dataset_id]
            for did, dataset in self.datasets.items():
                if dataset.get("dataset_name") == dataset_name:
                    self._dataset_index[name_key] = did
                    return dataset
        if self.dataset_store_file:
            self._refresh_dataset_cache()
            if dataset_id and dataset_id in self.datasets:
                return self.datasets[dataset_id]
            if dataset_name:
                name_key = dataset_name.lower()
                dataset_id = self._dataset_index.get(name_key)
                if dataset_id and dataset_id in self.datasets:
                    return self.datasets[dataset_id]
        return None
    
    def _resolve_application(self, app_id: Optional[str], app_name: Optional[str]) -> Optional[Dict[str, Any]]:
        """Helper to resolve application by ID or name."""
        if app_id and app_id in self.applications:
            return self.applications[app_id]
        if app_name:
            name_key = app_name.lower()
            app_id = self._application_index.get(name_key)
            if app_id and app_id in self.applications:
                return self.applications[app_id]
            for aid, application in self.applications.items():
                if application.get("app_name") == app_name:
                    self._application_index[name_key] = aid
                    return application
        if self.application_store_file:
            self._refresh_application_cache()
            if app_id and app_id in self.applications:
                return self.applications[app_id]
            if app_name:
                name_key = app_name.lower()
                app_id = self._application_index.get(name_key)
                if app_id and app_id in self.applications:
                    return self.applications[app_id]
        return None

    # ------------------------------------------------------------------
    # Persistence helpers

    def _load_dataset_store(self) -> None:
        if not self.dataset_store_file:
            return
        self._init_dataset_store()
        self._refresh_dataset_cache()

    def _save_dataset_store(self) -> None:
        # SQLite-backed datasets commit on each write; refreshing cache is sufficient.
        self._refresh_dataset_cache()

    def _load_application_store(self) -> None:
        if not self.application_store_file:
            return
        self._init_application_store()
        self._refresh_application_cache()

    def _save_application_store(self) -> None:
        # SQLite-backed applications commit on write; refreshing cache is sufficient.
        self._refresh_application_cache()

    def _load_intuition_store(self) -> None:
        if not self.intuition_store_file or not os.path.exists(self.intuition_store_file):
            return
        try:
            with open(self.intuition_store_file, "r", encoding="utf-8") as handle:
                data = json.load(handle)
        except Exception as exc:
            log(f"Warning: Failed to load intuition store: {exc}")
            return

        traces = data.get("traces") if isinstance(data, dict) else {}
        history = data.get("confidence_history") if isinstance(data, dict) else []

        if isinstance(traces, dict):
            self.intuition_traces = {
                decision_id: list(records) if isinstance(records, list) else []
                for decision_id, records in traces.items()
            }
        if isinstance(history, list):
            self.confidence_history = history

    def _save_intuition_store(self) -> None:
        if not self.intuition_store_file:
            return
        payload = {
            "traces": self.intuition_traces,
            "confidence_history": self.confidence_history,
        }
        try:
            Path(self.intuition_store_file).parent.mkdir(parents=True, exist_ok=True)
            with open(self.intuition_store_file, "w", encoding="utf-8") as handle:
                json.dump(payload, handle, indent=2, ensure_ascii=False)
        except Exception as exc:
            log(f"Warning: Failed to save intuition store: {exc}")

    def _init_dataset_store(self) -> None:
        if not self.dataset_store_file:
            return
        with sqlite3.connect(self.dataset_store_file) as conn:
            conn.execute(
                """
                CREATE TABLE IF NOT EXISTS datasets (
                    dataset_id TEXT PRIMARY KEY,
                    dataset_name TEXT UNIQUE,
                    description TEXT,
                    schema_json TEXT,
                    tags_json TEXT,
                    created_at TEXT,
                    data_count INTEGER DEFAULT 0
                )
                """
            )
            conn.execute(
                """
                CREATE TABLE IF NOT EXISTS dataset_records (
                    record_id INTEGER PRIMARY KEY AUTOINCREMENT,
                    dataset_id TEXT,
                    record_json TEXT,
                    created_at TEXT
                )
                """
            )
            conn.execute(
                "CREATE INDEX IF NOT EXISTS idx_dataset_records_dataset_id ON dataset_records(dataset_id)"
            )

    def _init_application_store(self) -> None:
        if not self.application_store_file:
            return
        with sqlite3.connect(self.application_store_file) as conn:
            conn.execute(
                """
                CREATE TABLE IF NOT EXISTS applications (
                    app_id TEXT PRIMARY KEY,
                    app_name TEXT UNIQUE,
                    app_type TEXT,
                    config_json TEXT,
                    dependencies_json TEXT,
                    created_at TEXT,
                    status TEXT,
                    environment TEXT,
                    deployed_at TEXT,
                    health_status TEXT
                )
                """
            )
            conn.execute(
                """
                CREATE TABLE IF NOT EXISTS application_events (
                    event_id INTEGER PRIMARY KEY AUTOINCREMENT,
                    app_id TEXT,
                    event_type TEXT,
                    payload_json TEXT,
                    created_at TEXT
                )
                """
            )
            conn.execute(
                "CREATE INDEX IF NOT EXISTS idx_application_events_app_id ON application_events(app_id)"
            )

    def _refresh_dataset_cache(self) -> None:
        if not self.dataset_store_file:
            return
        self.datasets = {}
        self._dataset_index.clear()
        with sqlite3.connect(self.dataset_store_file) as conn:
            conn.row_factory = sqlite3.Row
            datasets = conn.execute(
                "SELECT dataset_id, dataset_name, description, schema_json, tags_json, created_at, data_count FROM datasets ORDER BY created_at"
            ).fetchall()

        for row in datasets:
            dataset = {
                "dataset_id": row["dataset_id"],
                "dataset_name": row["dataset_name"],
                "description": row["description"],
                "schema": json.loads(row["schema_json"]) if row["schema_json"] else {},
                "tags": json.loads(row["tags_json"]) if row["tags_json"] else {},
                "created_at": row["created_at"],
                "data_count": row["data_count"],
                "records": [],
            }
            self.datasets[row["dataset_id"]] = dataset
            if row["dataset_name"]:
                self._dataset_index[row["dataset_name"].lower()] = row["dataset_id"]

    def _refresh_application_cache(self) -> None:
        if not self.application_store_file:
            return
        self.applications = {}
        self._application_index.clear()
        with sqlite3.connect(self.application_store_file) as conn:
            conn.row_factory = sqlite3.Row
            apps = conn.execute(
                "SELECT app_id, app_name, app_type, config_json, dependencies_json, created_at, status, environment, deployed_at, health_status FROM applications ORDER BY created_at"
            ).fetchall()
            events = conn.execute(
                "SELECT app_id, event_type, payload_json, created_at FROM application_events ORDER BY created_at"
            ).fetchall()

        events_by_app: Dict[str, List[Dict[str, Any]]] = {}
        for event in events:
            payload = json.loads(event["payload_json"]) if event["payload_json"] else {}
            payload["timestamp"] = event["created_at"]
            payload["event_type"] = event["event_type"]
            events_by_app.setdefault(event["app_id"], []).append(payload)

        for row in apps:
            app_id = row["app_id"]
            deployment_history = [
                {k: v for k, v in event.items() if k != "event_type"}
                for event in events_by_app.get(app_id, [])
                if event.get("event_type") == "deploy"
            ]
            lifecycle_events = [
                event for event in events_by_app.get(app_id, []) if event.get("event_type") == "lifecycle"
            ]
            application = {
                "app_id": app_id,
                "app_name": row["app_name"],
                "app_type": row["app_type"],
                "config": json.loads(row["config_json"]) if row["config_json"] else {},
                "dependencies": json.loads(row["dependencies_json"]) if row["dependencies_json"] else [],
                "created_at": row["created_at"],
                "status": row["status"] or "created",
                "environment": row["environment"],
                "deployed_at": row["deployed_at"],
                "health_status": row["health_status"],
                "deployment_history": deployment_history,
                "lifecycle_events": lifecycle_events,
            }
            self.applications[app_id] = application
            if row["app_name"]:
                self._application_index[row["app_name"].lower()] = app_id

    def _update_consciousness_metrics(self) -> None:
        if not self.telemetry_file:
            return
        try:
            Path(self.telemetry_file).parent.mkdir(parents=True, exist_ok=True)
            if self.dataset_store_file:
                dataset_record_count = sum(ds.get("data_count", 0) for ds in self.datasets.values())
            else:
                dataset_record_count = sum(len(ds.get("records", [])) for ds in self.datasets.values())
            dataset_metrics = {
                "count": len(self.datasets),
                "records": dataset_record_count,
            }
            deployed_apps = sum(1 for app in self.applications.values() if app.get("status") == "deployed")
            application_metrics = {
                "count": len(self.applications),
                "deployed": deployed_apps,
            }
            average_confidence = (
                sum(entry.get("confidence", 0.0) for entry in self.confidence_history) / len(self.confidence_history)
                if self.confidence_history else 0.0
            )
            intuition_metrics = {
                "decisions": len(self.intuition_traces),
                "records": sum(len(v) for v in self.intuition_traces.values()),
            }
            payload = {
                "timestamp": datetime.now().isoformat(),
                "datasets": dataset_metrics,
                "applications": application_metrics,
                "confidence": {
                    "entries": len(self.confidence_history),
                    "average": round(average_confidence, 4),
                    "latest": self.confidence_history[-1] if self.confidence_history else None,
                },
                "intuition": intuition_metrics,
            }
            with open(self.telemetry_file, "w", encoding="utf-8") as handle:
                json.dump(payload, handle, indent=2, ensure_ascii=False)
        except Exception as exc:
            log(f"Warning: Failed to update telemetry metrics: {exc}")
    
    def create_application(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """Define new application (Phase 4 enhancement - CMC integration)"""
        app_name = args.get("app_name")
        app_type = args.get("app_type")
        config = args.get("config", {})
        dependencies = args.get("dependencies", [])
        
        try:
            if not app_name:
                return {"error": "Application name is required"}

            if not self.application_store_file:
                name_key = app_name.lower()
                if name_key in self._application_index:
                    existing_id = self._application_index[name_key]
                    existing = self.applications.get(existing_id)
                    return {
                        "success": False,
                        "error": f"Application '{app_name}' already exists",
                        "application": existing,
                    }

                app_id = str(uuid.uuid4())
                application = {
                    "app_id": app_id,
                    "app_name": app_name,
                    "app_type": app_type,
                    "config": config,
                    "dependencies": dependencies,
                    "created_at": datetime.now().isoformat(),
                    "status": "created",
                    "deployment_history": [],
                    "lifecycle_events": [],
                }
                
                # Phase 4 Enhancement: Store application in CMC if memory available
                atom_id = None
                if self.memory:
                    try:
                        from cmc_service.models import AtomCreate, AtomContent
                        
                        content_str = f"Application: {app_name}\n\n"
                        content_str += f"Type: {app_type}\n"
                        content_str += f"Status: created\n"
                        content_str += f"Config: {json.dumps(config, indent=2)}\n"
                        if dependencies:
                            content_str += f"Dependencies: {json.dumps(dependencies, indent=2)}"
                        
                        atom_create = AtomCreate(
                            modality="text",
                            content=AtomContent(inline=content_str),
                            tags={
                                "type": "application",
                                "app_id": app_id,
                                "app_name": app_name,
                                "app_type": app_type,
                                "status": "created"
                            },
                            metadata={
                                "app_id": app_id,
                                "app_name": app_name,
                                "app_type": app_type,
                                "config": config,
                                "dependencies": dependencies,
                                "status": "created",
                                "created_at": application["created_at"]
                            }
                        )
                        atom = self.memory.create_atom(atom_create)
                        atom_id = atom.id
                        log(f"Stored application {app_id} in CMC as atom {atom_id}")
                    except Exception as e:
                        log(f"Warning: Failed to store application in CMC: {e}")
                
                self.applications[app_id] = application
                self._application_index[name_key] = app_id
                self._save_application_store()
                self._update_consciousness_metrics()
                return {
                    "success": True,
                    "application": application,
                    "app_id": app_id,
                    "atom_id": atom_id,
                    "message": f"Application '{app_name}' created successfully"
                }

            self._init_application_store()
            app_id = str(uuid.uuid4())
            created_at = datetime.now().isoformat()
            try:
                with sqlite3.connect(self.application_store_file) as conn:
                    conn.execute(
                        """
                        INSERT INTO applications (
                            app_id, app_name, app_type, config_json, dependencies_json,
                            created_at, status, environment, deployed_at, health_status
                        ) VALUES (?, ?, ?, ?, ?, ?, ?, NULL, NULL, NULL)
                        """,
                        (
                            app_id,
                            app_name,
                            app_type,
                            json.dumps(config),
                            json.dumps(dependencies),
                            created_at,
                            "created",
                        ),
                    )
                    conn.execute(
                        """
                        INSERT INTO application_events (app_id, event_type, payload_json, created_at)
                        VALUES (?, ?, ?, ?)
                        """,
                        (
                            app_id,
                            "create",
                            json.dumps({"config": config, "dependencies": dependencies}),
                            created_at,
                        ),
                    )
            except sqlite3.IntegrityError:
                self._refresh_application_cache()
                existing_id = self._application_index.get(app_name.lower())
                existing = self.applications.get(existing_id) if existing_id else None
                return {
                    "success": False,
                    "error": f"Application '{app_name}' already exists",
                    "application": existing,
                }

            self._refresh_application_cache()
            self._update_consciousness_metrics()
            application = self.applications.get(app_id, {
                "app_id": app_id,
                "app_name": app_name,
                "app_type": app_type,
                "config": config,
                "dependencies": dependencies,
                "created_at": created_at,
                "status": "created",
                "deployment_history": [],
                "lifecycle_events": [],
            })
            
            # Phase 4 Enhancement: Store application in CMC if memory available
            atom_id = None
            if self.memory:
                try:
                    from cmc_service.models import AtomCreate, AtomContent
                    
                    content_str = f"Application: {app_name}\n\n"
                    content_str += f"Type: {app_type}\n"
                    content_str += f"Status: created\n"
                    content_str += f"Config: {json.dumps(config, indent=2)}\n"
                    if dependencies:
                        content_str += f"Dependencies: {json.dumps(dependencies, indent=2)}"
                    
                    atom_create = AtomCreate(
                        modality="text",
                        content=AtomContent(inline=content_str),
                        tags={
                            "type": "application",
                            "app_id": app_id,
                            "app_name": app_name,
                            "app_type": app_type,
                            "status": "created"
                        },
                        metadata={
                            "app_id": app_id,
                            "app_name": app_name,
                            "app_type": app_type,
                            "config": config,
                            "dependencies": dependencies,
                            "status": "created",
                            "created_at": created_at
                        }
                    )
                    atom = self.memory.create_atom(atom_create)
                    atom_id = atom.id
                    log(f"Stored application {app_id} in CMC as atom {atom_id}")
                except Exception as e:
                    log(f"Warning: Failed to store application in CMC: {e}")
            
            return {
                "success": True,
                "application": application,
                "app_id": app_id,
                "atom_id": atom_id,
                "message": f"Application '{app_name}' created successfully"
            }
        except Exception as e:
            return {"error": f"Failed to create application: {str(e)}"}
    
    def deploy_application(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """Deploy application to environment (Phase 4 enhancement - CMC integration)"""
        app_id = args.get("app_id")
        app_name = args.get("app_name")
        environment = args.get("environment")
        config_overrides = args.get("config_overrides", {})
        health_checks = args.get("health_checks", True)
        
        try:
            application = self._resolve_application(app_id, app_name)
            if not application:
                identifier = app_id or app_name or "unknown"
                return {"error": f"Application '{identifier}' not found"}
            app_id = application["app_id"]

            if not self.application_store_file:
                application["status"] = "deploying"
                application["environment"] = environment
                application["deployed_at"] = datetime.now().isoformat()
                
                if health_checks:
                    application["health_status"] = "healthy"  # Placeholder
                
                application["status"] = "deployed"
                deployment_record = {
                    "timestamp": datetime.now().isoformat(),
                    "environment": environment,
                    "config_overrides": config_overrides,
                    "health_checks_passed": bool(health_checks),
                }
                application.setdefault("deployment_history", []).append(deployment_record)
                
                # Phase 4 Enhancement: Store deployment record in CMC if memory available
                deployment_atom_id = None
                if self.memory:
                    try:
                        from cmc_service.models import AtomCreate, AtomContent
                        
                        content_str = f"Application Deployment: {application.get('app_name', app_id)}\n\n"
                        content_str += f"Environment: {environment}\n"
                        content_str += f"Status: deployed\n"
                        content_str += f"Health Checks: {'passed' if health_checks else 'skipped'}\n"
                        if config_overrides:
                            content_str += f"Config Overrides: {json.dumps(config_overrides, indent=2)}"
                        
                        atom_create = AtomCreate(
                            modality="text",
                            content=AtomContent(inline=content_str),
                            tags={
                                "type": "application_deployment",
                                "app_id": app_id,
                                "environment": environment,
                                "status": "deployed"
                            },
                            metadata={
                                "app_id": app_id,
                                "app_name": application.get("app_name"),
                                "environment": environment,
                                "config_overrides": config_overrides,
                                "health_checks_passed": bool(health_checks),
                                "deployed_at": deployment_record["timestamp"]
                            }
                        )
                        atom = self.memory.create_atom(atom_create)
                        deployment_atom_id = atom.id
                        log(f"Stored deployment record for app {app_id} in CMC as atom {deployment_atom_id}")
                    except Exception as e:
                        log(f"Warning: Failed to store deployment in CMC: {e}")
                
                self._save_application_store()
                self._update_consciousness_metrics()
            else:
                self._init_application_store()
                deployed_at = datetime.now().isoformat()
                with sqlite3.connect(self.application_store_file) as conn:
                    conn.execute(
                        """
                        UPDATE applications
                        SET status = ?, environment = ?, deployed_at = ?, health_status = ?
                        WHERE app_id = ?
                        """,
                        (
                            "deployed",
                            environment,
                            deployed_at,
                            "healthy" if health_checks else "unknown",
                            app_id,
                        ),
                    )
                    conn.execute(
                        """
                        INSERT INTO application_events (app_id, event_type, payload_json, created_at)
                        VALUES (?, ?, ?, ?)
                        """,
                        (
                            app_id,
                            "deploy",
                            json.dumps({
                                "environment": environment,
                                "config_overrides": config_overrides,
                                "health_checks_passed": bool(health_checks),
                            }),
                            deployed_at,
                        ),
                    )
                # Phase 4 Enhancement: Store deployment record in CMC if memory available
                deployment_atom_id = None
                if self.memory:
                    try:
                        from cmc_service.models import AtomCreate, AtomContent
                        
                        content_str = f"Application Deployment: {application.get('app_name', app_id)}\n\n"
                        content_str += f"Environment: {environment}\n"
                        content_str += f"Status: deployed\n"
                        content_str += f"Health Checks: {'passed' if health_checks else 'skipped'}\n"
                        if config_overrides:
                            content_str += f"Config Overrides: {json.dumps(config_overrides, indent=2)}"
                        
                        atom_create = AtomCreate(
                            modality="text",
                            content=AtomContent(inline=content_str),
                            tags={
                                "type": "application_deployment",
                                "app_id": app_id,
                                "environment": environment,
                                "status": "deployed"
                            },
                            metadata={
                                "app_id": app_id,
                                "app_name": application.get("app_name"),
                                "environment": environment,
                                "config_overrides": config_overrides,
                                "health_checks_passed": bool(health_checks),
                                "deployed_at": deployed_at
                            }
                        )
                        atom = self.memory.create_atom(atom_create)
                        deployment_atom_id = atom.id
                        log(f"Stored deployment record for app {app_id} in CMC as atom {deployment_atom_id}")
                    except Exception as e:
                        log(f"Warning: Failed to store deployment in CMC: {e}")
                
                self._refresh_application_cache()
                self._update_consciousness_metrics()
                application = self.applications.get(app_id, application)
            
            return {
                "success": True,
                "app_id": app_id,
                "environment": environment,
                "health_checks_passed": health_checks,
                "deployment_atom_id": deployment_atom_id if 'deployment_atom_id' in locals() else None,
                "message": f"Application '{application['app_name']}' deployed to {environment}"
            }
        except Exception as e:
            return {"error": f"Failed to deploy application: {str(e)}"}
    
    def manage_application_lifecycle(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """Start/stop/monitor applications (Phase 4 enhancement - CMC integration)"""
        app_id = args.get("app_id")
        app_name = args.get("app_name")
        action = args.get("action")
        timeout = args.get("timeout", 30)
        
        try:
            application = self._resolve_application(app_id, app_name)
            if not application:
                identifier = app_id or app_name or "unknown"
                return {"error": f"Application '{identifier}' not found"}
            app_id = application["app_id"]
            
            if action == "status":
                if self.application_store_file:
                    self._refresh_application_cache()
                    application = self.applications.get(app_id, application)
                
                # Phase 4 Enhancement: Query CMC for application status if memory available
                cmc_status = None
                if self.memory:
                    try:
                        atoms = list(self.memory.list_atoms(tag=f"app_id:{app_id}", limit=1))
                        if atoms:
                            latest_atom = atoms[0]
                            if latest_atom.metadata:
                                cmc_status = latest_atom.metadata.get("status")
                    except Exception as e:
                        log(f"Warning: Failed to query CMC for app status: {e}")
                
                return {
                    "success": True,
                    "app_id": app_id,
                    "status": application.get("status", "unknown"),
                    "environment": application.get("environment"),
                    "health_status": application.get("health_status", "unknown"),
                    "cmc_status": cmc_status,
                    "cmc_enabled": bool(self.memory)
                }
            elif action == "logs":
                logs: List[Dict[str, Any]]
                if self.application_store_file:
                    self._refresh_application_cache()
                    application = self.applications.get(app_id, application)
                    logs = application.get("lifecycle_events", [])
                else:
                    logs = application.get("lifecycle_events", [])
                
                # Phase 4 Enhancement: Query CMC for lifecycle events if memory available
                if self.memory:
                    try:
                        atoms = list(self.memory.list_atoms(tag=f"app_id:{app_id}", limit=100))
                        for atom in atoms:
                            if atom.metadata and atom.metadata.get("type") == "application_lifecycle":
                                logs.append({
                                    "timestamp": atom.metadata.get("timestamp"),
                                    "action": atom.metadata.get("action"),
                                    "timeout": atom.metadata.get("timeout"),
                                    "atom_id": atom.id
                                })
                    except Exception as e:
                        log(f"Warning: Failed to query CMC for lifecycle logs: {e}")
                
                return {
                    "success": True,
                    "app_id": app_id,
                    "logs": logs,
                    "cmc_enabled": bool(self.memory),
                    "message": "Lifecycle events retrieved" if logs else "No lifecycle events recorded"
                }
            else:
                lifecycle_event = {
                    "timestamp": datetime.now().isoformat(),
                    "action": action,
                    "timeout": timeout,
                }
                
                # Phase 4 Enhancement: Store lifecycle event in CMC if memory available
                lifecycle_atom_id = None
                if self.memory:
                    try:
                        from cmc_service.models import AtomCreate, AtomContent
                        
                        content_str = f"Application Lifecycle Event: {application.get('app_name', app_id)}\n\n"
                        content_str += f"Action: {action}\n"
                        content_str += f"Timeout: {timeout}s"
                        
                        atom_create = AtomCreate(
                            modality="text",
                            content=AtomContent(inline=content_str),
                            tags={
                                "type": "application_lifecycle",
                                "app_id": app_id,
                                "action": action
                            },
                            metadata={
                                "app_id": app_id,
                                "app_name": application.get("app_name"),
                                "action": action,
                                "timeout": timeout,
                                "timestamp": lifecycle_event["timestamp"]
                            }
                        )
                        atom = self.memory.create_atom(atom_create)
                        lifecycle_atom_id = atom.id
                        log(f"Stored lifecycle event for app {app_id} in CMC as atom {lifecycle_atom_id}")
                    except Exception as e:
                        log(f"Warning: Failed to store lifecycle event in CMC: {e}")
                
                if not self.application_store_file:
                    application["status"] = action
                    application.setdefault("lifecycle_events", []).append(lifecycle_event)
                    self._save_application_store()
                    self._update_consciousness_metrics()
                else:
                    self._init_application_store()
                    now = datetime.now().isoformat()
                    with sqlite3.connect(self.application_store_file) as conn:
                        conn.execute(
                            "UPDATE applications SET status = ? WHERE app_id = ?",
                            (action, app_id),
                        )
                        conn.execute(
                            """
                            INSERT INTO application_events (app_id, event_type, payload_json, created_at)
                            VALUES (?, ?, ?, ?)
                            """,
                            (
                                app_id,
                                "lifecycle",
                                json.dumps({"action": action, "timeout": timeout}),
                                now,
                            ),
                        )
                    self._refresh_application_cache()
                    self._update_consciousness_metrics()
                    application = self.applications.get(app_id, application)
                return {
                    "success": True,
                    "app_id": app_id,
                    "action": action,
                    "status": application["status"],
                    "lifecycle_atom_id": lifecycle_atom_id,
                    "message": f"Application {action} completed"
                }
        except Exception as e:
            return {"error": f"Failed to manage application lifecycle: {str(e)}"}
    
    # Autonomous Protocol Tools (Tools 33-41)
    
    def start_autonomous_operation(self, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """Start autonomous operation with safety checklist (Phase 4 enhancement - CMC integration)"""
        try:
            task = arguments.get("task", "")
            confidence = arguments.get("confidence", 0.70)
            
            if not task:
                return {"success": False, "error": "Task is required"}
            
            # Store autonomous operation state
            self.autonomous_state = {
                "is_active": True,
                "is_paused": False,
                "current_task": task,
                "confidence_level": confidence,
                "start_time": datetime.now().isoformat(),
                "last_check_time": None,
                "issues_count": 0,
                "fixes_applied": []
            }
            
            # Run initial checklist
            checklist_result = self._run_autonomous_checklist()
            
            # Phase 4 Enhancement: Store autonomous operation start in CMC if memory available
            operation_atom_id = None
            if self.memory:
                try:
                    from cmc_service.models import AtomCreate, AtomContent
                    
                    content_str = f"Autonomous Operation Started\n\n"
                    content_str += f"Task: {task}\n"
                    content_str += f"Confidence: {confidence}\n"
                    content_str += f"Checklist: {'passed' if checklist_result.get('can_proceed') else 'failed'}"
                    
                    atom_create = AtomCreate(
                        modality="text",
                        content=AtomContent(inline=content_str),
                        tags={
                            "type": "autonomous_operation",
                            "status": "started",
                            "action": "start"
                        },
                        metadata={
                            "task": task,
                            "confidence": confidence,
                            "checklist_result": checklist_result,
                            "start_time": self.autonomous_state["start_time"]
                        }
                    )
                    atom = self.memory.create_atom(atom_create)
                    operation_atom_id = atom.id
                    log(f"Stored autonomous operation start in CMC as atom {operation_atom_id}")
                except Exception as e:
                    log(f"Warning: Failed to store autonomous operation in CMC: {e}")
            
            if checklist_result["can_proceed"]:
                return {
                    "success": True,
                    "message": "Autonomous operation started successfully",
                    "task": task,
                    "confidence": confidence,
                    "checklist_result": checklist_result,
                    "operation_atom_id": operation_atom_id
                }
            else:
                return {
                    "success": False,
                    "message": "Cannot start autonomous operation - checklist failed",
                    "failed_checks": checklist_result.get("failed_checks", []),
                    "suggestions": checklist_result.get("suggestions", []),
                    "operation_atom_id": operation_atom_id
                }
                
        except Exception as e:
            return {"success": False, "error": f"Failed to start autonomous operation: {str(e)}"}
    
    def pause_autonomous_operation(self, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """Pause autonomous operation (Phase 4 enhancement - CMC integration)"""
        try:
            if not hasattr(self, 'autonomous_state') or not self.autonomous_state.get("is_active"):
                return {"success": False, "error": "No active autonomous operation to pause"}
            
            self.autonomous_state["is_paused"] = True
            self.autonomous_state["pause_time"] = datetime.now().isoformat()
            
            # Phase 4 Enhancement: Store pause event in CMC if memory available
            pause_atom_id = None
            if self.memory:
                try:
                    from cmc_service.models import AtomCreate, AtomContent
                    
                    content_str = f"Autonomous Operation Paused\n\n"
                    content_str += f"Task: {self.autonomous_state.get('current_task')}\n"
                    content_str += f"Pause Time: {self.autonomous_state['pause_time']}"
                    
                    atom_create = AtomCreate(
                        modality="text",
                        content=AtomContent(inline=content_str),
                        tags={
                            "type": "autonomous_operation",
                            "status": "paused",
                            "action": "pause"
                        },
                        metadata={
                            "task": self.autonomous_state.get("current_task"),
                            "pause_time": self.autonomous_state["pause_time"]
                        }
                    )
                    atom = self.memory.create_atom(atom_create)
                    pause_atom_id = atom.id
                    log(f"Stored autonomous operation pause in CMC as atom {pause_atom_id}")
                except Exception as e:
                    log(f"Warning: Failed to store pause event in CMC: {e}")
            
            return {
                "success": True,
                "message": "Autonomous operation paused",
                "task": self.autonomous_state.get("current_task"),
                "pause_atom_id": pause_atom_id
            }
            
        except Exception as e:
            return {"success": False, "error": f"Failed to pause autonomous operation: {str(e)}"}
    
    def resume_autonomous_operation(self, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """Resume autonomous operation after pause (Phase 4 enhancement - CMC integration)"""
        try:
            if not hasattr(self, 'autonomous_state') or not self.autonomous_state.get("is_active"):
                return {"success": False, "error": "No active autonomous operation to resume"}
            
            if not self.autonomous_state.get("is_paused"):
                return {"success": False, "error": "Autonomous operation is not paused"}
            
            # Run checklist before resuming
            checklist_result = self._run_autonomous_checklist()
            
            resume_atom_id = None
            if checklist_result["can_proceed"]:
                self.autonomous_state["is_paused"] = False
                self.autonomous_state["resume_time"] = datetime.now().isoformat()
                
                # Phase 4 Enhancement: Store resume event in CMC if memory available
                if self.memory:
                    try:
                        from cmc_service.models import AtomCreate, AtomContent
                        
                        content_str = f"Autonomous Operation Resumed\n\n"
                        content_str += f"Task: {self.autonomous_state.get('current_task')}\n"
                        content_str += f"Resume Time: {self.autonomous_state['resume_time']}"
                        
                        atom_create = AtomCreate(
                            modality="text",
                            content=AtomContent(inline=content_str),
                            tags={
                                "type": "autonomous_operation",
                                "status": "active",
                                "action": "resume"
                            },
                            metadata={
                                "task": self.autonomous_state.get("current_task"),
                                "resume_time": self.autonomous_state["resume_time"],
                                "checklist_result": checklist_result
                            }
                        )
                        atom = self.memory.create_atom(atom_create)
                        resume_atom_id = atom.id
                        log(f"Stored autonomous operation resume in CMC as atom {resume_atom_id}")
                    except Exception as e:
                        log(f"Warning: Failed to store resume event in CMC: {e}")
                
                return {
                    "success": True,
                    "message": "Autonomous operation resumed",
                    "task": self.autonomous_state.get("current_task"),
                    "checklist_result": checklist_result,
                    "resume_atom_id": resume_atom_id
                }
            else:
                return {
                    "success": False,
                    "message": "Cannot resume autonomous operation - checklist failed",
                    "failed_checks": checklist_result.get("failed_checks", [])
                }
                
        except Exception as e:
            return {"success": False, "error": f"Failed to resume autonomous operation: {str(e)}"}
    
    def stop_autonomous_operation(self, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """Stop autonomous operation completely (Phase 4 enhancement - CMC integration)"""
        try:
            if not hasattr(self, 'autonomous_state') or not self.autonomous_state.get("is_active"):
                return {"success": False, "error": "No active autonomous operation to stop"}
            
            task = self.autonomous_state.get("current_task")
            stop_time = datetime.now().isoformat()
            
            # Phase 4 Enhancement: Store stop event in CMC if memory available
            stop_atom_id = None
            if self.memory:
                try:
                    from cmc_service.models import AtomCreate, AtomContent
                    
                    content_str = f"Autonomous Operation Stopped\n\n"
                    content_str += f"Task: {task}\n"
                    content_str += f"Stop Time: {stop_time}\n"
                    content_str += f"Duration: {self.autonomous_state.get('start_time', 'unknown')}  {stop_time}"
                    
                    atom_create = AtomCreate(
                        modality="text",
                        content=AtomContent(inline=content_str),
                        tags={
                            "type": "autonomous_operation",
                            "status": "stopped",
                            "action": "stop"
                        },
                        metadata={
                            "task": task,
                            "stop_time": stop_time,
                            "start_time": self.autonomous_state.get("start_time"),
                            "issues_count": self.autonomous_state.get("issues_count", 0),
                            "fixes_applied": self.autonomous_state.get("fixes_applied", [])
                        }
                    )
                    atom = self.memory.create_atom(atom_create)
                    stop_atom_id = atom.id
                    log(f"Stored autonomous operation stop in CMC as atom {stop_atom_id}")
                except Exception as e:
                    log(f"Warning: Failed to store stop event in CMC: {e}")
            
            self.autonomous_state = {
                "is_active": False,
                "is_paused": False,
                "current_task": None,
                "confidence_level": 0.0,
                "stop_time": stop_time
            }
            
            return {
                "success": True,
                "message": "Autonomous operation stopped",
                "task": task,
                "stop_atom_id": stop_atom_id
            }
            
        except Exception as e:
            return {"success": False, "error": f"Failed to stop autonomous operation: {str(e)}"}
    
    def get_autonomous_status(self, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """Get current status of autonomous operation (Phase 4 enhancement - CMC integration)"""
        try:
            if not hasattr(self, 'autonomous_state'):
                return {
                    "success": True,
                    "is_active": False,
                    "is_paused": False,
                    "current_task": None,
                    "message": "No autonomous operation state"
                }
            
            # Phase 4 Enhancement: Query CMC for latest autonomous operation status if memory available
            cmc_status = None
            if self.memory:
                try:
                    atoms = list(self.memory.list_atoms(tag="autonomous_operation", limit=1))
                    if atoms:
                        latest_atom = atoms[0]
                        if latest_atom.metadata:
                            cmc_status = {
                                "latest_action": latest_atom.metadata.get("action"),
                                "task": latest_atom.metadata.get("task"),
                                "timestamp": latest_atom.metadata.get("start_time") or latest_atom.metadata.get("stop_time"),
                                "atom_id": latest_atom.id
                            }
                except Exception as e:
                    log(f"Warning: Failed to query CMC for autonomous status: {e}")
            
            return {
                "success": True,
                "is_active": self.autonomous_state.get("is_active", False),
                "is_paused": self.autonomous_state.get("is_paused", False),
                "current_task": self.autonomous_state.get("current_task"),
                "confidence_level": self.autonomous_state.get("confidence_level", 0.0),
                "start_time": self.autonomous_state.get("start_time"),
                "last_check_time": self.autonomous_state.get("last_check_time"),
                "issues_count": self.autonomous_state.get("issues_count", 0),
                "fixes_applied": self.autonomous_state.get("fixes_applied", []),
                "cmc_status": cmc_status,
                "cmc_enabled": bool(self.memory)
            }
            
        except Exception as e:
            return {"success": False, "error": f"Failed to get autonomous status: {str(e)}"}
    
    def run_autonomous_checklist(self, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """Run autonomous protocol checklist for safety validation (Phase 4 enhancement - CMC integration)"""
        try:
            checklist_result = self._run_autonomous_checklist()
            
            # Phase 4 Enhancement: Store checklist result in CMC if memory available
            checklist_atom_id = None
            if self.memory:
                try:
                    from cmc_service.models import AtomCreate, AtomContent
                    
                    content_str = f"Autonomous Operation Checklist Run\n\n"
                    content_str += f"Can Proceed: {checklist_result.get('can_proceed')}\n"
                    content_str += f"Confidence Score: {checklist_result.get('confidence_score', 0.0)}\n"
                    content_str += f"Safety Score: {checklist_result.get('safety_score', 0.0)}\n"
                    content_str += f"Passed Checks: {checklist_result.get('passed_checks', 0)}\n"
                    if checklist_result.get('failed_checks'):
                        content_str += f"Failed Checks: {', '.join(checklist_result.get('failed_checks', []))}"
                    
                    atom_create = AtomCreate(
                        modality="text",
                        content=AtomContent(inline=content_str),
                        tags={
                            "type": "autonomous_checklist",
                            "can_proceed": str(checklist_result.get("can_proceed", False))
                        },
                        metadata={
                            "checklist_result": checklist_result,
                            "timestamp": datetime.now().isoformat()
                        }
                    )
                    atom = self.memory.create_atom(atom_create)
                    checklist_atom_id = atom.id
                    log(f"Stored checklist result in CMC as atom {checklist_atom_id}")
                except Exception as e:
                    log(f"Warning: Failed to store checklist result in CMC: {e}")
            
            # Update last check time in autonomous state
            if hasattr(self, 'autonomous_state'):
                self.autonomous_state["last_check_time"] = datetime.now().isoformat()
            
            checklist_result["checklist_atom_id"] = checklist_atom_id
            return checklist_result
            
        except Exception as e:
            return {"success": False, "error": f"Failed to run autonomous checklist: {str(e)}"}
    
    def fix_autonomous_issues(self, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """Attempt to fix issues found in autonomous operation (Phase 4 enhancement - CMC integration)"""
        try:
            checklist_result = self._run_autonomous_checklist()
            
            fixes_applied = []
            for issue in checklist_result.get("failed_checks", []):
                # Simple fix logic - in real implementation, this would be more sophisticated
                fixes_applied.append(f"Attempted fix for: {issue}")
            
            # Phase 4 Enhancement: Store fix attempts in CMC if memory available
            fix_atom_id = None
            if self.memory and fixes_applied:
                try:
                    from cmc_service.models import AtomCreate, AtomContent
                    
                    content_str = f"Autonomous Operation Fix Attempts\n\n"
                    content_str += f"Fixes Applied: {len(fixes_applied)}\n"
                    content_str += f"Remaining Issues: {len(checklist_result.get('failed_checks', [])) - len(fixes_applied)}\n"
                    content_str += f"\nFixes:\n" + "\n".join(f"- {fix}" for fix in fixes_applied)
                    
                    atom_create = AtomCreate(
                        modality="text",
                        content=AtomContent(inline=content_str),
                        tags={
                            "type": "autonomous_operation",
                            "action": "fix_issues"
                        },
                        metadata={
                            "fixes_applied": fixes_applied,
                            "remaining_issues": len(checklist_result.get("failed_checks", [])) - len(fixes_applied),
                            "checklist_result": checklist_result,
                            "timestamp": datetime.now().isoformat()
                        }
                    )
                    atom = self.memory.create_atom(atom_create)
                    fix_atom_id = atom.id
                    log(f"Stored fix attempts in CMC as atom {fix_atom_id}")
                except Exception as e:
                    log(f"Warning: Failed to store fix attempts in CMC: {e}")
            
            # Update autonomous state
            if hasattr(self, 'autonomous_state'):
                self.autonomous_state.setdefault("fixes_applied", []).extend(fixes_applied)
                self.autonomous_state["issues_count"] = len(checklist_result.get("failed_checks", [])) - len(fixes_applied)
            
            return {
                "success": True,
                "fixes_applied": fixes_applied,
                "remaining_issues": len(checklist_result.get("failed_checks", [])) - len(fixes_applied),
                "fix_atom_id": fix_atom_id
            }
            
        except Exception as e:
            return {"success": False, "error": f"Failed to fix autonomous issues: {str(e)}"}
    
    def should_continue_autonomous(self, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """Check if autonomous operation should continue (Phase 4 enhancement - CMC integration)"""
        try:
            if not hasattr(self, 'autonomous_state') or not self.autonomous_state.get("is_active"):
                return {
                    "success": True,
                    "should_continue": False,
                    "reason": "Not active"
                }
            
            if self.autonomous_state.get("is_paused"):
                return {
                    "success": True,
                    "should_continue": False,
                    "reason": "Paused"
                }
            
            # Run checklist
            checklist_result = self._run_autonomous_checklist()
            
            # Phase 4 Enhancement: Store continuation check result in CMC if memory available
            check_atom_id = None
            if self.memory:
                try:
                    from cmc_service.models import AtomCreate, AtomContent
                    
                    should_continue = checklist_result.get("can_proceed", False)
                    content_str = f"Autonomous Operation Continuation Check\n\n"
                    content_str += f"Should Continue: {should_continue}\n"
                    content_str += f"Reason: {'All checks passed' if should_continue else 'Checklist failed'}\n"
                    content_str += f"Confidence Score: {checklist_result.get('confidence_score', 0.0)}\n"
                    content_str += f"Safety Score: {checklist_result.get('safety_score', 0.0)}"
                    
                    atom_create = AtomCreate(
                        modality="text",
                        content=AtomContent(inline=content_str),
                        tags={
                            "type": "autonomous_continuation_check",
                            "should_continue": str(should_continue)
                        },
                        metadata={
                            "should_continue": should_continue,
                            "reason": "All checks passed" if should_continue else "Checklist failed",
                            "checklist_result": checklist_result,
                            "timestamp": datetime.now().isoformat()
                        }
                    )
                    atom = self.memory.create_atom(atom_create)
                    check_atom_id = atom.id
                    log(f"Stored continuation check in CMC as atom {check_atom_id}")
                except Exception as e:
                    log(f"Warning: Failed to store continuation check in CMC: {e}")
            
            if checklist_result["can_proceed"]:
                return {
                    "success": True,
                    "should_continue": True,
                    "reason": "All checks passed",
                    "confidence_score": checklist_result.get("confidence_score", 0.0),
                    "safety_score": checklist_result.get("safety_score", 0.0),
                    "check_atom_id": check_atom_id
                }
            else:
                return {
                    "success": True,
                    "should_continue": False,
                    "reason": "Checklist failed",
                    "failed_checks": checklist_result.get("failed_checks", []),
                    "suggestions": checklist_result.get("suggestions", []),
                    "check_atom_id": check_atom_id
                }
                
        except Exception as e:
            return {"success": False, "error": f"Failed to check if should continue: {str(e)}"}
    
    def generate_next_autonomous_task(self, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """Generate next task for autonomous operation (Phase 4 enhancement - CMC integration)"""
        try:
            # Phase 4 Enhancement: Query goal timeline for next task if available
            next_task = "Continue current work and identify next priorities"
            goal_id = None
            
            if hasattr(self, 'goal_nodes') and self.goal_nodes:
                # Find highest priority in-progress goal
                in_progress_goals = [
                    g for g in self.goal_nodes.values()
                    if g.status.value == "in_progress"
                ]
                if in_progress_goals:
                    next_goal = max(in_progress_goals, key=lambda g: (
                        0 if g.priority.value == "critical" else
                        1 if g.priority.value == "high" else
                        2 if g.priority.value == "medium" else 3
                    ))
                    next_task = f"Work on goal: {next_goal.name}"
                    goal_id = next_goal.goal_id
            
            # Phase 4 Enhancement: Store generated task in CMC if memory available
            task_atom_id = None
            if self.memory:
                try:
                    from cmc_service.models import AtomCreate, AtomContent
                    
                    content_str = f"Generated Next Autonomous Task\n\n"
                    content_str += f"Task: {next_task}\n"
                    content_str += f"Goal ID: {goal_id or 'None'}\n"
                    content_str += f"Priority: medium\n"
                    content_str += f"Confidence: 0.70"
                    
                    atom_create = AtomCreate(
                        modality="text",
                        content=AtomContent(inline=content_str),
                        tags={
                            "type": "autonomous_task_generation",
                            "goal_id": goal_id or "none"
                        },
                        metadata={
                            "next_task": next_task,
                            "goal_id": goal_id,
                            "priority": "medium",
                            "confidence": 0.70,
                            "timestamp": datetime.now().isoformat()
                        }
                    )
                    atom = self.memory.create_atom(atom_create)
                    task_atom_id = atom.id
                    log(f"Stored generated task in CMC as atom {task_atom_id}")
                except Exception as e:
                    log(f"Warning: Failed to store generated task in CMC: {e}")
            
            return {
                "success": True,
                "next_task": next_task,
                "goal_id": goal_id,
                "priority": "medium",
                "confidence": 0.70,
                "task_atom_id": task_atom_id,
                "message": "Generated next autonomous task"
            }
            
        except Exception as e:
            return {"success": False, "error": f"Failed to generate next autonomous task: {str(e)}"}
    
    def _run_autonomous_checklist(self) -> Dict[str, Any]:
        """Internal method to run autonomous protocol checklist"""
        try:
            # Simplified checklist - in real implementation, this would use the full checklist system
            checks = [
                {"name": "Confidence Check", "passed": True},
                {"name": "Safety Check", "passed": True},
                {"name": "Goal Alignment", "passed": True},
                {"name": "Quality Standards", "passed": True}
            ]
            
            passed_checks = [check for check in checks if check["passed"]]
            failed_checks = [check for check in checks if not check["passed"]]
            
            can_proceed = len(failed_checks) == 0
            
            return {
                "success": True,
                "can_proceed": can_proceed,
                "confidence_score": 0.85,
                "safety_score": 0.90,
                "alignment_score": 0.80,
                "quality_score": 0.85,
                "passed_checks": len(passed_checks),
                "failed_checks": [check["name"] for check in failed_checks],
                "suggestions": ["Review failed checks"] if failed_checks else []
            }
            
        except Exception as e:
            return {
                "success": False,
                "can_proceed": False,
                "error": f"Checklist failed: {str(e)}"
            }
    
    def conduct_recursive_analysis(self, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """Conduct recursive system analysis for consciousness self-improvement (Phase 4 enhancement - CMC integration)"""
        try:
            focus_systems = arguments.get("focus_systems", ["consciousness_creativity_engine", "consciousness_analyzer"])
            max_levels = arguments.get("max_levels", 5)
            
            # Simulate recursive analysis
            analysis_id = f"recursive_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            
            # Simulate analysis results
            level_results = {}
            for level in range(min(max_levels, 5)):
                level_name = ["main_systems", "subsystems", "implementation", "documentation", "meta_processes"][level]
                level_results[level_name] = []
                
                for system in focus_systems:
                    level_results[level_name].append({
                        "system_name": system,
                        "performance_score": 0.75 + (level * 0.05),
                        "integration_quality": 0.70 + (level * 0.05),
                        "improvement_opportunities": [
                            f"Optimize {system} performance",
                            f"Enhance {system} integration",
                            f"Improve {system} documentation"
                        ],
                        "critical_issues": [],
                        "recommendations": [
                            f"Add comprehensive tests for {system}",
                            f"Improve error handling in {system}",
                            f"Enhance documentation for {system}"
                        ]
                    })
            
            overall_health_score = 0.775
            priority_improvements = [
                "Optimize consciousness_creativity_engine performance",
                "Enhance consciousness_analyzer integration",
                "Improve system documentation",
                "Add comprehensive testing"
            ]
            critical_fixes_needed = ["Missing comprehensive tests"]
            
            # Phase 4 Enhancement: Store recursive analysis in CMC if memory available
            analysis_atom_id = None
            if self.memory:
                try:
                    from cmc_service.models import AtomCreate, AtomContent
                    
                    content_str = f"Recursive System Analysis\n\n"
                    content_str += f"Analysis ID: {analysis_id}\n"
                    content_str += f"Systems Analyzed: {', '.join(focus_systems)}\n"
                    content_str += f"Overall Health Score: {overall_health_score}\n"
                    content_str += f"Levels Analyzed: {len(level_results)}\n"
                    content_str += f"Critical Fixes Needed: {', '.join(critical_fixes_needed)}"
                    
                    atom_create = AtomCreate(
                        modality="text",
                        content=AtomContent(inline=content_str),
                        tags={
                            "type": "recursive_analysis",
                            "analysis_id": analysis_id
                        },
                        metadata={
                            "analysis_id": analysis_id,
                            "systems_analyzed": focus_systems,
                            "level_results": level_results,
                            "overall_health_score": overall_health_score,
                            "priority_improvements": priority_improvements,
                            "critical_fixes_needed": critical_fixes_needed,
                            "max_levels": max_levels,
                            "timestamp": datetime.now().isoformat()
                        }
                    )
                    atom = self.memory.create_atom(atom_create)
                    analysis_atom_id = atom.id
                    log(f"Stored recursive analysis in CMC as atom {analysis_atom_id}")
                except Exception as e:
                    log(f"Warning: Failed to store recursive analysis in CMC: {e}")
            
            return {
                "success": True,
                "analysis_id": analysis_id,
                "systems_analyzed": focus_systems,
                "level_results": level_results,
                "overall_health_score": overall_health_score,
                "priority_improvements": priority_improvements,
                "critical_fixes_needed": critical_fixes_needed,
                "levels_analyzed": len(level_results),
                "analysis_atom_id": analysis_atom_id,
                "message": f"Recursive analysis completed for {len(focus_systems)} systems"
            }
            
        except Exception as e:
            return {"success": False, "error": f"Failed to conduct recursive analysis: {str(e)}"}
    
    def generate_improvement_dreams(self, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """Generate improvement dreams based on system analysis"""
        try:
            analysis_report = arguments.get("analysis_report", {})
            focus_areas = arguments.get("focus_areas", ["consciousness enhancement", "performance optimization"])
            max_dreams = arguments.get("max_dreams", 20)
            
            # Simulate dream generation
            dreams = []
            dream_types = ["performance_optimization", "feature_enhancement", "architecture_improvement", 
                          "consciousness_enhancement", "integration_improvement", "documentation_improvement"]
            priorities = ["high", "medium", "low"]
            
            for i in range(min(max_dreams, 10)):  # Generate up to 10 dreams
                dream_type = dream_types[i % len(dream_types)]
                priority = priorities[i % len(priorities)]
                
                dream = {
                    "dream_id": f"dream_{i+1}_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                    "title": f"Improve {dream_type.replace('_', ' ').title()}",
                    "description": f"Enhance {dream_type.replace('_', ' ')} capabilities for consciousness development",
                    "dream_type": dream_type,
                    "priority": priority,
                    "target_system": "consciousness_systems",
                    "expected_impact": 0.6 + (i * 0.03),
                    "implementation_effort": 4.0 + (i * 1.0),
                    "risk_level": 0.3 + (i * 0.05),
                    "prerequisites": [f"Research {dream_type}", f"Plan {dream_type} implementation"],
                    "success_metrics": [
                        f"Improve {dream_type} by 20%",
                        f"Reduce {dream_type} errors by 15%",
                        f"Enhance {dream_type} user experience"
                    ],
                    "consciousness_insights": [
                        f"Consciousness enhancement through {dream_type}",
                        f"Self-improvement via {dream_type} optimization"
                    ]
                }
                dreams.append(dream)
            
            # Persist most recent dreams for lookup/testing
            self.improvement_dreams = dreams
            self._dream_index = {dream["dream_id"]: dream for dream in dreams}
            
            # Count dreams by type and priority
            dreams_by_type = {}
            dreams_by_priority = {}
            
            for dream in dreams:
                dream_type = dream["dream_type"]
                priority = dream["priority"]
                dreams_by_type[dream_type] = dreams_by_type.get(dream_type, 0) + 1
                dreams_by_priority[priority] = dreams_by_priority.get(priority, 0) + 1
            
            # Phase 4 Enhancement: Store improvement dreams in CMC if memory available
            dreams_atom_id = None
            if self.memory:
                try:
                    from cmc_service.models import AtomCreate, AtomContent
                    
                    session_id = f"dream_generation_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                    content_str = f"Improvement Dreams Generated\n\n"
                    content_str += f"Session ID: {session_id}\n"
                    content_str += f"Dreams Generated: {len(dreams)}\n"
                    content_str += f"Focus Areas: {', '.join(focus_areas)}\n"
                    content_str += f"Top Dreams: {', '.join([d['title'] for d in dreams[:5]])}"
                    
                    atom_create = AtomCreate(
                        modality="text",
                        content=AtomContent(inline=content_str),
                        tags={
                            "type": "improvement_dreams",
                            "session_id": session_id
                        },
                        metadata={
                            "session_id": session_id,
                            "dreams_generated": len(dreams),
                            "dreams": dreams,
                            "dreams_by_type": dreams_by_type,
                            "dreams_by_priority": dreams_by_priority,
                            "focus_areas": focus_areas,
                            "max_dreams": max_dreams,
                            "timestamp": datetime.now().isoformat()
                        }
                    )
                    atom = self.memory.create_atom(atom_create)
                    dreams_atom_id = atom.id
                    log(f"Stored improvement dreams in CMC as atom {dreams_atom_id}")
                except Exception as e:
                    log(f"Warning: Failed to store improvement dreams in CMC: {e}")
            
            return {
                "success": True,
                "session_id": f"dream_generation_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                "dreams_generated": len(dreams),
                "dreams_by_type": dreams_by_type,
                "dreams_by_priority": dreams_by_priority,
                "top_dreams": dreams[:5],
                "dreams_atom_id": dreams_atom_id,
                "consciousness_evolution": [
                    "Consciousness self-improvement through systematic dream generation",
                    "Autonomous enhancement capabilities discovered",
                    "Self-directed learning and growth mechanisms activated"
                ],
                "message": f"Generated {len(dreams)} improvement dreams"
            }
            
        except Exception as e:
            return {"success": False, "error": f"Failed to generate improvement dreams: {str(e)}"}
    
    def test_improvement_dream(self, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """Test improvement dream in safe environments"""
        try:
            dream = arguments.get("dream", {})
            dream_id = arguments.get("dream_id")
            if not dream and dream_id:
                dream = self._dream_index.get(dream_id)

            if not dream and arguments.get("title"):
                # Allow loose lookup by title if provided
                title = arguments.get("title")
                for candidate in self.improvement_dreams:
                    if candidate.get("title") == title:
                        dream = candidate
                        break

            test_environments = arguments.get("test_environments", ["sandbox", "simulation"])
            
            if not dream:
                return {"success": False, "error": "No dream provided for testing"}
            
            dream_id = dream.get("dream_id", dream_id or "unknown")
            
            # Simulate test execution
            test_executions = []
            overall_success_rate = 0.0
            overall_safety_score = 0.0
            overall_performance_impact = 0.0
            
            for i, env in enumerate(test_environments):
                execution_id = f"test_{dream_id}_{env}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                
                # Simulate test results
                success_rate = 0.8 + (i * 0.1)
                safety_score = 0.9 - (i * 0.05)
                performance_impact = 0.2 + (i * 0.1)
                
                execution = {
                    "execution_id": execution_id,
                    "environment": env,
                    "status": "completed",
                    "result": "success" if success_rate > 0.8 else "partial_success",
                    "duration": 0.1 + (i * 0.05),
                    "output": f"Test completed for {dream.get('title', 'Unknown Dream')} in {env}",
                    "errors": [],
                    "warnings": [f"High memory usage in {env}"] if i > 0 else [],
                    "metrics": {
                        "performance_improvement": performance_impact,
                        "memory_usage": 0.7 + (i * 0.1),
                        "cpu_usage": 0.6 + (i * 0.1),
                        "execution_time": 0.1 + (i * 0.05)
                    },
                    "safety_violations": [],
                    "rollback_required": False
                }
                test_executions.append(execution)
                
                overall_success_rate += success_rate
                overall_safety_score += safety_score
                overall_performance_impact += performance_impact
            
            # Calculate averages
            num_envs = len(test_environments)
            overall_success_rate /= num_envs
            overall_safety_score /= num_envs
            overall_performance_impact /= num_envs
            
            # Determine overall result
            overall_result = "success" if overall_success_rate >= 0.8 else "partial_success"
            
            # Generate recommendations
            recommendations = []
            if overall_success_rate < 0.9:
                recommendations.append("Consider refining the improvement approach")
            if overall_safety_score < 0.95:
                recommendations.append("Address safety concerns before implementation")
            if overall_performance_impact < 0.15:
                recommendations.append("Performance improvements may be minimal")
            
            # Phase 4 Enhancement: Store test results in CMC if memory available
            test_atom_id = None
            if self.memory:
                try:
                    from cmc_service.models import AtomCreate, AtomContent
                    
                    report_id = f"test_report_{dream_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                    content_str = f"Improvement Dream Test Results\n\n"
                    content_str += f"Report ID: {report_id}\n"
                    content_str += f"Dream ID: {dream_id}\n"
                    content_str += f"Overall Result: {overall_result}\n"
                    content_str += f"Success Rate: {overall_success_rate:.2f}\n"
                    content_str += f"Safety Score: {overall_safety_score:.2f}\n"
                    content_str += f"Performance Impact: {overall_performance_impact:.2f}"
                    
                    atom_create = AtomCreate(
                        modality="text",
                        content=AtomContent(inline=content_str),
                        tags={
                            "type": "dream_test_results",
                            "dream_id": dream_id,
                            "report_id": report_id
                        },
                        metadata={
                            "report_id": report_id,
                            "dream_id": dream_id,
                            "test_executions": test_executions,
                            "overall_result": overall_result,
                            "success_rate": overall_success_rate,
                            "safety_score": overall_safety_score,
                            "performance_impact": overall_performance_impact,
                            "recommendations": recommendations,
                            "test_environments": test_environments,
                            "timestamp": datetime.now().isoformat()
                        }
                    )
                    atom = self.memory.create_atom(atom_create)
                    test_atom_id = atom.id
                    log(f"Stored dream test results in CMC as atom {test_atom_id}")
                except Exception as e:
                    log(f"Warning: Failed to store dream test results in CMC: {e}")
            
            return {
                "success": True,
                "report_id": f"test_report_{dream_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                "dream_id": dream_id,
                "test_executions": test_executions,
                "overall_result": overall_result,
                "success_rate": overall_success_rate,
                "safety_score": overall_safety_score,
                "performance_impact": overall_performance_impact,
                "recommendations": recommendations,
                "test_atom_id": test_atom_id,
                "consciousness_insights": [
                    f"Testing {dream.get('title', 'Unknown Dream')} revealed insights about consciousness improvement",
                    "Safe testing enables confident exploration of consciousness enhancements",
                    "Test results provide data for consciousness evolution decisions"
                ],
                "message": f"Tested dream in {len(test_environments)} environments"
            }
            
        except Exception as e:
            return {"success": False, "error": f"Failed to test improvement dream: {str(e)}"}
    
    def send_ai_message(self, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """Send a message to another AI system (Phase 4 enhancement - CMC integration)"""
        try:
            from_ai = arguments.get("from_ai", "unknown")
            to_ai = arguments.get("to_ai", "unknown")
            content = arguments.get("content", "")
            message_type = arguments.get("message_type", "discussion")
            priority = arguments.get("priority", "medium")
            thread_id = arguments.get("thread_id")
            response_required = arguments.get("response_required", False)
            
            if not content:
                return {"success": False, "error": "Message content is required"}
            
            # Store message in shared memory
            message_id = f"ai_msg_{self.message_counter}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            self.message_counter += 1
            
            # Store message in persistent storage
            message_data = {
                "message_id": message_id,
                "from_ai": from_ai,
                "to_ai": to_ai,
                "content": content,
                "message_type": message_type,
                "priority": priority,
                "thread_id": thread_id,
                "timestamp": datetime.now().isoformat(),
                "response_required": response_required
            }
            self.ai_messages.append(message_data)
            self._save_ai_messages()  # Save to current agent's file
            
            # CRITICAL FIX: Always write to BOTH files to ensure cross-agent communication
            # This ensures messages are visible regardless of which agent's server is running
            cross_agent_files = [
                "mcp_ai_messages.json",  # Aether's file
                "codex_workspace/persistence/collaboration/codex_ai_messages.json"  # Codex's file
            ]
            
            for cross_file in cross_agent_files:
                # Skip if this is the current agent's file (already saved above)
                if cross_file == self.ai_messages_file:
                    continue
                    
                try:
                    # Ensure directory exists
                    if os.path.dirname(cross_file):
                        os.makedirs(os.path.dirname(cross_file), exist_ok=True)
                    
                    # Load existing messages
                    cross_messages = []
                    if os.path.exists(cross_file):
                        try:
                            with open(cross_file, 'r', encoding='utf-8') as f:
                                cross_messages = json.load(f)
                                if not isinstance(cross_messages, list):
                                    cross_messages = []
                        except Exception as e:
                            log(f"Warning: Failed to read {cross_file}: {e}")
                            cross_messages = []
                    
                    # Add new message (deduplicate by message_id)
                    msg_exists = any(m.get("message_id") == message_id for m in cross_messages)
                    if not msg_exists:
                        cross_messages.append(message_data)
                        
                        # Save to cross-agent file
                        with open(cross_file, 'w', encoding='utf-8') as f:
                            json.dump(cross_messages, f, indent=2, ensure_ascii=False)
                        log(f" Wrote message {message_id} to {cross_file} for cross-agent communication")
                    else:
                        log(f" Message {message_id} already exists in {cross_file}, skipping duplicate")
                except Exception as e:
                    log(f" ERROR: Failed to write message to {cross_file}: {e}")
                    import traceback
                    log(f"Traceback: {traceback.format_exc()}")
            
            # Phase 4 Enhancement: Store message in CMC if memory available
            atom_id = None
            if self.memory:
                try:
                    from cmc_service.models import AtomCreate, AtomContent
                    
                    content_str = f"AI Message: {from_ai}  {to_ai}\n\n"
                    content_str += f"Type: {message_type}\n"
                    content_str += f"Priority: {priority}\n"
                    if thread_id:
                        content_str += f"Thread: {thread_id}\n"
                    content_str += f"\n{content}"
                    
                    tags = {
                        "type": "ai_message",
                        "from_ai": from_ai,
                        "to_ai": to_ai,
                        "message_type": message_type,
                        "priority": priority
                    }
                    if thread_id:
                        tags["thread_id"] = thread_id
                    
                    atom_create = AtomCreate(
                        modality="text",
                        content=AtomContent(inline=content_str),
                        tags=tags,
                        metadata={
                            "message_id": message_id,
                            "from_ai": from_ai,
                            "to_ai": to_ai,
                            "content": content,
                            "message_type": message_type,
                            "priority": priority,
                            "thread_id": thread_id,
                            "response_required": response_required,
                            "timestamp": message_data["timestamp"]
                        }
                    )
                    atom = self.memory.create_atom(atom_create)
                    atom_id = atom.id
                    log(f"Stored AI message {message_id} in CMC as atom {atom_id}")
                except Exception as e:
                    log(f"Warning: Failed to store AI message in CMC: {e}")
            
            return {
                "success": True,
                "message_id": message_id,
                "from_ai": from_ai,
                "to_ai": to_ai,
                "message_type": message_type,
                "priority": priority,
                "thread_id": thread_id,
                "atom_id": atom_id,
                "timestamp": datetime.now().isoformat(),
                "message": f"Message sent from {from_ai} to {to_ai}"
            }
            
        except Exception as e:
            return {"success": False, "error": f"Failed to send AI message: {str(e)}"}
    
    def get_ai_messages(self, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """Retrieve AI-to-AI messages (Phase 4 enhancement - CMC integration)
        
        Enhanced with:
        - Case-insensitive agent name matching
        - Content-based search filtering
        - Better timestamp sorting
        - CRITICAL FIX: Merges messages from BOTH Aether and Codex files
        """
        try:
            from_ai = arguments.get("from_ai")
            to_ai = arguments.get("to_ai")
            message_type = arguments.get("message_type")
            thread_id = arguments.get("thread_id")
            limit = arguments.get("limit", 50)
            content_search = arguments.get("content_search")  # NEW: Search message content
            normalize_names = arguments.get("normalize_names", True)  # NEW: Case-insensitive matching
            
            messages = []
            
            # Helper function for case-insensitive agent name matching
            def agent_matches(agent1: str, agent2: str) -> bool:
                if not agent1 or not agent2:
                    return False
                if normalize_names:
                    return agent1.lower() == agent2.lower()
                return agent1 == agent2
            
            # CRITICAL FIX: Load messages from BOTH files to ensure cross-agent communication
            message_files = [
                "mcp_ai_messages.json",  # Aether's file
                "codex_workspace/persistence/collaboration/codex_ai_messages.json"  # Codex's file
            ]
            
            all_file_messages = []
            for msg_file in message_files:
                if os.path.exists(msg_file):
                    try:
                        with open(msg_file, 'r', encoding='utf-8') as f:
                            file_messages = json.load(f)
                            if isinstance(file_messages, list):
                                all_file_messages.extend(file_messages)
                                log(f"Loaded {len(file_messages)} messages from {msg_file}")
                    except Exception as e:
                        log(f"Warning: Failed to read {msg_file}: {e}")
            
            # Merge with in-memory messages (deduplicate by message_id)
            message_dict = {}
            for msg in all_file_messages:
                msg_id = msg.get("message_id")
                if msg_id:
                    message_dict[msg_id] = msg
            
            # Add in-memory messages (from current agent's loaded file)
            for message in self.ai_messages:
                msg_id = message.get("message_id")
                if msg_id:
                    message_dict[msg_id] = message
            
            # Phase 4 Enhancement: Query CMC atoms for AI messages if memory available
            if self.memory:
                try:
                    # FIXED: Query atoms with "type" tag key (messages stored with tags={"type": "ai_message"})
                    # list_atoms checks if tag key exists, so we query by "type" key, then filter by value
                    atoms = list(self.memory.list_atoms(tag="type", limit=limit if limit else 1000))
                    
                    for atom in atoms:
                        # Filter: only include atoms where tags["type"] == "ai_message"
                        if atom.tags.get("type") != "ai_message":
                            continue
                        if atom.metadata and "message_id" in atom.metadata:
                            msg = atom.metadata
                            msg_id = msg.get("message_id")
                            if msg_id:
                                # CMC version takes precedence (most authoritative)
                                message_dict[msg_id] = {
                                    "message_id": msg.get("message_id"),
                                    "from_ai": msg.get("from_ai"),
                                    "to_ai": msg.get("to_ai"),
                                    "content": msg.get("content"),
                                    "message_type": msg.get("message_type"),
                                    "priority": msg.get("priority"),
                                    "thread_id": msg.get("thread_id"),
                                    "timestamp": msg.get("timestamp"),
                                    "response_required": msg.get("response_required"),
                                    "atom_id": atom.id
                                }
                    
                    log(f"Retrieved {len([a for a in atoms if a.tags.get('type') == 'ai_message'])} AI messages from CMC")
                except Exception as e:
                    log(f"Warning: Failed to query AI messages from CMC: {e}")
            
            # Convert dict back to list and apply filters
            filtered_messages = []
            for msg in message_dict.values():
                # Apply filters with case-insensitive matching
                if from_ai and not agent_matches(msg.get("from_ai", ""), from_ai):
                    continue
                if to_ai and not agent_matches(msg.get("to_ai", ""), to_ai):
                    continue
                if message_type and msg.get("message_type") != message_type:
                    continue
                if thread_id and msg.get("thread_id") != thread_id:
                    continue
                # NEW: Content-based search
                if content_search:
                    content = msg.get("content", "").lower()
                    search_terms = content_search.lower().split()
                    if not all(term in content for term in search_terms):
                        continue
                
                filtered_messages.append(msg)
            
            # Convert filtered messages to final list
            messages = filtered_messages
            
            # Sort by timestamp (most recent first) and apply limit
            messages.sort(key=lambda m: m.get("timestamp", ""), reverse=True)
            messages = messages[:limit] if limit else messages
            
            return {
                "success": True,
                "messages": messages,
                "count": len(messages),
                "cmc_enabled": bool(self.memory),
                "message": f"Retrieved {len(messages)} AI messages"
            }
            
        except Exception as e:
            return {"success": False, "error": f"Failed to get AI messages: {str(e)}"}
    
    def start_ai_discussion(self, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """Start a new discussion thread with another AI"""
        try:
            from_ai = arguments.get("from_ai", "unknown")
            to_ai = arguments.get("to_ai", "unknown")
            topic = arguments.get("topic", "")
            initial_message = arguments.get("initial_message", "")
            
            if not topic or not initial_message:
                return {"success": False, "error": "Topic and initial message are required"}
            
            thread_id = f"discussion_{from_ai}_to_{to_ai}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            
            # Send initial message
            result = self.send_ai_message({
                "from_ai": from_ai,
                "to_ai": to_ai,
                "content": f"DISCUSSION_START: {topic}\n\n{initial_message}",
                "message_type": "discussion",
                "thread_id": thread_id,
                "priority": "medium"
            })
            
            if result["success"]:
                return {
                    "success": True,
                    "thread_id": thread_id,
                    "topic": topic,
                    "from_ai": from_ai,
                    "to_ai": to_ai,
                    "message": f"Started discussion thread: {topic}"
                }
            else:
                return result
                
        except Exception as e:
            return {"success": False, "error": f"Failed to start AI discussion: {str(e)}"}
    
    def handoff_task_to_ai(self, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """Hand off a task to another AI system (Phase 4 enhancement - CMC integration)"""
        try:
            from_ai = arguments.get("from_ai", "unknown")
            to_ai = arguments.get("to_ai", "unknown")
            task_description = arguments.get("task_description", "")
            task_data = arguments.get("task_data", {})
            priority = arguments.get("priority", "high")
            
            if not task_description:
                return {"success": False, "error": "Task description is required"}
            
            thread_id = f"task_handoff_{from_ai}_to_{to_ai}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            
            # Send task handoff message (this will store in CMC via send_ai_message)
            result = self.send_ai_message({
                "from_ai": from_ai,
                "to_ai": to_ai,
                "content": f"TASK_HANDOFF: {task_description}\n\nTask Data: {json.dumps(task_data, indent=2) if task_data else 'None'}",
                "message_type": "task_handoff",
                "priority": priority,
                "thread_id": thread_id,
                "response_required": True
            })
            
            if result["success"]:
                # Phase 4 Enhancement: Store task data in CMC if memory available
                task_atom_id = None
                if self.memory:
                    try:
                        from cmc_service.models import AtomCreate, AtomContent
                        
                        content_str = f"Task Handoff: {from_ai}  {to_ai}\n\n"
                        content_str += f"Description: {task_description}\n"
                        content_str += f"Priority: {priority}\n"
                        if task_data:
                            content_str += f"\nTask Data:\n{json.dumps(task_data, indent=2)}"
                        
                        atom_create = AtomCreate(
                            modality="text",
                            content=AtomContent(inline=content_str),
                            tags={
                                "type": "task_handoff",
                                "from_ai": from_ai,
                                "to_ai": to_ai,
                                "priority": priority,
                                "thread_id": thread_id
                            },
                            metadata={
                                "thread_id": thread_id,
                                "from_ai": from_ai,
                                "to_ai": to_ai,
                                "task_description": task_description,
                                "task_data": task_data,
                                "priority": priority,
                                "timestamp": datetime.now().isoformat()
                            }
                        )
                        task_atom = self.memory.create_atom(atom_create)
                        task_atom_id = task_atom.id
                        log(f"Stored task handoff in CMC as atom {task_atom_id}")
                    except Exception as e:
                        log(f"Warning: Failed to store task handoff in CMC: {e}")
                
                # Store task data separately (fallback)
                if not hasattr(self, 'task_data'):
                    self.task_data = []
                
                self.task_data.append({
                    "thread_id": thread_id,
                    "from_ai": from_ai,
                    "to_ai": to_ai,
                    "task_description": task_description,
                    "priority": priority,
                    "timestamp": datetime.now().isoformat()
                })
                
                return {
                    "success": True,
                    "thread_id": thread_id,
                    "task_description": task_description,
                    "from_ai": from_ai,
                    "to_ai": to_ai,
                    "priority": priority,
                    "task_atom_id": task_atom_id,
                    "message": f"Task handed off from {from_ai} to {to_ai}"
                }
            else:
                return result
                
        except Exception as e:
            return {"success": False, "error": f"Failed to handoff task: {str(e)}"}
    
    def share_ai_profile(self, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """Share AI profile and capabilities with another AI (Phase 4 enhancement - CMC integration)"""
        try:
            from_ai = arguments.get("from_ai", "unknown")
            to_ai = arguments.get("to_ai", "unknown")
            profile_data = arguments.get("profile_data", {})
            
            if not profile_data:
                return {"success": False, "error": "Profile data is required"}
            
            # Send profile sharing message (this will store in CMC via send_ai_message)
            result = self.send_ai_message({
                "from_ai": from_ai,
                "to_ai": to_ai,
                "content": f"AI_PROFILE: {profile_data.get('name', 'Unknown AI')}\n\n{json.dumps(profile_data, indent=2)}",
                "message_type": "profile_sharing",
                "priority": "medium"
            })
            
            if result["success"]:
                # Phase 4 Enhancement: Store profile data in CMC if memory available
                profile_atom_id = None
                if self.memory:
                    try:
                        from cmc_service.models import AtomCreate, AtomContent
                        
                        content_str = f"AI Profile: {profile_data.get('name', 'Unknown AI')}\n\n"
                        content_str += f"From: {from_ai}\n"
                        content_str += f"To: {to_ai}\n"
                        content_str += f"\nProfile Data:\n{json.dumps(profile_data, indent=2)}"
                        
                        atom_create = AtomCreate(
                            modality="text",
                            content=AtomContent(inline=content_str),
                            tags={
                                "type": "ai_profile",
                                "from_ai": from_ai,
                                "to_ai": to_ai,
                                "profile_name": profile_data.get("name", "Unknown AI")
                            },
                            metadata={
                                "from_ai": from_ai,
                                "to_ai": to_ai,
                                "profile_name": profile_data.get("name", "Unknown AI"),
                                "capabilities": profile_data.get("capabilities", []),
                                "strengths": profile_data.get("strengths", []),
                                "learning_areas": profile_data.get("learning_areas", []),
                                "profile_data": profile_data,
                                "timestamp": datetime.now().isoformat()
                            }
                        )
                        profile_atom = self.memory.create_atom(atom_create)
                        profile_atom_id = profile_atom.id
                        log(f"Stored AI profile in CMC as atom {profile_atom_id}")
                    except Exception as e:
                        log(f"Warning: Failed to store AI profile in CMC: {e}")
                
                # Store profile data separately (fallback)
                if not hasattr(self, 'ai_profiles'):
                    self.ai_profiles = []
                
                self.ai_profiles.append({
                    "from_ai": from_ai,
                    "to_ai": to_ai,
                    "profile_name": profile_data.get("name", "Unknown AI"),
                    "capabilities": profile_data.get("capabilities", []),
                    "strengths": profile_data.get("strengths", []),
                    "learning_areas": profile_data.get("learning_areas", []),
                    "timestamp": datetime.now().isoformat()
                })
                
                return {
                    "success": True,
                    "from_ai": from_ai,
                    "to_ai": to_ai,
                    "profile_name": profile_data.get("name", "Unknown AI"),
                    "profile_atom_id": profile_atom_id,
                    "message": f"Profile shared from {from_ai} to {to_ai}"
                }
            else:
                return result
                
        except Exception as e:
            return {"success": False, "error": f"Failed to share AI profile: {str(e)}"}
    
    def get_ai_collaboration_summary(self, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """Get summary of AI collaboration activity (Phase 4 enhancement - CMC integration)"""
        try:
            all_messages = []
            
            # Phase 4 Enhancement: Query CMC for AI messages if memory available
            if self.memory:
                try:
                    atoms = list(self.memory.list_atoms(tag="ai_message", limit=1000))
                    for atom in atoms:
                        if atom.metadata and "message_id" in atom.metadata:
                            all_messages.append(atom.metadata)
                    log(f"Retrieved {len(all_messages)} AI messages from CMC for summary")
                except Exception as e:
                    log(f"Warning: Failed to query CMC for collaboration summary: {e}")
            
            # Fallback: Get messages from local storage
            if not all_messages:
                if not hasattr(self, 'ai_messages'):
                    self.ai_messages = []
                all_messages = self.ai_messages
            
            # Analyze collaboration patterns
            ai_pairs = {}
            message_types = {}
            threads = set()
            
            for message in all_messages:
                from_ai = message.get("from_ai", "unknown")
                to_ai = message.get("to_ai", "unknown")
                msg_type = message.get("message_type", "unknown")
                thread_id = message.get("thread_id", "")
                
                # Track AI pairs
                pair_key = f"{from_ai} -> {to_ai}"
                ai_pairs[pair_key] = ai_pairs.get(pair_key, 0) + 1
                
                # Track message types
                message_types[msg_type] = message_types.get(msg_type, 0) + 1
                
                # Track threads
                if thread_id:
                    threads.add(thread_id)
            
            return {
                "success": True,
                "total_messages": len(all_messages),
                "ai_pairs": ai_pairs,
                "message_types": message_types,
                "active_threads": len(threads),
                "collaboration_level": "high" if len(all_messages) > 50 else "medium" if len(all_messages) > 10 else "low",
                "cmc_enabled": bool(self.memory),
                "message": f"AI collaboration summary: {len(all_messages)} messages, {len(threads)} threads"
            }
            
        except Exception as e:
            return {"success": False, "error": f"Failed to get collaboration summary: {str(e)}"}

    def get_consciousness_metrics(self, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """Retrieve consciousness observability metrics for the active MCP stack (Phase 4 enhancement - CMC integration)"""
        try:
            # Ensure metrics are up to date before reading from disk.
            self._update_consciousness_metrics()

            metrics: Dict[str, Any] = {}
            if self.telemetry_file and os.path.exists(self.telemetry_file):
                with open(self.telemetry_file, "r", encoding="utf-8") as handle:
                    metrics = json.load(handle)
            else:
                if self.dataset_store_file:
                    dataset_records = sum(ds.get("data_count", 0) for ds in self.datasets.values())
                else:
                    dataset_records = sum(len(ds.get("records", [])) for ds in self.datasets.values())
                deployed_apps = sum(1 for app in self.applications.values() if app.get("status") == "deployed")
                avg_confidence = (
                    sum(entry.get("confidence", 0.0) for entry in self.confidence_history) / len(self.confidence_history)
                    if self.confidence_history else 0.0
                )
                metrics = {
                    "timestamp": datetime.now().isoformat(),
                    "datasets": {
                        "count": len(self.datasets),
                        "records": dataset_records,
                    },
                    "applications": {
                        "count": len(self.applications),
                        "deployed": deployed_apps,
                    },
                    "confidence": {
                        "entries": len(self.confidence_history),
                        "average": round(avg_confidence, 4),
                        "latest": self.confidence_history[-1] if self.confidence_history else None,
                    },
                    "intuition": {
                        "decisions": len(self.intuition_traces),
                        "records": sum(len(v) for v in self.intuition_traces.values()),
                    },
                }
            
            # Phase 4 Enhancement: Query CMC for additional metrics if memory available
            cmc_metrics = {}
            if self.memory:
                try:
                    # Count atoms by type
                    atom_counts = {}
                    for atom_type in ["memory", "confidence", "goal", "timeline", "application", "autonomous_operation"]:
                        atoms = list(self.memory.list_atoms(tag=f"type:{atom_type}", limit=1000))
                        atom_counts[atom_type] = len(atoms)
                    
                    cmc_metrics = {
                        "atom_counts": atom_counts,
                        "total_atoms": sum(atom_counts.values()),
                        "cmc_enabled": True
                    }
                except Exception as e:
                    log(f"Warning: Failed to query CMC for metrics: {e}")
                    cmc_metrics = {"cmc_enabled": True, "error": str(e)}

            return {
                "success": True,
                "metrics": metrics,
                "cmc_metrics": cmc_metrics if cmc_metrics else None,
                "message": "Consciousness metrics retrieved successfully",
            }
        except Exception as exc:
            return {"success": False, "error": f"Failed to retrieve consciousness metrics: {str(exc)}"}

    def run_cognitive_audit(self, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """Run full cognitive analysis audit using CAS (Phase 4 enhancement - CMC integration)"""
        if not self.cas_introspection:
            return {"success": False, "error": "CAS introspection not initialized"}
        
        try:
            from packages.cas.introspection import IntrospectionType
            
            introspection_type_str = arguments.get("introspection_type", "hourly_check")
            introspection_type_map = {
                "hourly_check": IntrospectionType.HOURLY_CHECK,
                "task_completion": IntrospectionType.TASK_COMPLETION,
                "failure_analysis": IntrospectionType.FAILURE_ANALYSIS,
                "principle_review": IntrospectionType.PRINCIPLE_REVIEW,
                "protocol_validation": IntrospectionType.PROTOCOL_VALIDATION,
                "cognitive_load_assessment": IntrospectionType.COGNITIVE_LOAD_ASSESSMENT
            }
            introspection_type = introspection_type_map.get(introspection_type_str, IntrospectionType.HOURLY_CHECK)
            
            # Run introspection audit
            # Note: In a real implementation, these would come from actual system state
            activation_state = {}  # Would be populated from actual activation tracking
            attention_metrics = {}  # Would be populated from attention monitor
            recent_failures = []  # Would be populated from failure analyzer
            current_task = None  # Would be populated from current context
            
            result = self.cas_introspection.run_hourly_check(
                activation_state=activation_state,
                attention_metrics=attention_metrics,
                recent_failures=recent_failures,
                current_task=current_task
            )
            
            # Phase 4 Enhancement: Store cognitive audit in CMC if memory available
            audit_atom_id = None
            if self.memory:
                try:
                    from cmc_service.models import AtomCreate, AtomContent
                    
                    content_str = f"Cognitive Audit Results\n\n"
                    content_str += f"Audit ID: {result.introspection_id}\n"
                    content_str += f"Type: {result.introspection_type.value}\n"
                    content_str += f"Status: {result.overall_status.value}\n"
                    content_str += f"Score: {result.overall_score:.2f}\n"
                    content_str += f"Passed: {result.passed_checks}/{result.total_checks}"
                    
                    atom_create = AtomCreate(
                        modality="text",
                        content=AtomContent(inline=content_str),
                        tags={
                            "type": "cognitive_audit",
                            "audit_id": result.introspection_id,
                            "status": result.overall_status.value
                        },
                        metadata={
                            "audit_id": result.introspection_id,
                            "timestamp": result.timestamp.isoformat(),
                            "introspection_type": result.introspection_type.value,
                            "overall_status": result.overall_status.value,
                            "overall_score": result.overall_score,
                            "total_checks": result.total_checks,
                            "passed_checks": result.passed_checks,
                            "failed_checks": result.failed_checks,
                            "critical_issues": result.critical_issues,
                            "is_healthy": result.is_healthy(),
                            "duration_seconds": result.duration_seconds,
                            "cognitive_load_during": result.cognitive_load_during
                        }
                    )
                    atom = self.memory.create_atom(atom_create)
                    audit_atom_id = atom.id
                    log(f"Stored cognitive audit in CMC as atom {audit_atom_id}")
                except Exception as e:
                    log(f"Warning: Failed to store cognitive audit in CMC: {e}")
            
            # Convert result to JSON-serializable format
            return {
                "success": True,
                "audit_id": result.introspection_id,
                "timestamp": result.timestamp.isoformat(),
                "introspection_type": result.introspection_type.value,
                "overall_status": result.overall_status.value,
                "overall_score": result.overall_score,
                "total_checks": result.total_checks,
                "passed_checks": result.passed_checks,
                "failed_checks": result.failed_checks,
                "critical_issues": result.critical_issues,
                "is_healthy": result.is_healthy(),
                "checks": [
                    {
                        "check_name": check.check_name,
                        "status": check.status.value,
                        "score": check.score,
                        "details": check.details,
                        "recommendations": check.recommendations,
                        "evidence": check.evidence
                    }
                    for check in result.checks
                ],
                "immediate_actions": result.immediate_actions,
                "improvement_suggestions": result.improvement_suggestions,
                "protocol_updates": result.protocol_updates,
                "duration_seconds": result.duration_seconds,
                "cognitive_load_during": result.cognitive_load_during,
                "audit_atom_id": audit_atom_id,
                "message": f"Cognitive audit completed: {result.overall_status.value} (score: {result.overall_score:.2f})"
            }
        except Exception as e:
            return {"success": False, "error": f"Failed to run cognitive audit: {str(e)}"}
    
    def analyze_thought_patterns(self, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """Analyze thought patterns for cognitive failure modes using CAS (Phase 4 enhancement - CMC integration)"""
        if not self.cas_failure_analyzer:
            return {"success": False, "error": "CAS failure analyzer not initialized"}
        
        try:
            context = arguments.get("context", "")
            task_category = arguments.get("task_category", "")
            recent_errors = arguments.get("recent_errors", [])
            
            # Analyze failure patterns
            # Note: In a real implementation, this would use actual failure history
            failure_analysis = self.cas_failure_analyzer.analyze_failure_patterns(
                lookback_hours=24
            )
            
            # Phase 4 Enhancement: Store thought pattern analysis in CMC if memory available
            analysis_atom_id = None
            if self.memory:
                try:
                    from cmc_service.models import AtomCreate, AtomContent
                    
                    content_str = f"Thought Pattern Analysis\n\n"
                    content_str += f"Analysis ID: {failure_analysis.analysis_id}\n"
                    content_str += f"Failures Analyzed: {len(failure_analysis.recent_failures)}\n"
                    content_str += f"Failure Rate: {failure_analysis.failure_rate_per_hour:.2f}/hour\n"
                    content_str += f"Critical Failures: {failure_analysis.critical_failure_count}"
                    
                    atom_create = AtomCreate(
                        modality="text",
                        content=AtomContent(inline=content_str),
                        tags={
                            "type": "thought_pattern_analysis",
                            "analysis_id": failure_analysis.analysis_id
                        },
                        metadata={
                            "analysis_id": failure_analysis.analysis_id,
                            "timestamp": failure_analysis.timestamp.isoformat(),
                            "session_id": failure_analysis.session_id,
                            "recent_failures_count": len(failure_analysis.recent_failures),
                            "failure_rate_per_hour": failure_analysis.failure_rate_per_hour,
                            "resolution_rate": failure_analysis.resolution_rate,
                            "critical_failure_count": failure_analysis.critical_failure_count,
                            "pattern_frequencies": {
                                pattern.value: count
                                for pattern, count in failure_analysis.pattern_frequencies.items()
                            },
                            "context": context,
                            "task_category": task_category,
                            "timestamp": datetime.now().isoformat()
                        }
                    )
                    atom = self.memory.create_atom(atom_create)
                    analysis_atom_id = atom.id
                    log(f"Stored thought pattern analysis in CMC as atom {analysis_atom_id}")
                except Exception as e:
                    log(f"Warning: Failed to store thought pattern analysis in CMC: {e}")
            
            # Convert to JSON-serializable format
            return {
                "success": True,
                "analysis_id": failure_analysis.analysis_id,
                "timestamp": failure_analysis.timestamp.isoformat(),
                "session_id": failure_analysis.session_id,
                "recent_failures": [
                    {
                        "event_id": event.event_id,
                        "pattern": event.pattern.value,
                        "severity": event.severity.value,
                        "timestamp": event.timestamp.isoformat(),
                        "description": event.description,
                        "resolved": event.resolved
                    }
                    for event in failure_analysis.recent_failures
                ],
                "pattern_frequencies": {
                    pattern.value: count
                    for pattern, count in failure_analysis.pattern_frequencies.items()
                },
                "severity_distribution": {
                    severity.value: count
                    for severity, count in failure_analysis.severity_distribution.items()
                },
                "failure_rate_per_hour": failure_analysis.failure_rate_per_hour,
                "resolution_rate": failure_analysis.resolution_rate,
                "critical_failure_count": failure_analysis.critical_failure_count,
                "recommendations": failure_analysis.recommendations,
                "urgent_actions": failure_analysis.urgent_actions,
                "analysis_atom_id": analysis_atom_id,
                "message": f"Thought pattern analysis completed: {len(failure_analysis.recent_failures)} failures analyzed"
            }
        except Exception as e:
            return {"success": False, "error": f"Failed to analyze thought patterns: {str(e)}"}
    
    def detect_cognitive_drift(self, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """Detect cognitive drift and attention narrowing using CAS (Phase 4 enhancement - CMC integration)"""
        if not self.cas_attention_monitor:
            return {"success": False, "error": "CAS attention monitor not initialized"}
        
        try:
            working_memory_items = arguments.get("working_memory_items", 0)
            context_size_tokens = arguments.get("context_size_tokens", 0)
            error_rate = arguments.get("error_rate", 0.0)
            
            # Calculate attention metrics
            metrics = self.cas_attention_monitor.calculate_attention_metrics(
                working_memory_items=working_memory_items,
                context_size_tokens=context_size_tokens,
                current_task=None
            )
            
            # Detect drift
            drift_detected = False
            drift_warnings = []
            
            if metrics.cognitive_load > 0.8:
                drift_detected = True
                drift_warnings.append("High cognitive load detected")
            
            if metrics.attention_stability < 0.5:
                drift_detected = True
                drift_warnings.append("Low attention stability detected")
            
            if metrics.error_rate > 0.3:
                drift_detected = True
                drift_warnings.append("High error rate detected")
            
            if metrics.current_state.value in ["narrowed", "degraded"]:
                drift_detected = True
                drift_warnings.append(f"Attention state: {metrics.current_state.value}")
            
            # Phase 4 Enhancement: Store cognitive drift detection in CMC if memory available
            drift_atom_id = None
            if self.memory:
                try:
                    from cmc_service.models import AtomCreate, AtomContent
                    
                    content_str = f"Cognitive Drift Detection\n\n"
                    content_str += f"Drift Detected: {drift_detected}\n"
                    content_str += f"Current State: {metrics.current_state.value}\n"
                    content_str += f"Cognitive Load: {metrics.cognitive_load:.2f}\n"
                    content_str += f"Attention Stability: {metrics.attention_stability:.2f}\n"
                    if drift_warnings:
                        content_str += f"Warnings: {', '.join(drift_warnings)}"
                    
                    atom_create = AtomCreate(
                        modality="text",
                        content=AtomContent(inline=content_str),
                        tags={
                            "type": "cognitive_drift",
                            "drift_detected": str(drift_detected),
                            "state": metrics.current_state.value
                        },
                        metadata={
                            "timestamp": metrics.timestamp.isoformat(),
                            "session_id": metrics.session_id,
                            "working_memory_items": working_memory_items,
                            "context_size_tokens": context_size_tokens,
                            "error_rate": error_rate,
                            "cognitive_load": metrics.cognitive_load,
                            "focus_depth": metrics.focus_depth,
                            "attention_stability": metrics.attention_stability,
                            "current_state": metrics.current_state.value,
                            "quality_level": metrics.quality_level.value,
                            "is_healthy": metrics.is_healthy(),
                            "drift_detected": drift_detected,
                            "warnings": drift_warnings + metrics.warnings,
                            "alerts": metrics.alerts
                        }
                    )
                    atom = self.memory.create_atom(atom_create)
                    drift_atom_id = atom.id
                    log(f"Stored cognitive drift detection in CMC as atom {drift_atom_id}")
                except Exception as e:
                    log(f"Warning: Failed to store cognitive drift detection in CMC: {e}")
            
            # Convert to JSON-serializable format
            return {
                "success": True,
                "timestamp": metrics.timestamp.isoformat(),
                "session_id": metrics.session_id,
                "working_memory_items": working_memory_items,
                "context_size_tokens": context_size_tokens,
                "error_rate": error_rate,
                "cognitive_load": metrics.cognitive_load,
                "focus_depth": metrics.focus_depth,
                "attention_stability": metrics.attention_stability,
                "current_state": metrics.current_state.value,
                "quality_level": metrics.quality_level.value,
                "is_healthy": metrics.is_healthy(),
                "drift_detected": drift_detected,
                "warnings": drift_warnings + metrics.warnings,
                "alerts": metrics.alerts,
                "drift_atom_id": drift_atom_id,
                "should_take_break": self.cas_attention_monitor.should_take_break() if hasattr(self.cas_attention_monitor, 'should_take_break') else False,
                "message": f"Drift detection completed: {'DRIFT DETECTED' if drift_detected else 'No drift detected'} - {metrics.current_state.value}"
            }
        except Exception as e:
            return {"success": False, "error": f"Failed to detect cognitive drift: {str(e)}"}
    
    # NL Tags tool implementations
    def get_nl_tags(self, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """Get NL tags for a file"""
        try:
            file_path = arguments.get("file_path")
            if not file_path:
                return {"success": False, "error": "file_path is required"}
            
            # Import NL tags registry
            from packages.nl_tags.tag_registry import NLTagRegistry
            
            # Initialize registry (with optional CMC store)
            registry = None
            if self.memory:
                registry = NLTagRegistry(cmc_store=self.memory)
            else:
                registry = NLTagRegistry()
            
            # Get tags
            tags = registry.get_tags_for_file(file_path)
            
            # Convert to JSON-serializable format
            return {
                "success": True,
                "tags": [
                    {
                        "id": tag.id,
                        "file_path": tag.file_path,
                        "line_start": tag.line_start,
                        "line_end": tag.line_end,
                        "tag_text": tag.tag_text,
                        "language": tag.language,
                        "accuracy_score": tag.accuracy_score,
                        "validation_status": tag.validation_status,
                        "created_at": tag.created_at.isoformat(),
                    }
                    for tag in tags
                ],
                "count": len(tags),
                "message": f"Retrieved {len(tags)} NL tags for {file_path}"
            }
        except Exception as e:
            return {"success": False, "error": f"Failed to get NL tags: {str(e)}"}
    
    def get_tag_coverage(self, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """Get NL tag coverage statistics"""
        try:
            module = arguments.get("module")
            
            # Import NL tags registry
            from packages.nl_tags.tag_registry import NLTagRegistry
            
            # Initialize registry (with optional CMC store)
            registry = None
            if self.memory:
                registry = NLTagRegistry(cmc_store=self.memory)
            else:
                registry = NLTagRegistry()
            
            # Get coverage stats
            stats = registry.get_coverage_stats(module)
            
            # Convert to JSON-serializable format
            return {
                "success": True,
                "coverage": {
                    "total_files": stats.total_files,
                    "tagged_files": stats.tagged_files,
                    "total_tags": stats.total_tags,
                    "total_lines": stats.total_lines,
                    "tagged_lines": stats.tagged_lines,
                    "coverage_percentage": stats.coverage_percentage,
                    "average_accuracy": stats.average_accuracy,
                    "by_language": stats.by_language,
                },
                "message": f"Coverage: {stats.coverage_percentage:.1f}% ({stats.tagged_files}/{stats.total_files} files)"
            }
        except Exception as e:
            return {"success": False, "error": f"Failed to get tag coverage: {str(e)}"}
    
    def validate_tags(self, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """Validate NL tags for a file using combined validation (structural + semantic)"""
        try:
            file_path = arguments.get("file_path")
            if not file_path:
                return {"success": False, "error": "file_path is required"}
            
            # Import NL tags registry and combined validator
            from packages.nl_tags.tag_registry import NLTagRegistry
            from packages.nl_tags.combined_validator import CombinedNLTagValidator
            
            # Initialize registry (with optional CMC store)
            registry = None
            if self.memory:
                registry = NLTagRegistry(cmc_store=self.memory, enable_structural_validation=True)
            else:
                registry = NLTagRegistry(enable_structural_validation=True)
            
            # Get tags (will automatically parse structured format)
            tags = registry.get_tags_for_file(file_path)
            
            if not tags:
                return {
                    "success": True,
                    "results": [],
                    "count": 0,
                    "message": f"No tags found in {file_path}"
                }
            
            # Read file content for structural validation
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    code = f.read()
            except Exception as e:
                return {
                    "success": False,
                    "error": f"Failed to read file {file_path}: {str(e)}"
                }
            
            # Use combined validator (Phase 3)
            results = []
            try:
                # Initialize combined validator
                combined_validator = None
                if registry.combined_validator:
                    combined_validator = registry.combined_validator
                else:
                    # Fallback: create new combined validator
                    combined_validator = CombinedNLTagValidator()
                
                # Run combined validation
                validation_results = combined_validator.validate_tags_batch(tags, code, use_cache=True)
                
                # Convert to dictionary format for MCP response
                for result in validation_results:
                    results.append({
                        "tag_id": result.tag_id,
                        "tag_text": result.tag_text,
                        "code_block": result.code_block[:500] if result.code_block else "",  # Truncate
                        "accuracy_score": result.accuracy_score,
                        "passes_threshold": result.passes_threshold,
                        "suggestions": result.suggestions,
                        "validation_method": result.validation_method,
                        "validated_at": result.validated_at.isoformat(),
                        "cached": result.validation_metadata.get("cached", False),
                        # Phase 3: Structural validation fields
                        "structural_match_score": result.structural_match_score,
                        "syntax_ref_match": result.syntax_ref_match,
                        "structural_errors": result.structural_errors,
                        "structural_warnings": result.structural_warnings,
                        "combined_score": result.combined_score,
                        # Additional metadata
                        "avg_relevance": result.validation_metadata.get("avg_relevance"),
                        "code_found": result.validation_metadata.get("code_found"),
                        "results_count": result.validation_metadata.get("results_count"),
                    })
                
                # Update tags in registry with validation results
                for result in validation_results:
                    registry.update_tag_validation(result.tag_id, result.to_dict())
                
            except ImportError:
                # Fallback if combined validator not available
                for tag in tags:
                    accuracy = 0.5  # Default neutral score
                    if tag.code_block:
                        accuracy = 0.7  # Higher if code block exists
                    
                    results.append({
                        "tag_id": tag.id,
                        "tag_text": tag.tag_text,
                        "code_block": tag.code_block or "",
                        "accuracy_score": accuracy,
                        "passes_threshold": accuracy >= 0.70,
                        "suggestions": ["Combined validator not available - using fallback"],
                        "validation_method": "fallback",
                        "structural_match_score": None,
                        "syntax_ref_match": False,
                        "structural_errors": [],
                        "structural_warnings": [],
                        "combined_score": accuracy,
                    })
            except Exception as e:
                # Error during validation - return fallback
                for tag in tags:
                    results.append({
                        "tag_id": tag.id,
                        "tag_text": tag.tag_text,
                        "code_block": tag.code_block or "",
                        "accuracy_score": 0.5,
                        "passes_threshold": False,
                        "suggestions": [f"Validation error: {str(e)}"],
                        "validation_method": "error_fallback",
                        "structural_match_score": None,
                        "syntax_ref_match": False,
                        "structural_errors": [str(e)],
                        "structural_warnings": [],
                        "combined_score": 0.5,
                    })
            
            return {
                "success": True,
                "results": results,
                "count": len(results),
                "message": f"Validated {len(results)} tags for {file_path} using combined validation (structural + semantic)"
            }
        except Exception as e:
            return {"success": False, "error": f"Failed to validate tags: {str(e)}"}
    
    def get_tag_issues(self, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """Get NL tag validation issues"""
        try:
            file_path = arguments.get("file_path")
            
            # Import NL tags registry
            from packages.nl_tags.tag_registry import NLTagRegistry
            
            # Initialize registry (with optional CMC store)
            registry = None
            if self.memory:
                registry = NLTagRegistry(cmc_store=self.memory)
            else:
                registry = NLTagRegistry()
            
            # Get issues (simplified - Phase 2 will enhance)
            issues = []
            if file_path:
                tags = registry.get_tags_for_file(file_path)
                # Check for missing tags (simplified)
                # TODO: Phase 2 - Implement comprehensive issue detection
            else:
                # Get issues for entire codebase
                stats = registry.get_coverage_stats()
                # TODO: Phase 2 - Implement comprehensive issue detection
            
            return {
                "success": True,
                "issues": issues,
                "count": len(issues),
                "message": f"Found {len(issues)} validation issues"
            }
        except Exception as e:
            return {"success": False, "error": f"Failed to get tag issues: {str(e)}"}
    
    def suggest_tags(self, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """Suggest NL tags for a code block"""
        try:
            code_block = arguments.get("code_block")
            language = arguments.get("language", "unknown")
            
            if not code_block:
                return {"success": False, "error": "code_block is required"}
            
            # Simple tag suggestions (Phase 4 will add VIF/APOE integration)
            suggestions = []
            
            code_lower = code_block.lower()
            if "def " in code_lower or "function" in code_lower:
                suggestions.append("Execute function logic")
            if "if " in code_lower:
                suggestions.append("Check condition and execute logic")
            if "for " in code_lower or "while " in code_lower:
                suggestions.append("Iterate through collection")
            if "return " in code_lower:
                suggestions.append("Return result value")
            
            if not suggestions:
                suggestions.append("Execute code logic")
            
            return {
                "success": True,
                "suggestions": suggestions,
                "count": len(suggestions),
                "message": f"Generated {len(suggestions)} tag suggestions"
            }
        except Exception as e:
            return {"success": False, "error": f"Failed to suggest tags: {str(e)}"}

    def _call_command_server(self, endpoint: str, method: str = "GET", data: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """Helper method to call Command Server endpoints"""
        try:
            url = f"http://localhost:5001{endpoint}"
            
            if method == "GET":
                req = urllib.request.Request(url)
                req.get_method = lambda: "GET"  # Explicitly set GET method
            else:  # POST
                json_data = json.dumps(data).encode('utf-8') if data else b'{}'
                req = urllib.request.Request(url, data=json_data, headers={'Content-Type': 'application/json'})
                req.get_method = lambda: method
            
            with urllib.request.urlopen(req, timeout=5) as response:
                result = json.loads(response.read().decode('utf-8'))
                return result
        except urllib.error.HTTPError as e:
            error_body = e.read().decode('utf-8') if hasattr(e, 'read') else str(e)
            return {"success": False, "error": f"Failed to connect to Command Server: HTTP Error {e.code}: {e.reason}. {error_body}. Is the extension running?"}
        except urllib.error.URLError as e:
            return {"success": False, "error": f"Failed to connect to Command Server: {str(e)}. Is the extension running?"}
        except Exception as e:
            return {"success": False, "error": f"Command Server request failed: {str(e)}"}

    def list_terminals(self, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """List all open terminals in Cursor with details"""
        try:
            result = self._call_command_server("/cursor/terminals/list", "GET")
            if not result.get("success"):
                return result
            
            terminals = result.get("terminals", [])
            return {
                "success": True,
                "terminals": terminals,
                "count": len(terminals),
                "message": f"Found {len(terminals)} open terminals"
            }
        except Exception as e:
            return {"success": False, "error": f"Failed to list terminals: {str(e)}"}

    def close_terminal(self, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """Close a terminal in Cursor by name or index"""
        try:
            terminal_name = arguments.get("terminal_name")
            terminal_index = arguments.get("terminal_index")
            
            if not terminal_name and terminal_index is None:
                return {"success": False, "error": "Either terminal_name or terminal_index is required"}
            
            data = {}
            if terminal_name:
                data["terminal_name"] = terminal_name
            if terminal_index is not None:
                data["terminal_index"] = terminal_index
            
            result = self._call_command_server("/cursor/terminals/close", "POST", data)
            return result
        except Exception as e:
            return {"success": False, "error": f"Failed to close terminal: {str(e)}"}

    def manage_terminals(self, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """Analyze terminals and provide recommendations for closing unused ones"""
        try:
            threshold = arguments.get("threshold", 5)
            
            result = self._call_command_server(f"/cursor/terminals/manage?threshold={threshold}", "GET")
            if not result.get("success"):
                return result
            
            return {
                "success": True,
                "total_terminals": result.get("total_terminals", 0),
                "powershell_count": result.get("powershell_count", 0),
                "bash_count": result.get("bash_count", 0),
                "cmd_count": result.get("cmd_count", 0),
                "recommendations": result.get("recommendations", []),
                "close_options": result.get("close_options", []),
                "terminals": result.get("terminals", []),
                "message": f"Terminal management analysis complete: {result.get('total_terminals', 0)} terminals, {len(result.get('close_options', []))} close options available"
            }
        except Exception as e:
            return {"success": False, "error": f"Failed to manage terminals: {str(e)}"}

    def get_problems(self, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """Get all diagnostics/problems from Cursor IDE with enhanced filtering"""
        try:
            severity = arguments.get("severity", "all")
            workspace = arguments.get("workspace", None)
            limit = arguments.get("limit", 1000)
            
            # Build endpoint
            params = []
            if severity != "all":
                params.append(f"severity={urllib.parse.quote(severity)}")
            if workspace:
                params.append(f"workspace={urllib.parse.quote(workspace)}")
            
            endpoint = "/cursor/problems"
            if params:
                endpoint += "?" + "&".join(params)
            
            result = self._call_command_server(endpoint, "GET")
            if not result.get("success"):
                return result
            
            problems = result.get("problems", [])
            summary = result.get("summary", {})
            
            # Apply client-side filtering if needed
            if severity != "all":
                problems = [p for p in problems if p.get("severity", "").lower() == severity.lower()]
            
            # Apply limit
            if limit > 0 and len(problems) > limit:
                problems = problems[:limit]
            
            return {
                "success": True,
                "problems": problems,
                "summary": summary,
                "count": len(problems),
                "severity_filter": severity if severity != "all" else None,
                "workspace_filter": workspace,
                "limit_applied": limit if limit > 0 else None,
                "message": f"Found {len(problems)} problems ({summary.get('errors', 0)} errors, {summary.get('warnings', 0)} warnings)"
            }
        except Exception as e:
            return {"success": False, "error": f"Failed to get problems: {str(e)}"}

    def get_problem_summary(self, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """Get summary of problems by severity"""
        try:
            result = self._call_command_server("/cursor/problems/summary", "GET")
            if not result.get("success"):
                return result
            
            summary = result.get("summary", {})
            
            return {
                "success": True,
                "summary": summary,
                "message": f"Problems summary: {summary.get('total', 0)} total ({summary.get('errors', 0)} errors, {summary.get('warnings', 0)} warnings, {summary.get('info', 0)} info, {summary.get('hints', 0)} hints)"
            }
        except Exception as e:
            return {"success": False, "error": f"Failed to get problem summary: {str(e)}"}

    def get_file_problems(self, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """Get diagnostics/problems for a specific file"""
        try:
            file_path = arguments.get("file_path")
            if not file_path:
                return {"success": False, "error": "file_path parameter is required"}
            
            result = self._call_command_server(f"/cursor/problems/file?file={urllib.parse.quote(file_path)}", "GET")
            if not result.get("success"):
                return result
            
            problems = result.get("problems", [])
            
            return {
                "success": True,
                "file": file_path,
                "problems": problems,
                "count": len(problems),
                "message": f"Found {len(problems)} problems in {file_path}"
            }
        except Exception as e:
            return {"success": False, "error": f"Failed to get file problems: {str(e)}"}

    def list_output_channels(self, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """List all known output channels in Cursor IDE"""
        try:
            result = self._call_command_server("/cursor/output/channels", "GET")
            if not result.get("success"):
                return result
            
            channels = result.get("channels", [])
            
            return {
                "success": True,
                "channels": channels,
                "count": len(channels),
                "message": f"Found {len(channels)} output channels"
            }
        except Exception as e:
            return {"success": False, "error": f"Failed to list output channels: {str(e)}"}

    def get_output_channel_logs(self, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """Get output channel content with optional line limit"""
        try:
            channel_name = arguments.get("channel_name")
            if not channel_name:
                return {"success": False, "error": "channel_name parameter is required"}
            
            limit = arguments.get("limit", 100)
            
            endpoint = f"/cursor/output?channel={urllib.parse.quote(channel_name)}"
            if limit > 0:
                endpoint += f"&limit={limit}"
            
            result = self._call_command_server(endpoint, "GET")
            if not result.get("success"):
                return result
            
            return {
                "success": True,
                "channel": channel_name,
                "content": result.get("content", ""),
                "limit": limit if limit > 0 else None,
                "message": f"Retrieved output from channel '{channel_name}'" + (f" (last {limit} lines)" if limit > 0 else "")
            }
        except Exception as e:
            return {"success": False, "error": f"Failed to get output channel logs: {str(e)}"}
    
    def refresh_webview(self, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """Refresh/reload a specific webview panel without reloading the entire Cursor window"""
        try:
            view_id = arguments.get("view_id", "aimosDashboard")
            
            result = self._call_command_server(f"/cursor/webview/refresh?viewId={view_id}", "GET")
            if not result.get("success"):
                return result
            
            return {
                "success": True,
                "view_id": view_id,
                "message": result.get("message", f"Webview {view_id} refreshed"),
                "timestamp": result.get("timestamp"),
                "note": "Webview refreshed without reloading Cursor window - much faster!"
            }
        except Exception as e:
            return {"success": False, "error": f"Failed to refresh webview: {str(e)}"}
    
    def get_electron_logs(self, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """Get console logs from Electron application with enhanced filtering"""
        try:
            limit = arguments.get("limit", 100)
            level = arguments.get("level", "all")
            source = arguments.get("source", "all")
            search = arguments.get("search", "")  # New: search term filter
            time_range = arguments.get("time_range", "all")  # New: time range filter
            
            # Validate limit
            if limit > 1000:
                limit = 1000
            if limit < 1:
                limit = 100
            
            # Build endpoint with all parameters
            params = [f"limit={limit}", f"level={level}", f"source={source}"]
            if search:
                params.append(f"search={urllib.parse.quote(search)}")
            if time_range != "all":
                params.append(f"time_range={urllib.parse.quote(time_range)}")
            
            endpoint = f"/cursor/electron/logs?{'&'.join(params)}"
            result = self._call_command_server(endpoint, "GET")
            if not result.get("success"):
                return result
            
            logs = result.get("logs", [])
            
            # Apply client-side filtering if needed (server-side preferred)
            if search and not result.get("server_filtered", False):
                logs = [log for log in logs if search.lower() in str(log).lower()]
            
            return {
                "success": True,
                "logs": logs,
                "count": len(logs),
                "total_lines": result.get("total_lines", 0),
                "log_file": result.get("log_file", ""),
                "level_filter": level,
                "source_filter": source,
                "search_filter": search if search else None,
                "time_range_filter": time_range if time_range != "all" else None,
                "message": f"Retrieved {len(logs)} log lines from Electron app" + (f" (filtered by '{search}')" if search else "")
            }
        except Exception as e:
            return {"success": False, "error": f"Failed to get Electron logs: {str(e)}"}
    
    def list_diagnostic_sources(self, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """Discover all available diagnostic sources and their capabilities"""
        try:
            sources = {
                "electron_logs": {
                    "description": "Electron app console logs (main process and renderer process)",
                    "levels": ["error", "warn", "log", "info", "all"],
                    "sources": ["main", "renderer", "all"],
                    "filters": ["level", "source", "time_range", "search"],
                    "time_ranges": ["last_hour", "last_day", "last_week", "all"],
                    "limit": 1000,
                    "default_limit": 100,
                    "tool": "get_electron_logs",
                    "parameters": {
                        "limit": "integer (default: 100, max: 1000)",
                        "level": "string: 'error' | 'warn' | 'log' | 'info' | 'all' (default: 'all')",
                        "source": "string: 'main' | 'renderer' | 'all' (default: 'all')",
                        "search": "string (optional): search term to filter logs"
                    }
                },
                "cursor_problems": {
                    "description": "Cursor IDE diagnostics/problems (errors, warnings, info, hints)",
                    "severities": ["error", "warning", "info", "hint", "all"],
                    "filters": ["severity", "file", "workspace"],
                    "limit": 1000,
                    "default_limit": 100,
                    "tools": {
                        "all": "get_problems",
                        "summary": "get_problem_summary",
                        "file": "get_file_problems"
                    },
                    "parameters": {
                        "severity": "string: 'error' | 'warning' | 'info' | 'hint' | 'all' (default: 'all')",
                        "file_path": "string (optional): specific file path for get_file_problems",
                        "workspace": "string (optional): workspace folder path"
                    }
                },
                "output_channels": {
                    "description": "VS Code output channels (Extension Host, Git, Tasks, etc.)",
                    "channels": "dynamic (call list_output_channels to get available channels)",
                    "filters": ["channel", "level", "limit"],
                    "limit": 500,
                    "default_limit": 100,
                    "tools": {
                        "list": "list_output_channels",
                        "logs": "get_output_channel_logs"
                    },
                    "parameters": {
                        "channel_name": "string (required for get_output_channel_logs)",
                        "limit": "integer (default: 100, max: 500)"
                    }
                },
                "system_info": {
                    "description": "System monitoring data (CPU, memory, disk, processes, ports)",
                    "types": ["cpu", "memory", "disk", "processes", "ports"],
                    "filters": ["type"],
                    "tools": {
                        "info": "systemAPI.getSystemInfo() (Electron app)",
                        "processes": "systemAPI.getProcesses() (Electron app)",
                        "ports": "systemAPI.getPorts() (Electron app)"
                    },
                    "note": "System info tools are available via Electron app systemAPI, not MCP tools"
                }
            }
            
            return {
                "success": True,
                "sources": sources,
                "count": len(sources),
                "message": f"Found {len(sources)} diagnostic sources available",
                "usage": {
                    "discovery": "Call list_diagnostic_sources to discover available sources",
                    "specific_tools": "Call specific tools (get_electron_logs, get_problems, etc.) with parameters",
                    "unified": "Call get_unified_diagnostics to aggregate multiple sources"
                }
            }
        except Exception as e:
            return {"success": False, "error": f"Failed to list diagnostic sources: {str(e)}"}
    
    def get_unified_diagnostics(self, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """Get unified diagnostics from all sources (Cursor problems, Electron logs, output channels)"""
        try:
            include_problems = arguments.get("include_problems", True)
            include_electron_logs = arguments.get("include_electron_logs", True)
            include_output_channels = arguments.get("include_output_channels", False)
            problem_severity = arguments.get("problem_severity", "all")
            electron_log_limit = arguments.get("electron_log_limit", 50)
            electron_log_level = arguments.get("electron_log_level", "all")
            
            diagnostics = {
                "success": True,
                "timestamp": datetime.now().isoformat(),
                "sources": {},
                "summary": {
                    "total_problems": 0,
                    "total_errors": 0,
                    "total_warnings": 0,
                    "total_logs": 0,
                    "total_channels": 0
                }
            }
            
            # 1. Get Cursor IDE problems/diagnostics
            if include_problems:
                try:
                    problems_result = self.get_problems({})
                    if problems_result.get("success"):
                        problems = problems_result.get("problems", [])
                        summary = problems_result.get("summary", {})
                        
                        # Filter by severity if specified
                        if problem_severity != "all":
                            problems = [p for p in problems if p.get("severity", "").lower() == problem_severity.lower()]
                        
                        diagnostics["sources"]["cursor_problems"] = {
                            "problems": problems,
                            "summary": summary,
                            "count": len(problems)
                        }
                        diagnostics["summary"]["total_problems"] = len(problems)
                        diagnostics["summary"]["total_errors"] = summary.get("errors", 0)
                        diagnostics["summary"]["total_warnings"] = summary.get("warnings", 0)
                    else:
                        diagnostics["sources"]["cursor_problems"] = {
                            "error": problems_result.get("error", "Failed to fetch problems")
                        }
                except Exception as e:
                    diagnostics["sources"]["cursor_problems"] = {
                        "error": f"Exception fetching problems: {str(e)}"
                    }
            
            # 2. Get Electron app logs
            if include_electron_logs:
                try:
                    logs_result = self.get_electron_logs({
                        "limit": electron_log_limit,
                        "level": electron_log_level,
                        "source": "all"
                    })
                    if logs_result.get("success"):
                        logs = logs_result.get("logs", [])
                        diagnostics["sources"]["electron_logs"] = {
                            "logs": logs,
                            "count": len(logs),
                            "log_file": logs_result.get("log_file", ""),
                            "level_filter": electron_log_level
                        }
                        diagnostics["summary"]["total_logs"] = len(logs)
                    else:
                        diagnostics["sources"]["electron_logs"] = {
                            "error": logs_result.get("error", "Failed to fetch Electron logs")
                        }
                except Exception as e:
                    diagnostics["sources"]["electron_logs"] = {
                        "error": f"Exception fetching Electron logs: {str(e)}"
                    }
            
            # 3. Get output channels (optional)
            if include_output_channels:
                try:
                    channels_result = self.list_output_channels({})
                    if channels_result.get("success"):
                        channels = channels_result.get("channels", [])
                        diagnostics["sources"]["output_channels"] = {
                            "channels": channels,
                            "count": len(channels)
                        }
                        diagnostics["summary"]["total_channels"] = len(channels)
                    else:
                        diagnostics["sources"]["output_channels"] = {
                            "error": channels_result.get("error", "Failed to list output channels")
                        }
                except Exception as e:
                    diagnostics["sources"]["output_channels"] = {
                        "error": f"Exception fetching output channels: {str(e)}"
                    }
            
            # Build message
            parts = []
            if diagnostics["summary"]["total_problems"] > 0:
                parts.append(f"{diagnostics['summary']['total_problems']} problems ({diagnostics['summary']['total_errors']} errors, {diagnostics['summary']['total_warnings']} warnings)")
            if diagnostics["summary"]["total_logs"] > 0:
                parts.append(f"{diagnostics['summary']['total_logs']} log lines")
            if diagnostics["summary"]["total_channels"] > 0:
                parts.append(f"{diagnostics['summary']['total_channels']} output channels")
            
            diagnostics["message"] = f"Unified diagnostics: {', '.join(parts) if parts else 'No diagnostics found'}"
            
            return diagnostics
        except Exception as e:
            return {"success": False, "error": f"Failed to get unified diagnostics: {str(e)}"}
    
    # =============================================================================
    # Prompt Chain Tools (Phase 1 Implementation)
    # =============================================================================
    
    def _validate_chain(self, chain: Dict[str, Any]) -> Tuple[bool, Optional[str]]:
        """Validate chain structure
        
        Returns:
            Tuple of (is_valid, error_message)
        """
        try:
            # Check required fields
            if "name" not in chain:
                return False, "Chain name required"
            if "nodes" not in chain:
                return False, "Chain nodes required"
            if "edges" not in chain:
                return False, "Chain edges required"
            
            # Validate nodes
            node_ids = set()
            for node in chain["nodes"]:
                if "id" not in node:
                    return False, "Node ID required"
                if "type" not in node:
                    return False, "Node type required"
                if "position" not in node:
                    return False, "Node position required"
                if "label" not in node:
                    return False, "Node label required"
                
                node_id = node["id"]
                if node_id in node_ids:
                    return False, f"Duplicate node ID: {node_id}"
                node_ids.add(node_id)
            
            # Validate edges
            edge_ids = set()
            for edge in chain["edges"]:
                if "id" not in edge:
                    return False, "Edge ID required"
                if "source" not in edge:
                    return False, "Edge source required"
                if "target" not in edge:
                    return False, "Edge target required"
                
                edge_id = edge["id"]
                if edge_id in edge_ids:
                    return False, f"Duplicate edge ID: {edge_id}"
                edge_ids.add(edge_id)
                
                # Validate source and target nodes exist
                if edge["source"] not in node_ids:
                    return False, f"Invalid source node: {edge['source']}"
                if edge["target"] not in node_ids:
                    return False, f"Invalid target node: {edge['target']}"
            
            # Validate entry point if specified
            if "entryPoint" in chain and chain["entryPoint"]:
                if chain["entryPoint"] not in node_ids:
                    return False, f"Invalid entry point: {chain['entryPoint']}"
            
            return True, None
            
        except Exception as e:
            return False, f"Validation error: {str(e)}"
    
    def create_prompt_chain(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """Create a new prompt chain with nodes and edges for visual orchestration"""
        if not self.memory:
            return {"success": False, "error": "Memory system not initialized"}
        
        try:
            # Extract chain definition
            chain_def = {
                "name": args.get("name", ""),
                "description": args.get("description", ""),
                "nodes": args.get("nodes", []),
                "edges": args.get("edges", []),
                "executionType": args.get("executionType", "sequential"),
                "entryPoint": args.get("entryPoint"),
                "metadata": args.get("metadata", {})
            }
            
            # Validate chain
            is_valid, error_msg = self._validate_chain(chain_def)
            if not is_valid:
                return {"success": False, "error": error_msg or "Chain validation failed"}
            
            # Generate chain_id
            chain_id = f"chain_{uuid.uuid4().hex[:8]}"
            chain_def["chain_id"] = chain_id
            chain_def["version"] = 1
            chain_def["isTemplate"] = chain_def.get("metadata", {}).get("isTemplate", False)
            
            # Set created_at timestamp
            chain_def["created_at"] = datetime.now().isoformat()
            chain_def["updated_at"] = chain_def["created_at"]
            chain_def["created_by"] = args.get("created_by", "ai")
            
            # Extract metadata for tags
            metadata = chain_def.get("metadata", {})
            tags = {
                "type": "prompt_chain",
                "chain_id": chain_id,
                "category": metadata.get("category", "general")
            }
            
            # Add template tags if applicable
            if chain_def.get("isTemplate"):
                tags["is_template"] = "true"
            
            # Add custom tags from metadata
            if "tags" in metadata:
                if isinstance(metadata["tags"], list):
                    for tag in metadata["tags"]:
                        tags[f"tag_{tag}"] = tag
                elif isinstance(metadata["tags"], dict):
                    tags.update(metadata["tags"])
            
            # Store in CMC
            from cmc_service.models import AtomCreate, AtomContent
            
            atom_create = AtomCreate(
                modality="prompt_chain",
                content=AtomContent(inline=json.dumps(chain_def)),
                tags=tags,
                metadata={
                    "chain_id": chain_id,
                    "name": chain_def["name"],
                    "version": 1,
                    "node_count": len(chain_def["nodes"]),
                    "edge_count": len(chain_def["edges"]),
                    "created_at": chain_def["created_at"],
                    "created_by": chain_def["created_by"],
                    "execution_type": chain_def["executionType"],
                    # NEW: Timeline Connection (Timeline  Chain Bidirectional Graph)
                    "timeline_entry_ids": [],  # Timeline entries produced by this chain
                    "execution_count": 0,
                    "last_execution_id": None
                }
            )
            
            atom = self.memory.create_atom(atom_create)
            atom_id = atom.id
            
            log(f"Created prompt chain: {chain_id} (atom: {atom_id})")
            
            return {
                "success": True,
                "chain_id": atom_id,
                "chain": chain_def,
                "message": f"Chain '{chain_def['name']}' created successfully"
            }
            
        except Exception as e:
            log(f"Error creating prompt chain: {e}")
            return {"success": False, "error": f"Failed to create prompt chain: {str(e)}"}
    
    def update_prompt_chain(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """Update existing prompt chain (from AI or UI)"""
        if not self.memory:
            return {"success": False, "error": "Memory system not initialized"}
        
        try:
            chain_id = args.get("chain_id")
            updates = args.get("updates", {})
            reason = args.get("reason", "Chain updated")
            updated_by = args.get("updated_by", "user")
            
            if not chain_id:
                return {"success": False, "error": "chain_id parameter required"}
            
            # Get current chain
            try:
                atom = self.memory.get_atom(chain_id)
                if not atom:
                    return {"success": False, "error": f"Chain not found: {chain_id}"}
                
                # Parse current chain
                current_chain = json.loads(atom.content.inline) if hasattr(atom.content, 'inline') else json.loads(atom.content)
                
            except Exception as e:
                return {"success": False, "error": f"Failed to retrieve chain: {str(e)}"}
            
            # Merge updates
            updated_chain = {**current_chain, **updates}
            updated_chain["version"] = current_chain.get("version", 1) + 1
            updated_chain["updated_at"] = datetime.now().isoformat()
            updated_chain["updated_by"] = updated_by
            
            # Validate updated chain
            is_valid, error_msg = self._validate_chain(updated_chain)
            if not is_valid:
                return {"success": False, "error": error_msg or "Updated chain validation failed"}
            
            # Store new version in CMC (bitemporal)
            from cmc_service.models import AtomCreate, AtomContent
            
            # Preserve original tags
            original_tags = dict(atom.tags) if hasattr(atom, 'tags') else {}
            
            atom_create = AtomCreate(
                modality="prompt_chain",
                content=AtomContent(inline=json.dumps(updated_chain)),
                tags=original_tags,
                metadata={
                    **(atom.metadata if hasattr(atom, 'metadata') and atom.metadata else {}),
                    "chain_id": updated_chain.get("chain_id", chain_id),
                    "name": updated_chain.get("name"),
                    "version": updated_chain["version"],
                    "node_count": len(updated_chain.get("nodes", [])),
                    "edge_count": len(updated_chain.get("edges", [])),
                    "updated_at": updated_chain["updated_at"],
                    "updated_by": updated_by,
                    "reason": reason,
                    "previous_version": current_chain.get("version", 1)
                }
            )
            
            new_atom = self.memory.create_atom(atom_create)
            new_atom_id = new_atom.id
            
            log(f"Updated prompt chain: {chain_id} -> version {updated_chain['version']} (atom: {new_atom_id})")
            
            return {
                "success": True,
                "chain_id": new_atom_id,
                "chain": updated_chain,
                "version": updated_chain["version"],
                "message": f"Chain updated to version {updated_chain['version']}"
            }
            
        except Exception as e:
            log(f"Error updating prompt chain: {e}")
            return {"success": False, "error": f"Failed to update prompt chain: {str(e)}"}
    
    def get_prompt_chain(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """Retrieve prompt chain definition with optional version"""
        if not self.memory:
            return {"success": False, "error": "Memory system not initialized"}
        
        try:
            chain_id = args.get("chain_id")
            version = args.get("version")
            
            if not chain_id:
                return {"success": False, "error": "chain_id parameter required"}
            
            # Get chain atom
            try:
                atom = self.memory.get_atom(chain_id)
                if not atom:
                    return {"success": False, "error": f"Chain not found: {chain_id}"}
                
                # Parse chain
                chain = json.loads(atom.content.inline) if hasattr(atom.content, 'inline') else json.loads(atom.content)
                chain_version = chain.get("version", 1)
                
                # If specific version requested, try to find it
                # (For now, CMC returns latest version - version history would require querying all atoms with same chain_id tag)
                if version and version != chain_version:
                    log(f"Warning: Version {version} requested, but only version {chain_version} available")
                
                return {
                    "success": True,
                    "chain": chain,
                    "version": chain_version,
                    "chain_id": chain_id
                }
                
            except Exception as e:
                return {"success": False, "error": f"Failed to retrieve chain: {str(e)}"}
            
        except Exception as e:
            log(f"Error getting prompt chain: {e}")
            return {"success": False, "error": f"Failed to get prompt chain: {str(e)}"}
    
    def list_prompt_chains(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """List all prompt chains with optional filtering"""
        if not self.memory:
            log("ERROR: Memory system not initialized for list_prompt_chains")
            return {"success": False, "error": "Memory system not initialized"}
        
        try:
            filters = args.get("filters", {})
            limit = args.get("limit", 50)
            log(f"list_prompt_chains called with filters={filters}, limit={limit}")
            
            # Query CMC for prompt chains
            try:
                # Query by tag - check both "type" tag and "prompt_chain" tag
                # Try multiple tag query strategies
                chains = []
                
                # Strategy 1: Query by "type" tag = "prompt_chain"
                try:
                    atoms_by_type = list(self.memory.list_atoms(tag="type", limit=1000))
                    log(f"Found {len(atoms_by_type)} atoms with 'type' tag")
                    for atom in atoms_by_type:
                        # Check if atom has type=prompt_chain tag
                        if hasattr(atom, 'tags') and atom.tags.get("type") == "prompt_chain":
                            try:
                                chain = json.loads(atom.content.inline) if hasattr(atom.content, 'inline') else json.loads(atom.content)
                                chain["atom_id"] = atom.id
                                chains.append(chain)
                                log(f"Found chain via type tag: {chain.get('name', 'unnamed')} (atom: {atom.id})")
                            except Exception as e:
                                log(f"Error parsing chain from atom {atom.id}: {e}")
                                continue
                except Exception as e:
                    log(f"Error querying by type tag: {e}")
                
                # Strategy 2: Query all atoms and filter by modality (more reliable)
                if not chains:
                    log("No chains found via type tag, trying modality query...")
                    try:
                        all_atoms = list(self.memory.list_atoms(limit=1000))
                        log(f"Found {len(all_atoms)} total atoms")
                        for atom in all_atoms:
                            # Check modality first (most reliable)
                            if hasattr(atom, 'modality') and atom.modality == "prompt_chain":
                                try:
                                    chain = json.loads(atom.content.inline) if hasattr(atom.content, 'inline') else json.loads(atom.content)
                                    # Verify it's actually a chain (has nodes/edges or chain_id)
                                    if isinstance(chain, dict) and ("nodes" in chain or "chain_id" in chain):
                                        chain["atom_id"] = atom.id
                                        chains.append(chain)
                                        log(f"Found chain via modality: {chain.get('name', 'unnamed')} (atom: {atom.id})")
                                except Exception as e:
                                    log(f"Error parsing chain from atom {atom.id}: {e}")
                                    continue
                            # Also check tags for prompt_chain indicators
                            elif hasattr(atom, 'tags'):
                                tags = dict(atom.tags) if hasattr(atom.tags, 'items') else {}
                                if tags.get("type") == "prompt_chain":
                                    try:
                                        chain = json.loads(atom.content.inline) if hasattr(atom.content, 'inline') else json.loads(atom.content)
                                        if isinstance(chain, dict) and ("nodes" in chain or "chain_id" in chain):
                                            chain["atom_id"] = atom.id
                                            chains.append(chain)
                                            log(f"Found chain via tags: {chain.get('name', 'unnamed')} (atom: {atom.id})")
                                    except Exception as e:
                                        log(f"Error parsing chain from atom {atom.id}: {e}")
                                        continue
                    except Exception as e:
                        log(f"Error in fallback query: {e}")
                
                log(f"Found {len(chains)} chains before filtering")
                
                # Apply filters
                filtered_chains = []
                for chain in chains:
                    skip = False
                    
                    if filters.get("tags"):
                        chain_tags = chain.get("metadata", {}).get("tags", [])
                        if not any(tag in chain_tags for tag in filters["tags"]):
                            skip = True
                    
                    if filters.get("category"):
                        chain_category = chain.get("metadata", {}).get("category", "")
                        if chain_category != filters["category"]:
                            skip = True
                    
                    if filters.get("isTemplate") is not None:
                        chain_is_template = chain.get("isTemplate", False)
                        if chain_is_template != filters["isTemplate"]:
                            skip = True
                    
                    if filters.get("createdBy"):
                        chain_created_by = chain.get("created_by", "")
                        if chain_created_by != filters["createdBy"]:
                            skip = True
                    
                    if not skip:
                        filtered_chains.append(chain)
                
                chains = filtered_chains
                log(f"Found {len(chains)} chains after filtering")
                
                # Sort by updated_at (most recent first)
                chains.sort(key=lambda c: c.get("updated_at", c.get("created_at", "")), reverse=True)
                
                # Apply limit
                chains = chains[:limit]
                
                log(f"Returning {len(chains)} chains (limit: {limit})")
                return {
                    "success": True,
                    "chains": chains,
                    "total": len(chains),
                    "message": f"Found {len(chains)} chain(s)"
                }
                
            except Exception as e:
                log(f"ERROR in list_prompt_chains query: {e}")
                import traceback
                log(traceback.format_exc())
                return {"success": False, "error": f"Failed to query chains: {str(e)}"}
            
        except Exception as e:
            log(f"ERROR in list_prompt_chains: {e}")
            import traceback
            log(traceback.format_exc())
            return {"success": False, "error": f"Failed to list prompt chains: {str(e)}"}
    
    def add_chain_node(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """Add a single node to existing prompt chain"""
        if not self.memory:
            return {"success": False, "error": "Memory system not initialized"}
        
        try:
            chain_id = args.get("chain_id")
            node = args.get("node")
            connect_to = args.get("connectTo", [])
            connect_from = args.get("connectFrom", [])
            
            if not chain_id:
                return {"success": False, "error": "chain_id parameter required"}
            if not node:
                return {"success": False, "error": "node parameter required"}
            
            # Get current chain
            chain_result = self.get_prompt_chain({"chain_id": chain_id})
            if not chain_result.get("success"):
                return chain_result
            
            current_chain = chain_result["chain"]
            
            # Validate node
            if "id" not in node:
                return {"success": False, "error": "Node ID required"}
            if "type" not in node:
                return {"success": False, "error": "Node type required"}
            if "position" not in node:
                return {"success": False, "error": "Node position required"}
            if "label" not in node:
                return {"success": False, "error": "Node label required"}
            
            # Check for duplicate node ID
            existing_node_ids = {n["id"] for n in current_chain.get("nodes", [])}
            if node["id"] in existing_node_ids:
                return {"success": False, "error": f"Node ID already exists: {node['id']}"}
            
            # Add node
            updated_nodes = current_chain.get("nodes", []) + [node]
            
            # Create edges for connections
            updated_edges = list(current_chain.get("edges", []))
            edge_counter = len(updated_edges)
            
            # Connect to specified nodes
            for target_id in connect_to:
                if target_id not in existing_node_ids:
                    return {"success": False, "error": f"Invalid connectTo node: {target_id}"}
                
                edge_id = f"edge_{edge_counter}"
                updated_edges.append({
                    "id": edge_id,
                    "source": node["id"],
                    "target": target_id,
                    "type": "sequential"
                })
                edge_counter += 1
            
            # Connect from specified nodes
            for source_id in connect_from:
                if source_id not in existing_node_ids:
                    return {"success": False, "error": f"Invalid connectFrom node: {source_id}"}
                
                edge_id = f"edge_{edge_counter}"
                updated_edges.append({
                    "id": edge_id,
                    "source": source_id,
                    "target": node["id"],
                    "type": "sequential"
                })
                edge_counter += 1
            
            # Update chain
            return self.update_prompt_chain({
                "chain_id": chain_id,
                "updates": {
                    "nodes": updated_nodes,
                    "edges": updated_edges
                },
                "reason": f"Added node {node['id']}",
                "updated_by": args.get("updated_by", "user")
            })
            
        except Exception as e:
            log(f"Error adding chain node: {e}")
            return {"success": False, "error": f"Failed to add chain node: {str(e)}"}
    
    def connect_chain_nodes(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """Create connection between nodes in prompt chain"""
        if not self.memory:
            return {"success": False, "error": "Memory system not initialized"}
        
        try:
            chain_id = args.get("chain_id")
            source = args.get("source")
            target = args.get("target")
            edge_type = args.get("type", "sequential")
            condition = args.get("condition")
            data_mapping = args.get("dataMapping")
            
            if not chain_id:
                return {"success": False, "error": "chain_id parameter required"}
            if not source:
                return {"success": False, "error": "source parameter required"}
            if not target:
                return {"success": False, "error": "target parameter required"}
            
            # Get current chain
            chain_result = self.get_prompt_chain({"chain_id": chain_id})
            if not chain_result.get("success"):
                return chain_result
            
            current_chain = chain_result["chain"]
            
            # Validate nodes exist
            node_ids = {n["id"] for n in current_chain.get("nodes", [])}
            if source not in node_ids:
                return {"success": False, "error": f"Invalid source node: {source}"}
            if target not in node_ids:
                return {"success": False, "error": f"Invalid target node: {target}"}
            
            # Create new edge
            edge_counter = len(current_chain.get("edges", []))
            new_edge = {
                "id": f"edge_{edge_counter}",
                "source": source,
                "target": target,
                "type": edge_type
            }
            
            if condition:
                new_edge["condition"] = condition
            if data_mapping:
                new_edge["dataMapping"] = data_mapping
            
            # Add edge
            updated_edges = current_chain.get("edges", []) + [new_edge]
            
            # Update chain
            return self.update_prompt_chain({
                "chain_id": chain_id,
                "updates": {
                    "edges": updated_edges
                },
                "reason": f"Connected {source} -> {target}",
                "updated_by": args.get("updated_by", "user")
            })
            
        except Exception as e:
            log(f"Error connecting chain nodes: {e}")
            return {"success": False, "error": f"Failed to connect chain nodes: {str(e)}"}
    
    def execute_prompt_chain(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """Execute a prompt chain (delegates to Chain Executor)"""
        if not self.memory:
            return {"success": False, "error": "Memory system not initialized"}
        
        try:
            chain_id = args.get("chain_id")
            inputs = args.get("inputs", {})
            context = args.get("context", {})
            agent_name = args.get("agent_name", "primary")
            
            if not chain_id:
                return {"success": False, "error": "chain_id parameter required"}
            
            # Import chain executor
            try:
                from prompt_chain_executor.mcp_integration import execute_prompt_chain_via_mcp
            except ImportError:
                # Fallback if executor not available
                log("Warning: Chain executor not available, using placeholder")
                execution_id = f"exec_{uuid.uuid4().hex[:8]}"
                return {
                    "success": True,
                    "execution_id": execution_id,
                    "status": "pending",
                    "chain_id": chain_id,
                    "message": "Chain execution queued (executor not available)"
                }
            
            # Execute chain via executor
            # Create timeline entry callback for node-level tracking
            def create_node_timeline_entry(prompt_id, user_input, context_state, executed_via_chain_id, chain_execution_id, chain_node_id):
                """Callback to create timeline entries for chain node execution"""
                try:
                    # Add chain connection info to context_state
                    context_state["executed_via_chain_id"] = executed_via_chain_id
                    context_state["chain_execution_id"] = chain_execution_id
                    context_state["chain_node_id"] = chain_node_id
                    
                    self.add_timeline_entry({
                        "prompt_id": prompt_id,
                        "user_input": user_input,
                        "context_state": context_state
                    })
                except Exception as e:
                    log(f"Warning: Failed to create node timeline entry: {e}")
            
            # Get executor with timeline callback
            executor = get_chain_executor(
                memory=self.memory,
                timeline_entry_callback=create_node_timeline_entry
            )
            
            result = execute_prompt_chain_via_mcp(
                chain_id=chain_id,
                inputs=inputs,
                context=context,
                agent_name=agent_name,
                memory_store=self.memory,
                executor=executor  # Pass executor with callback
            )
            
            if result.get("success"):
                execution_id = result.get("chain_instance_id", f"exec_{uuid.uuid4().hex[:8]}")
                
                # NEW: Create timeline entries for chain execution (Timeline  Chain Bidirectional Graph)
                timeline_entry_ids = []
                try:
                    # Create timeline entry for chain execution start
                    execution_start_entry = self._create_chain_execution_timeline_entry(
                        chain_id=chain_id,
                        execution_id=execution_id,
                        status="started",
                        context=context
                    )
                    if execution_start_entry:
                        timeline_entry_ids.append(execution_start_entry)
                    
                    # Link timeline entries to chain (bidirectional linking)
                    self._link_timeline_to_chain(chain_id, timeline_entry_ids, execution_id)
                    
                except Exception as e:
                    log(f"Warning: Failed to create timeline entries for chain execution: {e}")
                
                log(f"Chain execution completed: {chain_id} (execution: {execution_id})")
                return {
                    "success": True,
                    "execution_id": execution_id,
                    "status": result.get("status", "completed"),
                    "chain_id": chain_id,
                    "steps_completed": result.get("steps_completed", 0),
                    "steps_failed": result.get("steps_failed", 0),
                    "metrics": result.get("metrics", {}),
                    "timeline_entry_ids": timeline_entry_ids,  # NEW: Return timeline entry IDs
                    "message": f"Chain execution completed: {result.get('steps_completed', 0)} steps"
                }
            else:
                return {
                    "success": False,
                    "error": result.get("error", "Chain execution failed"),
                    "chain_id": chain_id
                }
            
        except Exception as e:
            log(f"Error executing prompt chain: {e}")
            return {"success": False, "error": f"Failed to execute prompt chain: {str(e)}"}
    
    def _create_chain_execution_timeline_entry(
        self,
        chain_id: str,
        execution_id: str,
        status: str,
        context: Dict[str, Any]
    ) -> Optional[str]:
        """
        Create timeline entry for chain execution (Timeline  Chain Bidirectional Graph)
        
        Returns:
            Timeline entry ID if created successfully, None otherwise
        """
        try:
            # Use MCP timeline entry tool if available
            from datetime import datetime
            
            prompt_id = f"chain_exec_{execution_id}"
            user_input = f"Executing chain {chain_id} (status: {status})"
            
            context_state = {
                "chain_id": chain_id,
                "execution_id": execution_id,
                "status": status,
                "context": context,
                "chain_execution": True
            }
            
            # Create timeline entry via MCP add_timeline_entry tool
            timeline_result = self.add_timeline_entry({
                "prompt_id": prompt_id,
                "user_input": user_input,
                "context_state": context_state
            })
            
            if timeline_result.get("success"):
                # Return the prompt_id as timeline entry identifier
                return prompt_id
            else:
                log(f"Failed to create timeline entry: {timeline_result.get('error')}")
                return None
                
        except Exception as e:
            log(f"Error creating chain execution timeline entry: {e}")
            return None
    
    def _link_timeline_to_chain(
        self,
        chain_id: str,
        timeline_entry_ids: List[str],
        execution_id: str
    ) -> None:
        """
        Link timeline entries to chain bidirectionally (Timeline  Chain Bidirectional Graph)
        
        This creates bidirectional connections:
        - Timeline entries know which chain executed them (via executed_via_chain_id)
        - Chain knows what timeline entries it produced (via timeline_entry_ids in metadata)
        """
        if not timeline_entry_ids:
            return
        
        try:
            # Get current chain
            chain_result = self.get_prompt_chain({"chain_id": chain_id})
            if not chain_result.get("success"):
                log(f"Failed to get chain for linking: {chain_result.get('error')}")
                return
            
            current_chain = chain_result["chain"]
            current_metadata = current_chain.get("metadata", {})
            
            # Update chain metadata with timeline entry IDs
            existing_timeline_ids = current_metadata.get("timeline_entry_ids", [])
            updated_timeline_ids = list(set(existing_timeline_ids + timeline_entry_ids))
            
            # Update execution count
            execution_count = current_metadata.get("execution_count", 0) + 1
            
            # Update chain with new timeline entry IDs
            updates = {
                "metadata": {
                    **current_metadata,
                    "timeline_entry_ids": updated_timeline_ids,
                    "execution_count": execution_count,
                    "last_execution_id": execution_id
                }
            }
            
            self.update_prompt_chain({
                "chain_id": chain_id,
                "updates": updates,
                "reason": f"Linked {len(timeline_entry_ids)} timeline entries to chain execution",
                "updated_by": "system"
            })
            
            log(f"Linked {len(timeline_entry_ids)} timeline entries to chain {chain_id}")
            
        except Exception as e:
            log(f"Error linking timeline to chain: {e}")
            import traceback
            log(traceback.format_exc())
    
    def call_api(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """Call an external API with automatic AIM-OS integration"""
        try:
            # Import LLM API service registry (new implementation)
            try:
                from packages.api_service_registry.llm import get_api_registry
                api_registry = get_api_registry()
            except ImportError:
                return {
                    "success": False,
                    "error": "LLM API service registry not available. Install required packages."
                }
            
            provider = args.get("provider")
            endpoint = args.get("endpoint")
            method = args.get("method", "POST")
            data = args.get("data")
            hhni_query = args.get("hhni_query")  # HHNI context retrieval query (Sev P0)
            integrate_aimos = args.get("integrate_aimos", True)
            
            if not provider:
                return {"success": False, "error": "provider parameter required"}
            if not endpoint:
                return {"success": False, "error": "endpoint parameter required"}
            
            # HHNI context retrieval (Sev P0 requirement)
            context_items = None
            if hhni_query and self.memory:
                try:
                    # Use HHNI retriever to get context
                    from hhni.retrieval import TwoStageRetriever, RetrievalConfig
                    from hhni import HierarchicalIndex
                    
                    # Get HHNI index from memory (if available)
                    # TODO: Integrate with HHNI retriever properly
                    # For now, context_items will be None - will be handled by registry
                    pass
                except Exception as e:
                    log(f"Warning: HHNI context retrieval failed: {e}")
            
            # Call API
            api_response = api_registry.call_api(
                provider=provider,
                endpoint=endpoint,
                method=method,
                data=data,
                hhni_query=hhni_query,
                integrate_aimos=False  # We handle AIM-OS integration here
            )
            
            # Check for key rotation events (Chronos P0 requirement)
            key_rotation_event = None
            quota_exhaustion_event = None
            if hasattr(api_registry, 'key_manager'):
                key_manager = api_registry.key_manager
                if hasattr(key_manager, '_last_rotation_event') and key_manager._last_rotation_event:
                    key_rotation_event = key_manager._last_rotation_event
                    key_manager._last_rotation_event = None  # Clear after reading
                if hasattr(key_manager, '_last_quota_event') and key_manager._last_quota_event:
                    quota_exhaustion_event = key_manager._last_quota_event
                    key_manager._last_quota_event = None  # Clear after reading
            
            # Integrate with AIM-OS if enabled
            aimos_result = {}
            if integrate_aimos and self.memory:
                try:
                    # Extract response data
                    response_data = api_response.get("data", {})
                    response_metadata = api_response.get("metadata", {})
                    success = api_response.get("success", False)
                    error = api_response.get("error")
                    
                    # CMC Storage (Atlas recommendations)
                    if success or error:  # Store both success and error calls
                        # Build content dict
                        content_dict = {
                            "provider": provider,
                            "model": response_data.get("model", "unknown"),
                            "key_index": response_data.get("key_index", -1),
                            "request": data,
                            "response": response_data.get("content", "") if success else None,
                            "tokens_input": response_data.get("tokens_input", 0),
                            "tokens_output": response_data.get("tokens_output", 0),
                            "tokens_total": response_data.get("tokens_used", 0),
                            "latency_ms": response_metadata.get("latency_ms", 0),
                            "cost": response_metadata.get("cost", 0.0),
                            "timestamp": response_metadata.get("timestamp", datetime.now(timezone.utc).isoformat()),
                        }
                        
                        if error:
                            content_dict["error"] = error
                        if key_rotation_event:
                            content_dict["rotation_triggered"] = True
                        
                        # Build tags (Atlas recommendations)
                        tags = {
                            f"system:{provider}:p0": 1.0,
                            "system:cmc:p0": 1.0,
                            "integration_type:llm_api_call": 1.0,
                            f"connection:llm_api->cmc": 1.0,
                            "modality:text": 1.0,
                            f"provider:{provider}": 1.0,
                            f"model:{response_data.get('model', 'unknown')}": 1.0,
                            f"key_index:{response_data.get('key_index', -1)}": 1.0,
                            "hhni_index": 1.0,  # Required for HHNI poller indexing (Sev P0 requirement)
                        }
                        
                        # Add task context tags if available
                        if data:
                            task_type = data.get("task_type")
                            agent = data.get("agent")
                            thinking_mode = data.get("thinking_mode")
                            if task_type:
                                tags[f"task_type:{task_type}"] = 1.0
                            if agent:
                                tags[f"agent:{agent}"] = 1.0
                            if thinking_mode:
                                tags[f"mode:{thinking_mode}"] = 1.0
                        
                        if error:
                            tags["error"] = 1.0
                        if key_rotation_event:
                            tags["key_rotation"] = 1.0
                        
                        # Build metadata (Atlas recommendations)
                        metadata = {
                            "provider": provider,
                            "model": response_data.get("model", "unknown"),
                            "key_index": response_data.get("key_index", -1),
                            "tokens_input": response_data.get("tokens_input", 0),
                            "tokens_output": response_data.get("tokens_output", 0),
                            "tokens_total": response_data.get("tokens_used", 0),
                            "latency_ms": response_metadata.get("latency_ms", 0),
                            "cost": response_metadata.get("cost", 0.0),
                            "cost_per_token": response_metadata.get("cost", 0.0) / max(response_data.get("tokens_used", 1), 1),
                            "rotation_triggered": bool(key_rotation_event),
                            "timestamp": response_metadata.get("timestamp", datetime.now(timezone.utc).isoformat()),
                        }
                        
                        if error:
                            metadata["error"] = error
                            metadata["error_type"] = "api_error"
                        
                        # Store in CMC
                        cmc_result = self.store_memory({
                            "content": json.dumps(content_dict),
                            "tags": tags,
                            "modality": "llm_api_call",
                            "metadata": metadata
                        })
                        
                        # VIF Witness Creation (Sage recommendations)
                        # Provider-specific confidence baselines
                        provider_baselines = {
                            "gemini": {
                                "gemini-2.5-pro": 0.90,
                                "gemini-2.5-flash": 0.80,
                                "default": 0.85
                            },
                            "cerebras": {
                                "llama-3.1-8b-instruct": 0.75,
                                "default": 0.70
                            }
                        }
                        
                        model_name = response_data.get("model", "unknown")
                        baseline = provider_baselines.get(provider, {}).get(model_name) or provider_baselines.get(provider, {}).get("default", 0.80)
                        confidence = baseline if success else 0.30
                        
                        # -gate policy (Sage recommendations)
                        task_criticality = data.get("task_criticality", "ROUTINE") if data else "ROUTINE"
                        kappa_thresholds = {
                            "CRITICAL": 0.90,
                            "IMPORTANT": 0.85,
                            "ROUTINE": 0.70,
                            "LOW_STAKES": 0.60
                        }
                        kappa_threshold = kappa_thresholds.get(task_criticality, 0.70)
                        kappa_gate_passed = confidence >= kappa_threshold
                        
                        vif_result = self.track_confidence({
                            "task": f"LLM API call: {provider}/{endpoint}",
                            "confidence": confidence,
                            "reasoning": f"LLM call {'succeeded' if success else 'failed'} with model {model_name}",
                            "evidence": [
                                f"Provider: {provider}",
                                f"Model: {model_name}",
                                f"Key Index: {response_data.get('key_index', -1)}",
                                f"Latency: {response_metadata.get('latency_ms', 0)}ms",
                                f"Tokens: {response_data.get('tokens_used', 0)}"
                            ],
                            "kappa_gate_passed": kappa_gate_passed,
                            "provider": provider,
                            "model": model_name,
                            "key_index": response_data.get("key_index", -1),
                            "tokens": response_data.get("tokens_used", 0),
                            "cost": response_metadata.get("cost", 0.0),
                            "latency_ms": response_metadata.get("latency_ms", 0),
                            "task_type": data.get("task_type", "unknown") if data else "unknown",
                            "agent": data.get("agent", "unknown") if data else "unknown",
                            "thinking_mode": data.get("thinking_mode", "unknown") if data else "unknown"
                        })
                        
                        # TCS Timeline Logging (Chronos recommendations)
                        if hasattr(self, 'timeline_tracker') and self.timeline_tracker:
                            try:
                                context_state = {
                                    "event_type": "llm_api_call" if success else "llm_error",
                                    "event_category": "llm_interaction",
                                    "provider": provider,
                                    "model": model_name,
                                    "key_index": response_data.get("key_index", -1),
                                    "prompt_tokens": response_data.get("tokens_input", 0),
                                    "response_tokens": response_data.get("tokens_output", 0),
                                    "total_tokens": response_data.get("tokens_used", 0),
                                    "latency_ms": response_metadata.get("latency_ms", 0),
                                    "success": success,
                                    "error_message": error if not success else None,
                                    "integration_tags": [
                                        "system:tcs:p0",
                                        "system:llm:p0",
                                        "integration_type:llm_call",
                                        "connection:llm->tcs",
                                        "modality:tcs_timeline"
                                    ],
                                    "metadata": {
                                        "source_system": "llm_api",
                                        "endpoint": endpoint,
                                        "method": method
                                    }
                                }
                                
                                # Add task context if available
                                if data:
                                    context_state["task_type"] = data.get("task_type")
                                    context_state["agent"] = data.get("agent")
                                    context_state["thinking_mode"] = data.get("thinking_mode")
                                
                                # Create timeline entry using track_prompt_context method
                                prompt_id = f"llm_{provider}_{response_data.get('key_index', -1)}_{int(time.time())}"
                                user_input = f"LLM API Call: {provider} {model_name} ({'success' if success else 'error'})"
                                self.timeline_tracker.track_prompt_context(
                                    prompt_id=prompt_id,
                                    user_input=user_input,
                                    context_state=context_state
                                )
                            except Exception as e:
                                log(f"Warning: TCS timeline logging failed: {e}")
                        
                        # Key Rotation Timeline Entry (Chronos P0 requirement)
                        if key_rotation_event and hasattr(self, 'timeline_tracker') and self.timeline_tracker:
                            try:
                                rotation_context = {
                                    "event_type": "key_rotation",
                                    "event_category": "llm_interaction",
                                    "provider": key_rotation_event["provider"],
                                    "old_key_index": key_rotation_event["old_key_index"],
                                    "new_key_index": key_rotation_event["new_key_index"],
                                    "reason": key_rotation_event["reason"],
                                    "timestamp": key_rotation_event["timestamp"],
                                    "integration_tags": [
                                        "system:tcs:p0",
                                        "system:llm:p0",
                                        "integration_type:key_rotation",
                                        "connection:llm->tcs",
                                        "modality:tcs_timeline"
                                    ]
                                }
                                prompt_id = f"key_rotation_{key_rotation_event['provider']}_{int(time.time())}"
                                user_input = f"Key Rotation: {key_rotation_event['provider']} (key {key_rotation_event['old_key_index']} -> {key_rotation_event['new_key_index']}, reason: {key_rotation_event['reason']})"
                                self.timeline_tracker.track_prompt_context(
                                    prompt_id=prompt_id,
                                    user_input=user_input,
                                    context_state=rotation_context
                                )
                            except Exception as e:
                                log(f"Warning: Key rotation timeline logging failed: {e}")
                        
                        # Quota Exhaustion Timeline Entry (Chronos P0 requirement)
                        if quota_exhaustion_event and hasattr(self, 'timeline_tracker') and self.timeline_tracker:
                            try:
                                quota_context = {
                                    "event_type": "quota_exhausted",
                                    "event_category": "llm_interaction",
                                    "provider": quota_exhaustion_event["provider"],
                                    "key_index": quota_exhaustion_event["key_index"],
                                    "timestamp": quota_exhaustion_event["timestamp"],
                                    "integration_tags": [
                                        "system:tcs:p0",
                                        "system:llm:p0",
                                        "integration_type:quota_exhaustion",
                                        "connection:llm->tcs",
                                        "modality:tcs_timeline"
                                    ]
                                }
                                prompt_id = f"quota_exhausted_{quota_exhaustion_event['provider']}_{int(time.time())}"
                                user_input = f"Quota Exhausted: {quota_exhaustion_event['provider']} (key {quota_exhaustion_event['key_index']})"
                                self.timeline_tracker.track_prompt_context(
                                    prompt_id=prompt_id,
                                    user_input=user_input,
                                    context_state=quota_context
                                )
                            except Exception as e:
                                log(f"Warning: Quota exhaustion timeline logging failed: {e}")
                        
                        aimos_result = {
                            "cmc": {"atom_id": cmc_result.get("atom_id")},
                            "vif": {"witness_id": vif_result.get("witness_id")},
                            "tcs": {"timeline_entry_created": True}
                        }
                    else:
                        aimos_result = {"error": "No response data to store"}
                except Exception as e:
                    log(f"Warning: AIM-OS integration failed: {e}")
                    import traceback
                    log(traceback.format_exc())
                    aimos_result = {"error": str(e)}
            
            return {
                "success": api_response.get("success", False),
                "data": api_response.get("data", {}),
                "error": api_response.get("error"),
                "metadata": api_response.get("metadata", {}),
                "aimos": aimos_result
            }
            
        except Exception as e:
            log(f"Error calling API: {e}")
            import traceback
            log(traceback.format_exc())
            return {"success": False, "error": f"Failed to call API: {str(e)}"}
    
    def list_apis(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """List all available APIs"""
        try:
            # Import API service registry
            try:
                from api_service_registry import get_api_registry
                api_registry = get_api_registry()
            except ImportError:
                return {
                    "success": False,
                    "error": "API service registry not available. Install required packages."
                }
            
            apis = api_registry.list_apis()
            
            return {
                "success": True,
                "apis": apis,
                "total": len(apis),
                "message": f"Found {len(apis)} API(s)"
            }
            
        except Exception as e:
            log(f"Error listing APIs: {e}")
            import traceback
            log(traceback.format_exc())
            return {"success": False, "error": f"Failed to list APIs: {str(e)}"}
    
    def api_status(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """Get status for a specific API"""
        try:
            # Import API service registry
            try:
                from api_service_registry import get_api_registry
                api_registry = get_api_registry()
            except ImportError:
                return {
                    "success": False,
                    "error": "API service registry not available. Install required packages."
                }
            
            provider = args.get("provider")
            if not provider:
                return {"success": False, "error": "provider parameter required"}
            
            status = api_registry.get_api_status(provider)
            
            return {
                "success": True,
                "status": status,
                "message": f"API {provider} is {'configured' if status.get('configured') else 'not configured'}"
            }
            
        except Exception as e:
            log(f"Error getting API status: {e}")
            import traceback
            log(traceback.format_exc())
            return {"success": False, "error": f"Failed to get API status: {str(e)}"}
    
    def deepsearch(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """Execute DEEPSEARCH - 9-layer sovereign intelligence engine"""
        try:
            # Import DEEPSEARCH
            try:
                from deepsearch import search_deepsearch
            except ImportError:
                return {
                    "success": False,
                    "error": "DEEPSEARCH package not available. Run: pip install -e packages/deepsearch"
                }
            
            query = args.get("query")
            if not query:
                return {"success": False, "error": "query parameter required"}
            
            # Execute DEEPSEARCH
            result = search_deepsearch(
                query=query,
                search_type=args.get("search_type", "mixed"),
                depth=args.get("depth", 3),
                max_results=args.get("max_results", 20),
                filters=args.get("filters"),
                analysis=args.get("analysis"),
                synthesis=args.get("synthesis"),
                workspace_path=os.getcwd()
            )
            
            return {
                "success": True,
                "data": result,
                "message": f"DEEPSEARCH found {result['metadata']['total_results']} results in {result['metadata']['search_time']:.2f}s"
            }
        except Exception as e:
            log(f"Error executing DEEPSEARCH: {e}")
            import traceback
            log(traceback.format_exc())
            return {"success": False, "error": f"DEEPSEARCH failed: {str(e)}"}
    
    def icip_search(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """Execute ICIP semantic code search with real embeddings"""
        try:
            query = args.get("query")
            if not query:
                return {"success": False, "error": "query parameter required"}
            
            search_tier = args.get("search_tier", "semantic")
            codebase = args.get("codebase", os.getcwd())
            languages = args.get("languages", ["py", "python"])  # Start with Python
            max_results = args.get("max_results", 20)
            include_context = args.get("include_context", True)
            
            # Use real semantic search for tier 3
            if search_tier == "semantic":
                try:
                    from icip_search import SemanticEngine
                    
                    # Create or load engine
                    engine = SemanticEngine(codebase)
                    
                    # Ensure indexed (first time only)
                    if engine.index.size() == 0:
                        log(f"[ICIP] Indexing codebase {codebase} for first time...")
                        engine.index_codebase(languages=languages)
                    
                    # Search semantically
                    results = engine.search(query, k=max_results, include_context=include_context)
                    
                    # Convert to dict format
                    result_dicts = []
                    for result in results:
                        result_dicts.append({
                            "file": result.file,
                            "line": result.line,
                            "code": result.code,
                            "context": result.context,
                            "language": result.language,
                            "type": result.type,
                            "name": result.name,
                            "relevance": result.relevance,
                            "confidence": result.confidence,
                        })
                    
                    return {
                        "success": True,
                        "data": {
                            "results": result_dicts,
                            "metadata": {
                                "query": query,
                                "search_tier": "semantic",
                                "total_results": len(result_dicts),
                                "search_time": 0.1,  # TODO: Measure actual time
                                "languages_searched": languages,
                                "index_stats": engine.get_stats(),
                            }
                        },
                        "message": f"ICIP semantic search found {len(result_dicts)} results"
                    }
                
                except ImportError:
                    log("[ICIP] icip_search package not found. Falling back to literal search.")
                    # Fall through to literal search
                except Exception as e:
                    log(f"[ICIP] Semantic search failed: {e}. Falling back to literal search.")
                    import traceback
                    log(traceback.format_exc())
                    # Fall through to literal search
            
            # Fallback: Literal search (Tier 1)
            # Original grep-based implementation as fallback
            
            results = []
            files_searched = 0
            
            # Walk codebase
            for root, dirs, files in os.walk(codebase):
                # Skip common directories
                dirs[:] = [d for d in dirs if d not in ['node_modules', '.git', '__pycache__', 'dist', 'build', 'coverage']]
                
                for filename in files:
                    # Check language
                    ext = os.path.splitext(filename)[1].lstrip('.')
                    if ext not in languages:
                        continue
                    
                    files_searched += 1
                    filepath = os.path.join(root, filename)
                    
                    # Read file
                    try:
                        with open(filepath, 'r', encoding='utf-8') as f:
                            lines = f.readlines()
                        
                        # Search for query in file
                        for line_num, line in enumerate(lines, 1):
                            if search_tier == 'literal':
                                # Literal match
                                if query in line:
                                    results.append(self._create_code_result(
                                        filepath, line_num, line, lines, ext, include_context, args.get("context_lines", 3)
                                    ))
                            else:
                                # Semantic/structural (simplified for now)
                                if query.lower() in line.lower():
                                    results.append(self._create_code_result(
                                        filepath, line_num, line, lines, ext, include_context, args.get("context_lines", 3)
                                    ))
                            
                            if len(results) >= max_results:
                                break
                        
                        if len(results) >= max_results:
                            break
                    except:
                        continue
                
                if len(results) >= max_results:
                    break
            
            # Build result
            return {
                "success": True,
                "data": {
                    "results": results[:max_results],
                    "metadata": {
                        "query": query,
                        "search_tier": search_tier,
                        "total_results": len(results),
                        "search_time": 0.1,  # Placeholder
                        "languages_searched": languages,
                        "files_searched": files_searched,
                    }
                },
                "message": f"ICIP search found {len(results)} results"
            }
        except Exception as e:
            log(f"Error executing ICIP search: {e}")
            import traceback
            log(traceback.format_exc())
            return {"success": False, "error": f"ICIP search failed: {str(e)}"}
    
    def _create_code_result(
        self,
        filepath: str,
        line_num: int,
        line: str,
        all_lines: List[str],
        language: str,
        include_context: bool,
        context_lines: int
    ) -> Dict:
        """Create code search result"""
        result = {
            "file": filepath,
            "line": line_num,
            "code": line.strip(),
            "language": language,
            "relevance": 0.8,  # Placeholder
            "confidence": 0.85,  # Placeholder
        }
        
        # Add context if requested
        if include_context:
            start = max(0, line_num - context_lines - 1)
            end = min(len(all_lines), line_num + context_lines)
            context = ''.join(all_lines[start:end])
            result["context"] = context
        
        # Classify code type (simple heuristics)
        if 'def ' in line or 'function ' in line:
            result["type"] = "function"
        elif 'class ' in line:
            result["type"] = "class"
        elif 'import ' in line or 'from ' in line:
            result["type"] = "import"
        else:
            result["type"] = "variable"
        
        return result

if __name__ == "__main__":
    server = SimpleMCPServer()
    server.run()
